[
  {
    "objectID": "proyectos.html",
    "href": "proyectos.html",
    "title": "Proyectos",
    "section": "",
    "text": "La secciÃ³n Proyectos tiene como propÃ³sito ofrecer un espacio para que los estudiantes de la Facultad de EconomÃ­a y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de EconometrÃ­a y EconometrÃ­a para la GestiÃ³n.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicaciÃ³n prÃ¡ctica de los contenidos del curso y el fortalecimiento de las habilidades analÃ­ticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "proyectos.html#recopilaciÃ³n-de-proyectos",
    "href": "proyectos.html#recopilaciÃ³n-de-proyectos",
    "title": "Proyectos",
    "section": "",
    "text": "La secciÃ³n Proyectos tiene como propÃ³sito ofrecer un espacio para que los estudiantes de la Facultad de EconomÃ­a y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de EconometrÃ­a y EconometrÃ­a para la GestiÃ³n.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicaciÃ³n prÃ¡ctica de los contenidos del curso y el fortalecimiento de las habilidades analÃ­ticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "proyectos.html#subir-tu-proyecto",
    "href": "proyectos.html#subir-tu-proyecto",
    "title": "Proyectos",
    "section": "Subir tu proyecto",
    "text": "Subir tu proyecto\nSi eres estudiante de los cursos de EconometrÃ­a o EconometrÃ­a para la GestiÃ³n, puedes subir tu proyecto de investigaciÃ³n (formato PDF, QMD o ZIP).\nEn caso de que debas subir mÃ¡s de un archivo, comprÃ­melos en una sola carpeta y sÃºbela en formato .zip.\nLos archivos se almacenarÃ¡n automÃ¡ticamente en el repositorio fen-uah/lab-econometria, dentro de la carpeta /uploads."
  },
  {
    "objectID": "datos.html",
    "href": "datos.html",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reÃºnen diversas fuentes de informaciÃ³n estadÃ­stica y bases de datos relevantes para el anÃ¡lisis econÃ³mico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio Ãºnico y accesible, desde el cual puedan explorar y trabajar con informaciÃ³n oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a travÃ©s del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interÃ©s.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisiÃ³n universitaria (PSU, PAES, etc.).\nMinisterio de EducaciÃ³n (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadÃ­sticas comparables a nivel internacional.\nMinisterio de Ciencia, TecnologÃ­a, Conocimiento e InnovaciÃ³n, con la Encuesta Nacional de InnovaciÃ³n.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de EconomÃ­a, con encuestas y bases orientadas a la actividad econÃ³mica.\nBanco Central de Chile, a travÃ©s de su sistema SIETE.\n\nAdemÃ¡s, se proyecta integrar informaciÃ³n de ODEPA, INDAP y otros organismos pÃºblicos vinculados al Ã¡mbito econÃ³mico y agrÃ­cola."
  },
  {
    "objectID": "datos.html#datos",
    "href": "datos.html#datos",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reÃºnen diversas fuentes de informaciÃ³n estadÃ­stica y bases de datos relevantes para el anÃ¡lisis econÃ³mico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio Ãºnico y accesible, desde el cual puedan explorar y trabajar con informaciÃ³n oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a travÃ©s del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interÃ©s.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisiÃ³n universitaria (PSU, PAES, etc.).\nMinisterio de EducaciÃ³n (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadÃ­sticas comparables a nivel internacional.\nMinisterio de Ciencia, TecnologÃ­a, Conocimiento e InnovaciÃ³n, con la Encuesta Nacional de InnovaciÃ³n.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de EconomÃ­a, con encuestas y bases orientadas a la actividad econÃ³mica.\nBanco Central de Chile, a travÃ©s de su sistema SIETE.\n\nAdemÃ¡s, se proyecta integrar informaciÃ³n de ODEPA, INDAP y otros organismos pÃºblicos vinculados al Ã¡mbito econÃ³mico y agrÃ­cola."
  },
  {
    "objectID": "datos.html#tabla-de-bases-de-datos",
    "href": "datos.html#tabla-de-bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Tabla de bases de datos",
    "text": "Tabla de bases de datos\nDebajo encontrarÃ¡s una tabla interactiva que contiene la siguiente informaciÃ³n para cada base:\n\nAÃ±os: periodo temporal cubierto.\nSiglas: abreviaciÃ³n con la que se conoce la encuesta o base.\nNombre de la base: denominaciÃ³n oficial de la fuente de datos.\nEnlace: acceso directo al sitio web o repositorio correspondiente.\nDescripciÃ³n: breve explicaciÃ³n del contenido y posibles usos de la base."
  },
  {
    "objectID": "datos.html#buscador",
    "href": "datos.html#buscador",
    "title": "Repositorio de Datos",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (â€œsearchâ€) que facilita la exploraciÃ³n, que funciona a nivel de palabras claves, por ejemplo, si se escribe â€œeconomÃ­aâ€, el sistema buscarÃ¡ esa palabra en todas las columnas de la tabla (aÃ±os, siglas, nombre, enlace y descripciÃ³n). Esto permite filtrar de manera rÃ¡pida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "datos.html#bases-de-datos",
    "href": "datos.html#bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Bases de Datos",
    "text": "Bases de Datos"
  },
  {
    "objectID": "index.html#descripciÃ³n-del-sitio-web",
    "href": "index.html#descripciÃ³n-del-sitio-web",
    "title": "",
    "section": "DescripciÃ³n del Sitio Web",
    "text": "DescripciÃ³n del Sitio Web\nEste sitio web es una iniciativa conjunta de los profesores Fernando Crespo y RocÃ­o Valdebenito, docentes de la Facultad de EconomÃ­a y Negocios de la Universidad Alberto Hurtado (UAH). EstÃ¡ dirigido a los estudiantes de la carrera de IngenierÃ­a Comercial, con menciÃ³n en EconomÃ­a y AdministraciÃ³n de Empresas, que cursan las asignaturas de EconometrÃ­a.\nEl objetivo principal de estos cursos es que los estudiantes se familiaricen con el uso de bases de datos y aprendan a utilizar el software R y Rstudio como herramienta para analizar y responder preguntas de investigaciÃ³n. Como parte fundamental del aprendizaje, los estudiantes desarrollan un proyecto aplicado, el cual es presentado en formato de pÃ³ster y expuesto frente a la comunidad acadÃ©mica.\nPara acompaÃ±ar este proceso, el sitio web se organiza en tres secciones principales:\n\nDatos:\nEspacio donde se recopilan bases de datos que pueden ser utilizadas en proyectos de investigacion con metodologÃ­as econometricas. Cada base de datos incluye enlaces de acceso o descarga, asÃ­ como una breve descripciÃ³n de su contenido y posibles aplicaciones.\n\n\nMaterial de Estudio:\n\nUna secciÃ³n de apoyo que ofrece cÃ³digos en Rstudio, apuntes de econometrÃ­a y laboratorios, que abarcan desde operaciones bÃ¡sicas en R (como crear variables, realizar estadÃ­stica descriptiva y generar tablas) hasta la elaboraciÃ³n de grÃ¡ficos y anÃ¡lisis mÃ¡s avanzados. Esta secciÃ³n busca ser un recurso de referencia constante para los estudiantes.\n\n\nProyectos:\n\nEspacio dedicado a la difusiÃ³n de los trabajos de los estudiantes, donde se podrÃ¡n visualizar sus pÃ³sters y presentaciones, sirviendo como inspiraciÃ³n y guÃ­a para generaciones futuras.\nEn conjunto, este sitio busca convertirse en un centro de recursos para la formaciÃ³n en econometrÃ­a, promoviendo el uso de datos y herramientas de anÃ¡lisis como competencias clave para la futura labor profesional de los estudiantes de IngenierÃ­a Comercial de la UAH."
  },
  {
    "objectID": "index.html#docentes",
    "href": "index.html#docentes",
    "title": "",
    "section": "Docentes",
    "text": "Docentes\nExplora las secciones usando la barra de navegaciÃ³n o haciendo clic en los tÃ­tulos anteriores."
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Material de Estudio",
    "section": "",
    "text": "Bienvenido al Repositorio de Laboratorios y Materiales PrÃ¡cticos del curso de EconometrÃ­a FEN-UAH.\nAquÃ­ encontrarÃ¡s guÃ­as paso a paso en Rstudio respaldadas con teoria y conceptos escenciales para el curso que acompaÃ±an el aprendizaje aplicado de la econometrÃ­a, desde regresiÃ³n simple hasta modelos avanzados.\nCada laboratorio se puede abrir directamente en formato HTML renderizado desde RStudio/Quarto.\nLos documentos que contengan las siglas â€œepgâ€ corresponden al curso EconometrÃ­a para la GestiÃ³n, mientras que los â€œecâ€ pertenecen a EconometrÃ­a (menciÃ³n EconomÃ­a).\n\n\n\n\n\nImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresiÃ³n mÃºltiple, EliminaciÃ³n de variables irrelevantes, RegresiÃ³n polinomial, etc.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n de logit y probit.\nVer Laboratorio\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "proyectos.html#recopilaciÃ³n-de-proyectos-1",
    "href": "proyectos.html#recopilaciÃ³n-de-proyectos-1",
    "title": "Proyectos",
    "section": "RecopilaciÃ³n de proyectos",
    "text": "RecopilaciÃ³n de proyectos\nLa secciÃ³n Proyectos tiene como propÃ³sito ofrecer un espacio para que los estudiantes de la Facultad de EconomÃ­a y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de EconometrÃ­a y EconometrÃ­a para la GestiÃ³n.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicaciÃ³n prÃ¡ctica de los contenidos del curso y el fortalecimiento de las habilidades analÃ­ticas y comunicacionales de los futuros profesionales."
  },
  {
    "objectID": "proyectos.html#subir-tu-proyecto-1",
    "href": "proyectos.html#subir-tu-proyecto-1",
    "title": "Proyectos",
    "section": "Subir tu proyecto",
    "text": "Subir tu proyecto\nSi eres estudiante de los cursos de EconometrÃ­a o EconometrÃ­a para la GestiÃ³n, puedes subir tu proyecto de investigaciÃ³n (formato PDF, QMD o ZIP).\nEn caso de que debas subir mÃ¡s de un archivo, comprÃ­melos en una sola carpeta y sÃºbela en formato .zip.\nLos archivos se almacenarÃ¡n automÃ¡ticamente en el repositorio fen-uah/lab-econometria, dentro de la carpeta /uploads.\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "codigos.html#laboratorios-de-econometrÃ­a",
    "href": "codigos.html#laboratorios-de-econometrÃ­a",
    "title": "Material de Estudio",
    "section": "",
    "text": "Cada laboratorio se puede abrir directamente en formato HTML renderizado desde RStudio/Quarto.\nLos documentos que contengan las siglas â€œepgâ€ corresponden al curso EconometrÃ­a para la GestiÃ³n, mientras que los â€œecâ€ pertenecen a EconometrÃ­a (menciÃ³n EconomÃ­a).\n\n\n\nImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nDiagnÃ³stico y correcciÃ³n de problemas comunes en OLS.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n prÃ¡ctica en R.\nVer Laboratorio\n\n\n\nModelaciÃ³n de variables dependientes binarias.\nVer Laboratorio\n\n\n\nModelos de efectos fijos y aleatorios con R.\nVer Laboratorio\n\n\n\nEvaluaciÃ³n de polÃ­ticas pÃºblicas y experimentos naturales.\nVer Laboratorio\n\n\n\nDiseÃ±os RD y RD local en contextos aplicados.\nVer Laboratorio\n\n\n\nIV con heterogeneidad y dos etapas en R.\nVer Laboratorio\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "labs/lab01_epg.html",
    "href": "labs/lab01_epg.html",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2023) para el curso EconometrÃ­a para la GestiÃ³n â€” FEN-UAH."
  },
  {
    "objectID": "labs/lab01_epg.html#laboratorios-de-econometrÃ­a",
    "href": "labs/lab01_epg.html#laboratorios-de-econometrÃ­a",
    "title": "Material de Estudio",
    "section": "",
    "text": "Cada laboratorio se puede abrir directamente en formato HTML renderizado desde RStudio/Quarto.\nLos documentos que contengan las siglas â€œepgâ€ corresponden al curso EconometrÃ­a para la GestiÃ³n, mientras que los â€œecâ€ pertenecen a EconometrÃ­a (menciÃ³n EconomÃ­a).\n\n\n\nImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nDiagnÃ³stico y correcciÃ³n de problemas comunes en OLS.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n prÃ¡ctica en R.\nVer Laboratorio\n\n\n\nModelaciÃ³n de variables dependientes binarias.\nVer Laboratorio\n\n\n\nModelos de efectos fijos y aleatorios con R.\nVer Laboratorio\n\n\n\nEvaluaciÃ³n de polÃ­ticas pÃºblicas y experimentos naturales.\nVer Laboratorio\n\n\n\nDiseÃ±os RD y RD local en contextos aplicados.\nVer Laboratorio\n\n\n\nIV con heterogeneidad y dos etapas en R.\nVer Laboratorio\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML."
  },
  {
    "objectID": "labs/lab01_epg.html#preparaciÃ³n-del-entorno",
    "href": "labs/lab01_epg.html#preparaciÃ³n-del-entorno",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "1 1) PreparaciÃ³n del entorno",
    "text": "1 1) PreparaciÃ³n del entorno\n\n# Definir ruta absoluta de los datos\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# Comprobar existencia de archivos\nif (!file.exists(file.path(data_path, \"Ejemplo1.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'Ejemplo1.xlsx'. Verifica la ruta.\")\n}\nif (!file.exists(file.path(data_path, \"tabla_ejemplo_R.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'tabla_ejemplo_R.xlsx'. Verifica la ruta.\")\n}\n\n# Cargar librerÃ­as necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"psych\",\"moments\",\"qcc\",\"modeest\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(psych)\nlibrary(moments)\nlibrary(qcc)\nlibrary(modeest)"
  },
  {
    "objectID": "labs/lab01_epg.html#tablas-de-frecuencia-datos-cualitativos",
    "href": "labs/lab01_epg.html#tablas-de-frecuencia-datos-cualitativos",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "2 2) Tablas de frecuencia (datos cualitativos)",
    "text": "2 2) Tablas de frecuencia (datos cualitativos)\nSea una variable categÃ³rica ( X ) con categorÃ­as ( x_1, x_2, , x_k ).\nLa frecuencia absoluta es ( f_i ) y la frecuencia relativa se define como\n( r_i = ).\n\n# Cargar datos cualitativos\nej1 &lt;- read.xlsx(file.path(data_path, \"Ejemplo1.xlsx\"), sheet = 1, colNames = TRUE)\n\n# Calcular frecuencias relativas y porcentajes\ntotal &lt;- sum(ej1$Frecuencia, na.rm = TRUE)\nej1 &lt;- ej1 |&gt;\n  mutate(Relativa = Frecuencia / total,\n         Porcentaje = 100 * Relativa)\nej1\n\n                  Categoria Frecuencia Acumulado   Relativa Porcentaje\n1          Explosion de Gas         28        28 0.62222222  62.222222\n2 Colapso de mina de carbon          7        35 0.15555556  15.555556\n3             Falla Represa          4        39 0.08888889   8.888889\n4      Incendio Combustible          4        43 0.08888889   8.888889\n5        Descarga electrica          1        44 0.02222222   2.222222\n6           Reactor Nuclear          1        45 0.02222222   2.222222\n\n\n\n2.1 2.1) VisualizaciÃ³n grÃ¡fica\n\n# GrÃ¡fico de barras\nggplot(ej1, aes(x = reorder(Categoria, -Frecuencia), y = Frecuencia)) +\n  geom_col(fill = \"#2b9348\") +\n  labs(title = \"DistribuciÃ³n de CategorÃ­as\",\n       x = \"CategorÃ­a\", y = \"Frecuencia\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# GrÃ¡fico de Pareto\nqcc::pareto.chart(ej1$Frecuencia, names = ej1$Categoria,\n                  main = \"GrÃ¡fico de Pareto por categorÃ­a\")\n\n\n\n\n\n\n\n\n   \nPareto chart analysis for ej1$Frecuencia\n     Frequency  Cum.Freq. Percentage Cum.Percent.\n  A  28.000000  28.000000  62.222222    62.222222\n  B   7.000000  35.000000  15.555556    77.777778\n  C   4.000000  39.000000   8.888889    86.666667\n  D   4.000000  43.000000   8.888889    95.555556\n  E   1.000000  44.000000   2.222222    97.777778\n  F   1.000000  45.000000   2.222222   100.000000"
  },
  {
    "objectID": "labs/lab01_epg.html#medidas-de-tendencia-central-y-dispersiÃ³n",
    "href": "labs/lab01_epg.html#medidas-de-tendencia-central-y-dispersiÃ³n",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "3 3) Medidas de tendencia central y dispersiÃ³n",
    "text": "3 3) Medidas de tendencia central y dispersiÃ³n\nPara una variable numÃ©rica ( X = (x_1, , x_n) ):\n\nMedia: ( {X} = _{i=1}^n x_i )\n\nMediana: valor central\n\nModa: valor mÃ¡s frecuente\n\nVarianza: ( s^2 = )\n\nDesviaciÃ³n estÃ¡ndar: ( s = )\n\n\n# Cargar datos numÃ©ricos\ndatos &lt;- read.xlsx(file.path(data_path, \"tabla_ejemplo_R.xlsx\"), sheet = 1, colNames = TRUE)\n\nx &lt;- datos$Precio\n\nmedia   &lt;- mean(x, na.rm = TRUE)\nmediana &lt;- median(x, na.rm = TRUE)\nmoda    &lt;- modeest::mlv(x, method = \"mfv\", na.rm = TRUE)\nrango   &lt;- diff(range(x, na.rm = TRUE))\nvar_x   &lt;- var(x, na.rm = TRUE)\nsd_x    &lt;- sd(x, na.rm = TRUE)\niqr_x   &lt;- IQR(x, na.rm = TRUE)\n\ntibble(Media = media, Mediana = mediana, Moda = moda,\n       Rango = rango, Varianza = var_x, `Desv.Est` = sd_x, IQR = iqr_x)\n\n# A tibble: 1 Ã— 7\n  Media Mediana  Moda Rango Varianza Desv.Est   IQR\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1   179     162   200   325    8805.     93.8    95\n\n\n\n3.1 3.1) Resumen con psych::describe()\n\npsych::describe(x)\n\n   vars  n mean    sd median trimmed   mad min max range skew kurtosis    se\nX1    1 16  179 93.84    162  170.64 74.13  75 400   325 0.92    -0.25 23.46"
  },
  {
    "objectID": "labs/lab01_epg.html#distribuciones-y-normalidad",
    "href": "labs/lab01_epg.html#distribuciones-y-normalidad",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "4 4) Distribuciones y normalidad",
    "text": "4 4) Distribuciones y normalidad\nUna variable normalmente distribuida sigue ( X N(, ^2) ).\nEl histograma permite comparar la densidad empÃ­rica con la normal teÃ³rica.\n\nhist(x, breaks = \"FD\", probability = TRUE,\n     main = \"Histograma con densidad\",\n     xlab = \"Variable X\", col = \"#cdeac0\", border = \"#2b9348\")\nlines(density(x, na.rm = TRUE))\ncurve(dnorm(x, mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)),\n      add = TRUE, col = \"red\")\n\n\n\n\n\n\n\nqqnorm(x)\nqqline(x, col = \"red\")"
  },
  {
    "objectID": "labs/lab01_epg.html#asimetrÃ­a-y-curtosis",
    "href": "labs/lab01_epg.html#asimetrÃ­a-y-curtosis",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "5 5) AsimetrÃ­a y curtosis",
    "text": "5 5) AsimetrÃ­a y curtosis\n\nAsimetrÃ­a (Î³â‚):\n( _1 = )\nCurtosis (Î²â‚‚):\n( _2 = )\n\n\nskew &lt;- moments::skewness(x, na.rm = TRUE)\nkurt &lt;- moments::kurtosis(x, na.rm = TRUE)\ntibble(AsimetrÃ­a = skew, Curtosis = kurt)\n\n# A tibble: 1 Ã— 2\n  AsimetrÃ­a Curtosis\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      1.01     3.13\n\n\n\nInterpretaciÃ³n: - Si Î³â‚ &gt; 0 â†’ cola derecha (asimetrÃ­a positiva).\n- Si Î³â‚ &lt; 0 â†’ cola izquierda (asimetrÃ­a negativa).\n- Î²â‚‚ &gt; 3 â†’ leptocÃºrtica (colas pesadas).\n- Î²â‚‚ = 3 â†’ mesocÃºrtica (normal).\n- Î²â‚‚ &lt; 3 â†’ platicÃºrtica (colas ligeras)."
  },
  {
    "objectID": "labs/lab01_epg.html#cuantiles-y-posiciÃ³n-relativa",
    "href": "labs/lab01_epg.html#cuantiles-y-posiciÃ³n-relativa",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "6 6) Cuantiles y posiciÃ³n relativa",
    "text": "6 6) Cuantiles y posiciÃ³n relativa\nUn z-score mide cuÃ¡ntas desviaciones estÃ¡ndar separan un valor ( x_i ) de la media:\n[ z_i = ]\ny los cuantiles teÃ³ricos de una normal se calculan como:\n[ q_p = + z_p ]\n\nz_075 &lt;- mean(x, na.rm = TRUE) + qnorm(0.75) * sd(x, na.rm = TRUE)\nz_025 &lt;- mean(x, na.rm = TRUE) + qnorm(0.25) * sd(x, na.rm = TRUE)\nc(Q25 = z_025, Q75 = z_075)\n\n     Q25      Q75 \n115.7081 242.2919"
  },
  {
    "objectID": "labs/lab01_epg.html#relaciÃ³n-entre-dos-variables-opcional",
    "href": "labs/lab01_epg.html#relaciÃ³n-entre-dos-variables-opcional",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "7 7) RelaciÃ³n entre dos variables (opcional)",
    "text": "7 7) RelaciÃ³n entre dos variables (opcional)\n\nplot(datos$Superficie, datos$Antiguedad,\n     main = \"Diagrama de DispersiÃ³n\",\n     xlab = \"Superficie\", ylab = \"AntigÃ¼edad\",\n     col = \"#2b9348\", pch = 19)"
  },
  {
    "objectID": "labs/lab01_epg.html#glosario",
    "href": "labs/lab01_epg.html#glosario",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "8 8) Glosario",
    "text": "8 8) Glosario\n\n\n\nConcepto\nDefiniciÃ³n\n\n\n\n\nFrecuencia relativa\n( f_i / n )\n\n\nMedia\n( {x} = x_i )\n\n\nMediana\nValor central ordenado\n\n\nModa\nValor mÃ¡s frecuente\n\n\nVarianza\n( s^2 = )\n\n\nDesv. EstÃ¡ndar\n( s = )\n\n\nAsimetrÃ­a (Î³â‚)\nSimetrÃ­a de la distribuciÃ³n\n\n\nCurtosis (Î²â‚‚)\nApuntamiento o achatamiento\n\n\nIQR\n( Q_3 - Q_1 )\n\n\nRango\n( x_{max} - x_{min} )\n\n\n\n\n\nCrÃ©ditos: Adaptado de CapÃ­tulo 1 â€” IntroducciÃ³n y EstadÃ­stica Descriptiva (Prof.Â Fernando Crespo, 2023)."
  },
  {
    "objectID": "proyectos.html#section",
    "href": "proyectos.html#section",
    "title": "Proyectos",
    "section": "",
    "text": "La secciÃ³n Proyectos tiene como propÃ³sito ofrecer un espacio para que los estudiantes de la Facultad de EconomÃ­a y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de EconometrÃ­a y EconometrÃ­a para la GestiÃ³n.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicaciÃ³n prÃ¡ctica de los contenidos del curso y el fortalecimiento de las habilidades analÃ­ticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "labs/lab01_epg.html#teorÃ­a-texto-original",
    "href": "labs/lab01_epg.html#teorÃ­a-texto-original",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "1 TeorÃ­a (texto original)",
    "text": "1 TeorÃ­a (texto original)\nCap Â´ Ä±tulo 1: IntroducciÂ´ on y EstadÂ´ Ä±stica Descriptiva Fernando A. Crespo R. 3 de Agosto de 2023\nÂ´Indice 1.1 IntroducciÂ´ on 1.1.1 DefiniciÂ´ on y tÂ´ erminos bÂ´ asicos de la estadÂ´ Ä±stica 1.2 Elementos Fundamentales de EstadÂ´ Ä±stica 1.3 Tipos de Datos 1.4 EstadÂ´ Ä±stica Descriptiva 1.4.1 MÂ´ etodos GrÂ´ aficos y NÂ´ umericos para Describir Datos Cualitativos 1.4.2 MÂ´ etodos GrÂ´ aficos para Describir Datos Cuantitativos 1.4.3 MÂ´ etodos NÂ´ umericos para Describir Datos Cuantitativos 1.4.4 Medidas de Tendencia Central 1.4.5 Medidas de VariaciÂ´ on 1.4.6 Medidas de PosiciÂ´ on Relativa 1.4.7 Medidas de AsimetrÂ´ Ä±a 1.4.8 Medidas de ConcentraciÂ´ on de Datos 1.1.1 DefiniciÂ´ on y tÂ´ erminos bÂ´ asicos de la estad Â´ Ä±stica â–¶La estadÂ´ Ä±stica es la ciencia de los datos. â–¶La estadÂ´ Ä±stica es aplicada comÂ´ unmente a dos tipos de problemas: â–¶Resumir, describir y explorar datos. â–¶Ejemplo: Resultados del censo. â–¶Usando muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada. â–¶Ejemplo: Cuando se estudia la sobrevida de las personas para calcular el valor de la prima de un seguro de vida. DefiniciÂ´ on (Ramas de Estudio de la Estad Â´ Ä±stica) Las Â´ areas que estudian las diferentes problemÂ´ aticas de la estadÂ´ Ä±stica se reconocen como: â–¶â–¶La rama que se dedica a resumir, describir y explorar datos se denomina estadÂ´ Ä±stica descriptiva. â–¶La rama que se decida a usar muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada, se denomina estadÂ´ Ä±stica inferencial. 1.1.1 DefiniciÂ´ on y tÂ´ erminos bÂ´ asicos de la estad Â´ Ä±stica â–¶Todo ello con el fin de comprender la variablidad. â–¶Se desarrolla el pensamiento estadÂ´ Ä±stico con el fin de poder enfrentar la variabilidad. â–¶Esa variabilidad, puede provenir de: â–¶desde los distintos factores que influyen en un fenÂ´ omeno: por ejemplo, pensemos en la mediciÂ´ on del rendimiento de [km/l] del automÂ´ ovil. â–¶Puede ser implÂ´ Ä±cita, porque las variables no se pueden medir de manera precisa, o el fenÂ´ omeno tiene variabilidad. Por ejemplo: Genes, medidas atÂ´ omicas. â–¶La estadÂ´ Ä±stica en conjunto con el mÂ´ etodo cientÂ´ Ä±fico permite crear modelos coherentes capaces de soportar la variabilidad de los fenÂ´ omenos. 1.2 Elementos Fundamentales de Estad Â´ Ä±stica â–¶Una poblaciÂ´ on estadÂ´ Ä±stica es un conjunto de datos (usualmente grande, otras veces conceptual) que es el objetivo de interÂ´ es. â–¶Una muestra (sample) es un subconjunto de datos seleccionados de la poblaciÂ´ on objetivo. â–¶El objeto (ie persona, cosa, transacciÂ´ on, espÂ´ ecimen, evento, u otra construcciÂ´ on) sobre el cual se observan las medidas se denomina unidad experimental. Una poblaciÂ´ on puede considerarse como datos recolectados sobre muchas unidades experimentales. â–¶Una variable es una caracterÂ´ Ä±stica o propiedad de una unidad experimental individual. â–¶Ejemplo: Un estudio que desea observar las esquinas que tienen mÂ´ as accidentes de la comuna de Santiago. â–¶Una inferencia es una afirmaciÂ´ on sustentada a partir de los datos. â–¶En un problema de inferencia estadÂ´ Ä±stica se puede indentificar cuatro puntos: una poblaciÂ´ on, una o mÂ´ as variables, una muestra, y una inferencia. Hay que aËœ nadir la confiabilidad de la inferencia, es decir, una medida que nos diga cuan verdadera es la inferencia. â–¶Una medida de confiabilidad es una declaraciÂ´ on (cuantificada) acerca del grado de incerteza asociada a una inferencia estadÂ´ Ä±stica. 1.2 Elementos Fundamentales de Estad Â´ Ä±stica â–¶Cuatro elementos de Problemas de EstadÂ´ Ä±stica Descriptiva: â–¶La poblaciÂ´ on o muestra de interÂ´ es. â–¶Una o mÂ´ as variables que son investigadas. â–¶Tablas, grÂ´ aficos, o herramientas de resumen nÂ´ umerico. â–¶Cuatro elementos de Problemas de Inferencia EstadÂ´ Ä±stica: â–¶La poblaciÂ´ on de interÂ´ es. â–¶Una o mÂ´ as variables que son investigadas. â–¶La muestra de unidades experimentales. â–¶La inferencia acerca de la poblaciÂ´ on basada en la informaciÂ´ on contenida en la muestra. â–¶Una medida de confiabilidad para la inferencia. 1.3 Tipos de Datos â–¶Datos Cuantitativos son los que representan cantidades de algo, medidos en una escala nÂ´ umerica. â–¶Datos Cualitativos no poseen interpretaciÂ´ on cuantitativa. SÂ´ olo pueden ser clasificados. Ejemplo: Los ntrabajos que realizan n graduados de ingenierÂ´ Ä±a despuÂ´ es de un aËœ no. La clasificaciÂ´ on de los estratos econÂ´ omicos, es cualitativa pero ordinal, sabemos que a mayor nÂ´ umero mayor ingreso. â–¶La herramienta estadÂ´ Ä±stica propiamente tal, usada para describir y analizar datos, dependerÂ´ a del tipo de dato. De ahÂ´ Ä± la importancia de si es cuantitativo o cualitativo. 1.4 EstadÂ´ Ä±stica Descriptiva â–¶El objetivo es presentar mÂ´ etodos grÂ´ aficos y nÂ´ umericos para explorar, resumir, y describir datos. 1.4.1 MÂ´ etodos GrÂ´ aficos y NÂ´ umericos para Describir Datos Cualitativos â–¶Asumiendo que tenemos un conjunto de datos reunidos de interÂ´ es para uno, Â¿Como podemos darle sentido? Â¿CÂ´ omo podemos organizarlos de tal forma que sean mÂ´ as comprensibles y significativos? â–¶La respuesta depende de los datos. â–¶Cuando es cualitativo se grupa en categorÂ´ Ä±as. â–¶La frecuencia de categorÂ´ Ä±a (o clases) para una categorÂ´ Ä±a dada es el nÂ´ umero de observaciones que cuentan en esa categorÂ´ Ä±a. â–¶La frecuencia relativa de la categorÂ´ Ä±a (o clase) para una categorÂ´ Ä±a dada es la proporciÂ´ on de el nÂ´ umero total de observaciones que cuentan en esa categorÂ´ Ä±a. â–¶Ejemplo 1: InvestigaciÂ´ on de seguridad de reactores nucleares y el riesgo de uso de distintas fuentes de energÂ´ Ä±a. Accidentes observados desde 1977, publicado en â€Safety of nuclear power reactorsâ€. Nuclear Issues Briefing Paper 14, November 2004. 1.4.1 MÂ´ etodos GrÂ´ aficos y NÂ´ umericos para Describir Datos Cualitativos â–¶El grÂ´ afico de barras da la frecuencia (o frecuencia relativa) para cada categorÂ´ Ä±a donde el largo de la barra es proporcional a la frecuencia (o frecuencia relativa) de la categorÂ´ Ä±a. â–¶El grÂ´ afico de tortas divide un cÂ´ Ä±rculo completo en trozos, uno para cada categorÂ´ Ä±a, donde el Â´ angulo es proporcional la frecuencia (o frecuencia relativa) para cada categorÂ´ Ä±a donde el largo de la barra es proporcional a la frecuencia (o frecuencia relativa) de la categorÂ´ Ä±a. â–¶El diagrama de Pareto (en honor a Vilfredo Pareto un economista italiano) es un grÂ´ afico de barras de frecuencias, desplegadas en orden descendente. Es muy usado en control de procesos y calidad, con la primera categorÂ´ Ä±a indicando la mayor falla, etc. La acumulaciÂ´ on (denominada lÂ´ Ä±nea de acumulaciÂ´ on) es graficada con una lÂ´ Ä±nea impuesta sobre las barras. 1.4.2 MÂ´ etodos GrÂ´ aficos para Describir Datos Cuantitativos â–¶Los datos cuantitativos son grabados en escalas nÂ´ umericas significativas. â–¶Hay mÂ´ etodos grÂ´ aficos de punto, despliegue stem-and-leaf (tallos y hojas), e histogramas. Los primeros dos ya no se usan, por razones de potencia grÂ´ afica y de cÂ´ alculo computacional. â–¶Ejemplo 2: Datos de rendimiento de los nuevos vehÂ´ Ä±culos medidos en millas por galÂ´ on, recolectados por la Environmental Protection Agency (EPA). â–¶El histograma es un grÂ´ afico que se construye de partir de generar intervalos de clases para los cuales contamos la frecuencia de datos observados que caen en los distintos intervalos de clases. â–¶Desventaja, no muestra el valor de las medidas individuales, por ejemplo, el hecho que se repita un punto. 1.4.2 MÂ´ etodos GrÂ´ aficos para Describir Datos Cuantitativos â–¶Pasos a seguir para construir un histograma: 1. CÂ´ alculo del rango de los datos: rango = mÂ´ aximo dato observado - mÂ´ Ä±nimo dato observado. 2. Divida el rango entre 5 a 20 clases de igual ancho. El valor mÂ´ as bajo va primero. 3. Por cada clase, se cuenta el nÂ´ umero de observaciones en esa clase. Ello es denominado la frecuencia de la clase. 4. Calcular cada frecuencia relativa de clase: Frecuencia relativa de clase =Frecuencia de clase NÂ´ umero total de medidas. 5. El histograma es un grÂ´ afico de barras en el cual las categorÂ´ Ä±as son conjunto. Si es un histograma de frecuencia, las alturas son determinadas por la frecuencia de clases. Y en un histograma de frecuencia relativa de clase, las alturas de las barras son determinadas por la frecuencia relativa de clase. 1.4.2 MÂ´ etodos GrÂ´ aficos para Describir Datos Cuantitativos â–¶Otro grÂ´ afico, es el grÂ´ afico de densidad, donde se grÂ´ afica la distribuciÂ´ on de probabilidad de los datos. 1.4.3 MÂ´ etodos NÂ´ umericos para Describir Datos Cuantitativos â–¶Las medidas descriptivas nÂ´ umericas son valores calculados desde los datos, y nos ayuda a crear una imagen mental de su histograma de frecuencias relativas. â–¶Las medidas a presentar estÂ´ an en tres categorÂ´ Ä±as: 1. Las que ayudan a localizar el centro de la distribuciÂ´ on de las frecuencias relativas. 2. Las que miden la dispersiÂ´ on alrededor del centro. 3. Las que miden la posiciÂ´ on relativa de una observaciÂ´ on dentro del conjunto de datos. â–¶Una estadÂ´ Ä±stica es una medida numÂ´ erica calculada desde la muestra de datos. â–¶Un parÂ´ ametro es una medida numÂ´ erica descriptiva de una poblaciÂ´ on, generalmente notada con sÂ´ Ä±mbolos griegos. 1.4.4 Medidas de Tendencia Central â–¶La media aritmÂ´ etica de un conjunto de nmedidas, x1, . . . , xn, es el promedio de las medidas: Â¯xn=nP i=1xi n, (1) tambiÂ´ en se denomina media muestral, como la media de una muestra de nmedidas. â–¶La mediana de un conjunto de nmedidas, x1, . . . , xn, es el nÂ´ umero medio cuando las medidas son arregladas en orden ascendente (o descendente), i.e, el valor de xlocalizado a la mitad del Â´ area bajo el histograma de frecuencia relativa que tiene lugar a su izquierda y la mitad del Â´ area que tiene lugar a su derecha. Se usa el sÂ´ Ä±mbolo m para representar la mediana de la muestra, y Ï„para representar la mediana de la poblaciÂ´ on. Six(i)denota el i-Â´ esimo valor de la muestra cuando esta ordenada en orden ascendente. La mediana de la muestra es calculada como sigue: m=(xâŒŠ(n+1) 2âŒ‹sines impar x(n 2)+x(n 2+1) 2sines par. (2) tambiÂ´ en se denomina media muestral, como la media de una muestra de nmedidas. 1.4.4 Medidas de Tendencia Central â–¶La moda de un conjunto de nmedidas, y1, . . . , yn, es el valor de x que ocurre con mayor frecuencia. â–¶La media es la medida preferida de tendencia central, pero no dice nada respecto de la asÂ´ Ä±metria (skewness) (la cola de la distribuciÂ´ on). â–¶La mediana es denominada una medida de resistencia de la tendencia central, ya que la media, es resistente a las influencias de observaciones extremas. â–¶La moda sÂ´ olo es importante si la frecuencia relativa de xes de interÂ´ es. 1.4.5 Medidas de VariaciÂ´ on â–¶Las medidas de variaciÂ´ on mÂ´ as usadas son el rango, la varianza y la desviaciÂ´ on estÂ´ andar. â–¶El rango es igual a la diferencia entre la mayor y la menor medida en un conjunto de datos: rango = mÂ´ aximo dato observado - mÂ´ Ä±nimo dato observado. (3) â–¶La varianza de una muestra de nmedidas, x1, . . . , xn, es definida como: s2 n=nP i=1(xiâˆ’Â¯xn)2 nâˆ’1=nP i=1x2 iâˆ’nÂ¯x2 n nâˆ’1, (4) La varianza de una poblaciÂ´ on finita con nmedidas es definida como: Ïƒ2=nP i=1(xiâˆ’Âµ)2 nâˆ’1. (5) 1.4.5 Medidas de VariaciÂ´ on â–¶La desviaciÂ´ on estÂ´ andar de una muestra de nmedidas es igual a la raÂ´ Ä±z de la varianza: sn=p s2n=vuuutnP i=1(xiâˆ’Â¯xn)2 nâˆ’1, (6) La desviaciÂ´ on estÂ´ andar de una poblaciÂ´ on es: Ïƒ=âˆš Ïƒ2. (7) â–¶Ver Ejemplo 2, varianza. 1.4.6 Medidas de PosiciÂ´ on Relativa â–¶Las medidas de PosiciÂ´ on Relativa de una observaciÂ´ on son los percentiles y los z-scores, e indican la localizaciÂ´ on de una observaciÂ´ on relativa respecto a otros puntos en la distribuciÂ´ on. â–¶El percentil 100 pâ—¦de un conjunto es un valor de xlocalizado tal que el 100 p% de el Â´ area bajo la distribuciÂ´ on de frecuencia relativa para los datos estÂ´ a contenida a la izquierda de el 100 pâ—¦percentil y 100(1âˆ’p)% del Â´ area estÂ´ a contenida a su derecha. (Notar que 0â‰¤pâ‰¤1.) â–¶El cuartil mÂ´ as bajo, QL, para un conjunto de datos es el percentil 25â—¦. â–¶El cuartil medio o mediana, m, para un conjunto de datos es el percentil 50â—¦. â–¶El cuartil superior, QU, para un conjunto de datos es el percentil 75â—¦. 1.4.6 Medidas de PosiciÂ´ on Relativa â–¶Pasos a seguir para construir cuartiles: 1. Ordene los datos de menor a mayor. Sean x(1), . . . , x(n)los datos ordenados. 2. CÂ´ alcule la cantidad l=1 4(n+ 1) y redondeÂ´ e al entero mÂ´ as cercano. La medida con este rango, x(l), representa el cuartil mÂ´ as bajo o percentil 25â—¦. 3. CÂ´ alcule la cantidad u=3 4(n+ 1) y redondeÂ´ e al entero mÂ´ as cercano. La medida con este rango, x(u), representa el cuartil mÂ´ as alto o percentil 75â—¦. â–¶Ver ejemplo 2. 1.4.6 Medidas de PosiciÂ´ on Relativa â–¶El z-scores para un valor xdel conjunto de datos es la distancia de x sobre o bajo la media, en unidades de la desviaciÂ´ on estÂ´ andar: z-cores muestra =xâˆ’Â¯xn sn, (8) z-cores poblaciÂ´ on =xâˆ’Âµ Ïƒ. (9) 1.4.7 Medidas de AsimetrÂ´ Ä±a â–¶Skewness o Coeficiente de asimetrÂ´ Ä±a de Fisher: Î³1=IEâ€\u0012Xâˆ’Âµ Ïƒ\u00133# =Âµ3 Ïƒ3. (10) â–¶SiÎ³1&gt;0, la distribuciÂ´ on es asimÂ´ etrica positiva o a la derecha. â–¶SiÎ³1&lt;0, la distribuciÂ´ on es asimÂ´ etrica negativa o a la izquierda. 1.4.8 Medidas de ConcentraciÂ´ on de Datos â–¶Curtosis o Kurtosis: Î²2=IEâ€\u0012Xâˆ’Âµ Ïƒ\u00134# =Âµ4 Ïƒ4. (11) â–¶SiÎ²2&gt;3, la distribuciÂ´ on es mÂ´ as apuntada y con colas mÂ´ as gruesas que la normal. â–¶SiÎ²2&lt;3, la distribuciÂ´ on es menos apuntadas y con colas menos gruesas que la normal. â–¶SiÎ²2= 3, la distribuciÂ´ on es normal."
  },
  {
    "objectID": "labs/lab01_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab01_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "5 AplicaciÃ³n en R (sobre los contenidos anteriores)",
    "text": "5 AplicaciÃ³n en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (segÃºn tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# VerificaciÃ³n\nif (!file.exists(file.path(data_path, \"Ejemplo1.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'Ejemplo1.xlsx' en data_path\")\n}\nif (!file.exists(file.path(data_path, \"tabla_ejemplo_R.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'tabla_ejemplo_R.xlsx' en data_path\")\n}\n\n# LibrerÃ­as necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"psych\",\"moments\",\"qcc\",\"modeest\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(psych)\nlibrary(moments)\nlibrary(qcc)\nlibrary(modeest)\n\n\n5.1 1) Datos cualitativos: tabla de frecuencias, barras y Pareto\n\nej1 &lt;- read.xlsx(file.path(data_path, \"Ejemplo1.xlsx\"), sheet = 1, colNames = TRUE)\ntotal &lt;- sum(ej1$Frecuencia, na.rm = TRUE)\nej1 &lt;- ej1 |&gt;\n  mutate(Relativa = Frecuencia / total,\n         Porcentaje = 100 * Relativa)\nej1\n\n                  Categoria Frecuencia Acumulado   Relativa Porcentaje\n1          Explosion de Gas         28        28 0.62222222  62.222222\n2 Colapso de mina de carbon          7        35 0.15555556  15.555556\n3             Falla Represa          4        39 0.08888889   8.888889\n4      Incendio Combustible          4        43 0.08888889   8.888889\n5        Descarga electrica          1        44 0.02222222   2.222222\n6           Reactor Nuclear          1        45 0.02222222   2.222222\n\n\n\nggplot(ej1, aes(x = reorder(Categoria, -Frecuencia), y = Frecuencia)) +\n  geom_col(fill = \"#2b9348\") +\n  labs(title = \"DistribuciÃ³n de CategorÃ­as\", x = \"CategorÃ­a\", y = \"Frecuencia\") +\n  theme_minimal()\n\n\n\n\n\n\n\nqcc::pareto.chart(ej1$Frecuencia, names = ej1$Categoria,\n                  main = \"GrÃ¡fico de Pareto por categorÃ­a\")\n\n\n\n\n\n\n\n\n   \nPareto chart analysis for ej1$Frecuencia\n     Frequency  Cum.Freq. Percentage Cum.Percent.\n  A  28.000000  28.000000  62.222222    62.222222\n  B   7.000000  35.000000  15.555556    77.777778\n  C   4.000000  39.000000   8.888889    86.666667\n  D   4.000000  43.000000   8.888889    95.555556\n  E   1.000000  44.000000   2.222222    97.777778\n  F   1.000000  45.000000   2.222222   100.000000\n\n\n\n\n5.2 2) Datos cuantitativos: medidas y grÃ¡ficos\n\ndatos &lt;- read.xlsx(file.path(data_path, \"tabla_ejemplo_R.xlsx\"), sheet = 1, colNames = TRUE)\nx &lt;- datos$Precio\n\nmedia   &lt;- mean(x, na.rm = TRUE)\nmediana &lt;- median(x, na.rm = TRUE)\nmoda    &lt;- modeest::mlv(x, method = \"mfv\", na.rm = TRUE)\nrango   &lt;- diff(range(x, na.rm = TRUE))\nvar_x   &lt;- var(x, na.rm = TRUE)\nsd_x    &lt;- sd(x, na.rm = TRUE)\niqr_x   &lt;- IQR(x, na.rm = TRUE)\n\ntibble(Media = media, Mediana = mediana, Moda = moda,\n       Rango = rango, Varianza = var_x, `Desv.Est` = sd_x, IQR = iqr_x)\n\n# A tibble: 1 Ã— 7\n  Media Mediana  Moda Rango Varianza Desv.Est   IQR\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1   179     162   200   325    8805.     93.8    95\n\n\n\nhist(x, breaks = \"FD\", probability = TRUE,\n     main = \"Histograma con densidad\",\n     xlab = \"Variable X\", col = \"#cdeac0\", border = \"#2b9348\")\nlines(density(x, na.rm = TRUE))\ncurve(dnorm(x, mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)),\n      add = TRUE, col = \"red\")\n\n\n\n\n\n\n\nqqnorm(x); qqline(x, col = \"red\")\n\n\n\n\n\n\n\n\n\ntibble(AsimetrÃ­a = moments::skewness(x, na.rm = TRUE),\n       Curtosis  = moments::kurtosis(x, na.rm = TRUE))\n\n# A tibble: 1 Ã— 2\n  AsimetrÃ­a Curtosis\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      1.01     3.13\n\n\n\n\n5.3 3) ExploraciÃ³n bivariada (opcional)\n\nplot(datos$Superficie, datos$Antiguedad,\n     main = \"Diagrama de DispersiÃ³n\",\n     xlab = \"Superficie\", ylab = \"AntigÃ¼edad\",\n     col = \"#2b9348\", pch = 19)"
  },
  {
    "objectID": "labs/lab01_epg.html#bibliografÃ­a",
    "href": "labs/lab01_epg.html#bibliografÃ­a",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "6 BibliografÃ­a",
    "text": "6 BibliografÃ­a\nCrespo, F. A. (2023). IntroducciÃ³n y EstadÃ­stica Descriptiva. Universidad Alberto Hurtado."
  },
  {
    "objectID": "datos.html#section",
    "href": "datos.html#section",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reÃºnen diversas fuentes de informaciÃ³n estadÃ­stica y bases de datos relevantes para el anÃ¡lisis econÃ³mico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio Ãºnico y accesible, desde el cual puedan explorar y trabajar con informaciÃ³n oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a travÃ©s del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interÃ©s.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisiÃ³n universitaria (PSU, PAES, etc.).\nMinisterio de EducaciÃ³n (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadÃ­sticas comparables a nivel internacional.\nMinisterio de Ciencia, TecnologÃ­a, Conocimiento e InnovaciÃ³n, con la Encuesta Nacional de InnovaciÃ³n.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de EconomÃ­a, con encuestas y bases orientadas a la actividad econÃ³mica.\nBanco Central de Chile, a travÃ©s de su sistema SIETE.\n\nAdemÃ¡s, se proyecta integrar informaciÃ³n de ODEPA, INDAP y otros organismos pÃºblicos vinculados al Ã¡mbito econÃ³mico y agrÃ­cola."
  },
  {
    "objectID": "labs/lab01_epg.html#teorÃ­a-introducciÃ³n-a-la-estadÃ­stica",
    "href": "labs/lab01_epg.html#teorÃ­a-introducciÃ³n-a-la-estadÃ­stica",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "1 TeorÃ­a: IntroducciÃ³n a la EstadÃ­stica",
    "text": "1 TeorÃ­a: IntroducciÃ³n a la EstadÃ­stica"
  },
  {
    "objectID": "labs/lab01_epg.html#introducciÃ³n",
    "href": "labs/lab01_epg.html#introducciÃ³n",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "2 1.1 IntroducciÃ³n",
    "text": "2 1.1 IntroducciÃ³n\n\n2.1 1.1.1 DefiniciÃ³n y tÃ©rminos bÃ¡sicos de la estadÃ­stica\nLa estadÃ­stica es la ciencia de los datos.\nSe aplica comÃºnmente a dos tipos de problemas:\n\nResumir, describir y explorar datos.\nEjemplo: resultados del censo.\nUsar muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada.\nEjemplo: estudio de la sobrevida de las personas para calcular el valor de la prima de un seguro de vida.\n\nRamas de estudio de la estadÃ­stica:\n\nLa rama que se dedica a resumir, describir y explorar datos se denomina estadÃ­stica descriptiva.\n\nLa rama que usa muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada se denomina estadÃ­stica inferencial.\n\nLa estadÃ­stica busca comprender la variabilidad.\nEl pensamiento estadÃ­stico se desarrolla para poder enfrentar dicha variabilidad, que puede provenir de:\n\nDistintos factores que influyen en un fenÃ³meno (por ejemplo, medir el rendimiento de un automÃ³vil en km/l).\n\nFactores implÃ­citos, porque las variables no se pueden medir con precisiÃ³n o el fenÃ³meno tiene variabilidad propia (genes, medidas atÃ³micas, etc.).\n\nLa estadÃ­stica, junto con el mÃ©todo cientÃ­fico, permite crear modelos coherentes capaces de soportar la variabilidad de los fenÃ³menos."
  },
  {
    "objectID": "labs/lab01_epg.html#elementos-fundamentales-de-estadÃ­stica",
    "href": "labs/lab01_epg.html#elementos-fundamentales-de-estadÃ­stica",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "2 Elementos Fundamentales de EstadÃ­stica",
    "text": "2 Elementos Fundamentales de EstadÃ­stica\n\nPoblaciÃ³n estadÃ­stica: conjunto (grande o conceptual) de datos que es el objetivo de interÃ©s.\n\nMuestra: subconjunto de datos seleccionados de la poblaciÃ³n.\n\nUnidad experimental: objeto sobre el cual se observan las medidas (persona, transacciÃ³n, evento, etc.).\n\nVariable: caracterÃ­stica o propiedad de una unidad experimental.\n\nEjemplo: estudio de esquinas con mÃ¡s accidentes en la comuna de Santiago.\n\n\nInferencia: afirmaciÃ³n sustentada a partir de los datos.\n\nEn un problema de inferencia estadÃ­stica se pueden identificar cuatro puntos:\n\nUna poblaciÃ³n.\n\nUna o mÃ¡s variables.\n\nUna muestra.\n\nUna inferencia (mÃ¡s su medida de confiabilidad, que cuantifica el grado de incertidumbre).\n\nProblemas de estadÃ­stica descriptiva:\n\nPoblaciÃ³n o muestra de interÃ©s.\n\nVariables investigadas.\n\nTablas, grÃ¡ficos o resÃºmenes numÃ©ricos.\n\nProblemas de inferencia estadÃ­stica:\n\nPoblaciÃ³n de interÃ©s.\n\nVariables investigadas.\n\nMuestra de unidades experimentales.\n\nInferencia sobre la poblaciÃ³n basada en la muestra.\n\nMedida de confiabilidad para la inferencia."
  },
  {
    "objectID": "labs/lab01_epg.html#tipos-de-datos",
    "href": "labs/lab01_epg.html#tipos-de-datos",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "3 Tipos de Datos",
    "text": "3 Tipos de Datos\n\nDatos cuantitativos: representan cantidades medidas en una escala numÃ©rica.\n\nDatos cualitativos: no poseen interpretaciÃ³n numÃ©rica; solo pueden clasificarse.\n\nEjemplo: tipo de trabajo de egresados, estrato socioeconÃ³mico (ordinal).\n\n\nLa herramienta estadÃ­stica apropiada depende del tipo de dato, por lo que es esencial distinguir si es cuantitativo o cualitativo."
  },
  {
    "objectID": "labs/lab01_epg.html#estadÃ­stica-descriptiva",
    "href": "labs/lab01_epg.html#estadÃ­stica-descriptiva",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "4 EstadÃ­stica Descriptiva",
    "text": "4 EstadÃ­stica Descriptiva\nEl objetivo es presentar mÃ©todos grÃ¡ficos y numÃ©ricos para explorar, resumir y describir datos.\n\n\n4.1 MÃ©todos GrÃ¡ficos y NumÃ©ricos para Describir Datos Cualitativos\nCuando los datos son cualitativos, se agrupan en categorÃ­as:\n\nFrecuencia: nÃºmero de observaciones en cada categorÃ­a.\n\nFrecuencia relativa: proporciÃ³n respecto del total.\n\nEjemplo: estudio sobre seguridad de reactores nucleares (Safety of Nuclear Power Reactors, 2004).\nGrÃ¡ficos mÃ¡s usados:\n\nGrÃ¡fico de barras: largo proporcional a la frecuencia (o frecuencia relativa).\n\nGrÃ¡fico de torta: cada sector del cÃ­rculo representa una categorÃ­a proporcional a su frecuencia.\n\nDiagrama de Pareto: barras ordenadas de mayor a menor frecuencia, Ãºtil en control de calidad; puede incluir lÃ­nea de acumulaciÃ³n.\n\n\n\n\n4.2 MÃ©todos GrÃ¡ficos para Describir Datos Cuantitativos\nLos datos cuantitativos se representan en escalas numÃ©ricas.\nEjemplo: rendimiento de vehÃ­culos (millas por galÃ³n) medido por la EPA.\nGrÃ¡ficos mÃ¡s comunes:\n\nHistograma: divide los datos en intervalos de clase y muestra su frecuencia o frecuencia relativa.\n\nGrÃ¡fico de densidad: muestra la distribuciÃ³n de probabilidad de los datos.\n\nPasos para construir un histograma:\n\nCalcular el rango \\(=\\) mÃ¡ximo \\(-\\) mÃ­nimo.\n\nDividir el rango en 5â€“20 clases de igual ancho.\n\nContar las observaciones en cada clase (frecuencia).\n\nCalcular la frecuencia relativa \\(=\\) frecuencia / total de observaciones.\n\nDibujar las barras adyacentes con altura segÃºn frecuencia o frecuencia relativa.\n\n\n\n\n4.3 MÃ©todos NumÃ©ricos para Describir Datos Cuantitativos\nLas medidas numÃ©ricas descriptivas ayudan a visualizar la distribuciÃ³n de los datos.\nSe agrupan en tres categorÃ­as:\n\nMedidas de tendencia central (centro).\n\nMedidas de dispersiÃ³n (variabilidad).\n\nMedidas de posiciÃ³n relativa (comparaciÃ³n).\n\n\nEstadÃ­stica: medida numÃ©rica calculada desde la muestra.\n\nParÃ¡metro: medida descriptiva de la poblaciÃ³n (usualmente con sÃ­mbolos griegos).\n\n\n\n\n4.4 Medidas de Tendencia Central\nMedia aritmÃ©tica\nLa media aritmÃ©tica de un conjunto de observaciones se define como:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\n\nMediana\nLa mediana es el valor central cuando los datos estÃ¡n ordenados.\nSi \\(x_{(i)}\\) representa el i-Ã©simo valor ordenado:\n\\[\nm =\n\\begin{cases}\nx_{\\left(\\frac{n+1}{2}\\right)}, & \\text{si } n \\text{ es impar} \\\\\n\\\\[-0.5em]\n\\dfrac{x_{\\left(\\frac{n}{2}\\right)} + x_{\\left(\\frac{n}{2} + 1\\right)}}{2}, & \\text{si } n \\text{ es par}\n\\end{cases}\n\\]\n\nModa\nLa moda es el valor que ocurre con mayor frecuencia en el conjunto de datos.\n\nLa media es sensible a valores extremos.\n\nLa mediana es resistente a valores extremos.\n\nLa moda es Ãºtil en datos categÃ³ricos o con repeticiones frecuentes.\n\n\n\n\n4.5 Medidas de VariaciÃ³n\nLas medidas mÃ¡s usadas son el rango, la varianza y la desviaciÃ³n estÃ¡ndar.\nRango\n\\[\n\\text{Rango} = \\text{mÃ¡ximo} - \\text{mÃ­nimo}\n\\]\n\nVarianza muestral\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}\n\\]\n\nVarianza poblacional\n\\[\n\\sigma^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}\n\\]\n\nDesviaciÃ³n estÃ¡ndar\n\\[\ns = \\sqrt{s^2}\n\\qquad \\text{y} \\qquad\n\\sigma = \\sqrt{\\sigma^2}\n\\]\n\n\n\n4.6 Medidas de PosiciÃ³n Relativa\nIndican la ubicaciÃ³n de una observaciÃ³n respecto al resto.\nPercentiles\nEl percentil \\(p\\) deja el \\(p\\%\\) de las observaciones a su izquierda:\n\n\\(Q_L = P_{25}\\): cuartil inferior\n\n\\(m = P_{50}\\): mediana\n\n\\(Q_U = P_{75}\\): cuartil superior\n\nPasos para calcular cuartiles:\n\nOrdenar los datos de menor a mayor.\n\nCalcular \\(l = \\frac{1}{4}(n + 1)\\) â†’ primer cuartil.\n\nCalcular \\(u = \\frac{3}{4}(n + 1)\\) â†’ tercer cuartil.\n\n\nZ-score\nEl puntaje z mide cuÃ¡ntas desviaciones estÃ¡ndar estÃ¡ un valor respecto a la media:\n\\[\nz = \\frac{x - \\bar{x}}{s}\n\\quad \\text{(muestra)}, \\qquad\nz = \\frac{x - \\mu}{\\sigma}\n\\quad \\text{(poblaciÃ³n)}\n\\]\n\n\n\n4.7 Medidas de AsimetrÃ­a\nEl coeficiente de asimetrÃ­a de Fisher mide la direcciÃ³n y magnitud de la cola de la distribuciÃ³n:\n\\[\n\\gamma_1 = \\frac{\\mu_3}{\\sigma^3}\n\\]\n\nSi \\(\\gamma_1 &gt; 0\\): asimetrÃ­a positiva (cola hacia la derecha).\n\nSi \\(\\gamma_1 &lt; 0\\): asimetrÃ­a negativa (cola hacia la izquierda).\n\n\n\n\n4.8 Medidas de ConcentraciÃ³n de Datos\nLa curtosis o kurtosis mide el grado de concentraciÃ³n de los datos alrededor de la media:\n\\[\n\\beta_2 = \\frac{\\mu_4}{\\sigma^4}\n\\]\n\nSi \\(\\beta_2 &gt; 3\\): distribuciÃ³n mÃ¡s apuntada (colas gruesas).\n\nSi \\(\\beta_2 &lt; 3\\): distribuciÃ³n mÃ¡s plana (colas delgadas).\n\nSi \\(\\beta_2 = 3\\): distribuciÃ³n normal."
  },
  {
    "objectID": "labs/lab01_epg.html#definiciÃ³n-y-tÃ©rminos-bÃ¡sicos-de-la-estadÃ­stica",
    "href": "labs/lab01_epg.html#definiciÃ³n-y-tÃ©rminos-bÃ¡sicos-de-la-estadÃ­stica",
    "title": "Laboratorio 1_epg: IntroducciÃ³n y EstadÃ­stica Descriptiva",
    "section": "1 DefiniciÃ³n y tÃ©rminos bÃ¡sicos de la estadÃ­stica",
    "text": "1 DefiniciÃ³n y tÃ©rminos bÃ¡sicos de la estadÃ­stica\nLa estadÃ­stica es la ciencia de los datos.\nSe aplica comÃºnmente a dos tipos de problemas:\n\nResumir, describir y explorar datos.\nEjemplo: resultados del censo.\n\nUsar muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada.\nEjemplo: estudio de la sobrevida de las personas para calcular el valor de la prima de un seguro de vida.\n\nRamas de estudio de la estadÃ­stica:\n\nLa rama que se dedica a resumir, describir y explorar datos se denomina estadÃ­stica descriptiva.\n\nLa rama que usa muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada se denomina estadÃ­stica inferencial.\n\nLa estadÃ­stica busca comprender la variabilidad.\nEl pensamiento estadÃ­stico se desarrolla para poder enfrentar dicha variabilidad, que puede provenir de:\n\nDistintos factores que influyen en un fenÃ³meno (por ejemplo, medir el rendimiento de un automÃ³vil en km/l).\n\nFactores implÃ­citos, porque las variables no se pueden medir con precisiÃ³n o el fenÃ³meno tiene variabilidad propia (genes, medidas atÃ³micas, etc.).\n\nLa estadÃ­stica, junto con el mÃ©todo cientÃ­fico, permite crear modelos coherentes capaces de soportar la variabilidad de los fenÃ³menos."
  },
  {
    "objectID": "labs/lab02_epg.html",
    "href": "labs/lab02_epg.html",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso EconometrÃ­a para la GestiÃ³n â€” FEN-UAH."
  },
  {
    "objectID": "labs/lab02_epg.html#correlaciÃ³n-y-regresiÃ³n-lineal-simple",
    "href": "labs/lab02_epg.html#correlaciÃ³n-y-regresiÃ³n-lineal-simple",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "1 CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "text": "1 CorrelaciÃ³n y RegresiÃ³n Lineal Simple\nCap Â´ Ä±tulo 2: CorrelaciÂ´ on y RegresiÂ´ on Simple Fernando A. Crespo R. 30 de Septiembre de 2021\nÂ´Indice 2.1 Covarianza y CorrelaciÂ´ on 2.3 Diagramas de DispersiÂ´ on 2.4 Prueba de HipÂ´ otesis de la CorrelaciÂ´ on 2.5 Ecuaciones Lineales 2.6 MÂ´ etodo de MÂ´ Ä±nimos Cuadrados 2.7 Residuos 2.8 PredicciÂ´ on e Intervalo de Confianza 2.9 Coeficiente de determinaciÂ´ on simple 2.10 Prueba de HipÂ´ otesis de AnÂ´ alisis de la RegresiÂ´ on 2.1 Covarianza y CorrelaciÂ´ on â–¶Hasta el momento hemos visto distribuciones conjuntas, medias y varianzas que entregan informaciÂ´ on Â´ util de su distribuciones marginales. Pero ellas no nos entregan informaciÂ´ on de la relaciÂ´ on entre dos variables, de como varÂ´ Ä±an juntas. DefiniciÂ´ on (2.1 Covarianza) Sean XeYv.a. que tienen distribuciÂ´ on conjunta y cuyos primeros momentos y varianzas son IE(X) =ÂµX,IE(Y) =ÂµY,Var(X) =Ïƒ2 Xy Var(Y) =Ïƒ2 Y. La covarianza de XeY, que se denota por Cov(X,Y), se define como: Cov(X,Y) =IE[(Xâˆ’ÂµX) (Yâˆ’ÂµY)]. (1) â–¶ â–¶Se puede demostrar que si Ïƒ2 X&lt;âˆyÏƒ2 Y&lt;âˆ, entonces existe la esperanza de (1) y Cov(X,Y) serÂ´ a finita. Cov(X,Y) puede tomar cualquier valor en IR. 2.1 Covarianza y CorrelaciÂ´ on DefiniciÂ´ on (2.2 CorrelaciÂ´ on) Si0&lt; Ïƒ2 X&lt;âˆy0&lt; Ïƒ2 Y&lt;âˆ, entonces la correlaciÂ´ on de XeY, que se denota por Ï(X,Y), se define como sigue: Ï(X,Y) =Cov(X,Y) ÏƒXÏƒY. (2) â–¶ Teorema (2.1 Desigualdad de Schwartz) Para cualquiera variables aleatorias UyV, [IE(UV)]2â‰¤IE(U2)IE(V2). (3) â–¶ â–¶De la Desigualdad de Schwartz se tiene âˆ’1â‰¤Ï(X,Y)â‰¤1. Teorema (2.2) Para cualquiera v.a. XeYtales que Ïƒ2 X&lt;âˆyÏƒ2 Y&lt;âˆ, Cov(X,Y) =IE(XY)âˆ’IE(X)IE(Y). (4) â–¶ 2.1 Covarianza y CorrelaciÂ´ on Teorema (2.3) SiXeYson v.a. independientes con 0&lt; Ïƒ2 X&lt;âˆy0&lt; Ïƒ2 Y&lt;âˆ, entonces Cov(X,Y) =Ï(X,Y) = 0 . (5) â–¶ â–¶Ejemplo 2.1.1: Variables aleatorias dependientes pero no correlacionadas. Suponga que la v.a. Xpuede tomar Â´ unicamente los tres valores âˆ’1, 0 y 1, que cada uno de estos tres valores tienen la misma probabilidad. AdemÂ´ as, sea la v.a. Ydefinida por la relaciÂ´ on Y=X2. Teorema (2.4) Suponga que Xes una v.a. tal que 0&lt; Ïƒ2 X&lt;âˆy que Y=aX+bpara alguna constantes ayb, donde aÌ¸= 0. Sia&gt;0, entonces Ï(X,Y) = 1 . Sia&lt;0, entonces Ï(X,Y) =âˆ’1. â–¶ 2.1 Covarianza y CorrelaciÂ´ on Teorema (2.5) SiXeYson v.a. con varianza finita, Ïƒ2 X&lt;âˆyÏƒ2 Y&lt;âˆ, entonces Var(X+Y) =Var(X) +Var(Y) + 2 Cov(X,Y). (6) â–¶ 2.1 Covarianza y CorrelaciÂ´ on â–¶Del Teorema 2.5 se obtiene: Var(aX+bY+c) =a2Var(X) +b2Var(Y) + 2 abCov (X,Y).(7) â–¶TambiÂ´ en del Teorema 2.5 se obtiene: Var(Xâˆ’Y) =Var(X) +Var(Y)âˆ’2Cov(X,Y). (8) Teorema (2.6) SiX1, . . . , Xnson v.a. tales que Var(Xi)&lt;âˆpara i= 1, . . . , n, entonces: Var nX i=1Xi! =nX i=1Var(Xi) + 2nX i=1nX j=i+1Cov(Xi,Xj). (9) Var nX i=1Xi! =nX i=1Var(Xi) + 2X i&lt;jX Cov(Xi,Xj). (10) â–¶ 2.1 Covarianza y CorrelaciÂ´ on â–¶CÂ´ alculos necesarios: Â¯X=1 nnX i=1Xi. (11) ÏƒX=p Var(X) =vuut1 nnX i=1(Xiâˆ’Â¯X)2. (12) Â¯Y=1 nnX i=1Yi. (13) ÏƒY=p Var(Y) =vuut1 nnX i=1(Yiâˆ’Â¯Y)2. (14) â–¶CÂ´ alculo de covarianza: ÏƒXY=1 nnX i=1(Xiâˆ’Â¯X)(Yiâˆ’Â¯Y). (15) 2.1 Covarianza y CorrelaciÂ´ on â–¶CÂ´ alculo correlaciÂ´ on de Pearson: r=rXY=ÏƒXY ÏƒXÏƒY. (16) 2.3 Diagramas de DispersiÂ´ on â–¶Es la grÂ´ afica para ver la relaciÂ´ on de dos variables. Es la forma mÂ´ as intuitiva de ver la relaciones entre variables. â–¶Caso famoso: https: //es.wikipedia.org/wiki/Ley_de_elasticidad_de_Hooke â–¶Caso famoso: https://es.wikipedia.org/wiki/Ley_de_Hubble-Lemaitre â–¶Caso famoso: https: //www.ligo.org/sp/science/Publication-GW170817Hubble/ 2.3 Diagramas de DispersiÂ´ on â–¶Ejemplo 1: Veamos los datos en excel de rendimiento de automÂ´ oviles respecto de su peso. 2.4 Prueba de HipÂ´ otesis de la CorrelaciÂ´ on â–¶ H0:Ï= 0, H1:ÏÌ¸= 0(17) â–¶Para calcular se tiene: sr=r 1âˆ’r nâˆ’2, (18) donde sres el error estÂ´ andar del coeficiente de correlaciÂ´ on, res la correlaciÂ´ on empÂ´ Ä±rica, y nel nÂ´ umero de observaciones pareadas. â–¶el estadÂ´ Ä±stico: t=râˆ’Ï sr, (19) donde res la correlaciÂ´ on empÂ´ Ä±rica, Ïes el valor hipotÂ´ etico, srel error estÂ´ andar calculado con (18). â–¶ttiene una distribuciÂ´ on tâˆ’student de nâˆ’2 grados de libertad. â–¶tse rechaza si t&gt;cot&lt;âˆ’cconF(c) =Î± 2. 2.4 Prueba de HipÂ´ otesis de la CorrelaciÂ´ on â–¶Una correlaciÂ´ on entre dos variables no significa que una variable causa u ocasiona a la otra. â–¶CorrelaciÂ´ on 0 no significa que no exista relaciÂ´ on entre variables, veamos un ejemplo grÂ´ afico. 2.5 Ecuaciones Lineales â–¶Cuando se menciona una correlaciÂ´ on es para predecir una variable por la otra. â–¶Estudiar el valor que cambia, o denominada variable dependiente , habitualmente designada como y, por una variable independiente denominada x. â–¶La idea base es trazar una recta que permita ver la relaciÂ´ on en el grÂ´ afico de dispersiÂ´ on. â–¶Para ello se plantea el modelo: y=Î²0+Î²1x, (20) donde: Î²0es la ordenada al origen (o intercepciÂ´ on en y), Î²1 pendiente de la recta. â–¶Este es un modelo que propone una relaciÂ´ on entre las variables, si se permite algÂ´ un error aleatorio a (20) se se denomina modelo estadÂ´ Ä±stico: y=Î²0+Î²1x+Ïµ, (21) conÏµel error. 2.5 Ecuaciones Lineales â–¶La distribuciÂ´ on de Ïµdetermina el grado de relaciÂ´ on entre las variables independientes y dependiente. â–¶Para ello se hacen los siguientes supuestos: 1. La distribuciÂ´ on de probabilidad de Ïµes normal. 2. La varianza de la distribuciÂ´ on de Ïµes constante para todos los valores de x. 3. La media de la distribuciÂ´ on de probabilidad de Ïµes 0. Esta suposiciÂ´ on implica que el valor medio de ypara un valor de x es IE(y) =Î²0+Î²1x. 4. Los valores de Ïµson independientes entre sÂ´ Ä±. 2.6 MÂ´ etodo de M Â´ Ä±nimos Cuadrados â–¶Para determinar la recta, se utiliza mÂ´ Ä±nimos cuadrados: minnX i=0(yâˆ’Î²0âˆ’Î²1x)2. (22) â–¶al resolver (22), se obtiene: Ë†Î²1=nP i=0XiYiâˆ’nÂ¯XÂ¯Y nP i=0X2 iâˆ’nÂ¯X2(23) Ë†Î²0=Â¯Yâˆ’Ë†Î²1Â¯X (24) 2.6 MÂ´ etodo de M Â´ Ä±nimos Cuadrados â–¶Ejemplo 2.1, costo de mantenimiento anual de buses (USD) por tiempo de operaciÂ´ on (aËœ nos). 1. Ver diagrama de dispersiÂ´ on. 2. Ver si hay relaciÂ´ on entre variables. 3. Calcule el coeficiente de correlaciÂ´ on. 4. Pruebe el coeficiente de correlaciÂ´ on para nivel 0.05. 5. Â¿Se puede usar la regresiÂ´ on lineal para analizar el costo? 6. determine la ecuaciÂ´ on del modelo lineal. 7. Calcule el costo de mantenimiento anual para un bus con 5 aËœ nos de operaciÂ´ on. 2.7 Residuos â–¶Se denominan residuos a: Ë†Ïµ=yâˆ’Ë†y. (25) Donde yes el valor real e Ë† yvalor estimado. Este es un valor empÂ´ Ä±rico, es la estimaciÂ´ on del error. â–¶Definimos como error estÂ´ andar de la estimaciÂ´ on , a la dispersiÂ´ on de los valores observados de yalrededor de la recta estimada: sy,x=vuuutnP i=0(yâˆ’Ë†y)2 nâˆ’2. (26) 2.8 PredicciÂ´ on e Intervalo de Confianza â–¶La estimaciÂ´ on puntual no proporciona informaciÂ´ on sobre la distancia que se encuentra respecto del parÂ´ ametro poblacional. Para ello se requiere usar: Ë†yÂ±tsË†y,x. (27) contla distribuciÂ´ on de t student con nâˆ’2 grados de libertad, y sË†y,x elerror estÂ´ andar de la estimaciÂ´ on del pronÂ´ ostico . â–¶El error estÂ´ andar de la predicciÂ´ on y: sË†y,x=sy,xvuuut1 +1 n+(Xpâˆ’Â¯X)2 nP i=0(Xiâˆ’Â¯X)2. (28) Xpel valor dado de X,Â¯Xla media de X, suma de cuadrados total para la variable X. 2.8 PredicciÂ´ on e Intervalo de Confianza â–¶Se puede pensar en estimar el valor medio de un nÂ´ umero grande de experimentos para un valor de x: Ë†yÂ±tsË†Âµ,x. (29) contla distribuciÂ´ on de t student con nâˆ’2 grados de libertad, y sË†mu,xerror estÂ´ andar de distribuciÂ´ on muestral del estimador de y. â–¶La desviaciÂ´ on estÂ´ andar de la estimaciÂ´ on: sË†Âµ,x=sy,xvuuut1 n+(Xpâˆ’Â¯X)2 nP i=0(Xiâˆ’Â¯X)2. (30) Xpel valor dado de X,Â¯Xla media de X, suma de cuadrados total para la variable X. 2.9 Coeficiente de determinaciÂ´ on simple â–¶El coeficiente de determinaciÂ´ on simple, R2, mide el porcentaje de variabilidad en yque puede ser explicada por la variable predictora x: R2= 1âˆ’nP i=0(Yiâˆ’Ë†Yi)2 nP i=0(Yiâˆ’Â¯Y)2. (31) 2.10 Prueba de HipÂ´ otesis de AnÂ´ alisis de la RegresiÂ´ on â–¶e quiere ver la hipÂ´ otesis con dos colas para: H0:Î²1= 0, H1:Î²1Ì¸= 0(32) â–¶El error estÂ´ andar del estimador se estima como: sb=sy,xs nP i=0(Xiâˆ’Â¯X)2. (33) â–¶El estadÂ´ Ä±stico es: t=Ë†Î²1âˆ’Î²1 sb, (34) donde Î²1es el valor hipotÂ´ etico. â–¶ttiene una distribuciÂ´ on tâˆ’student de nâˆ’2 grados de libertad. â–¶tse rechaza si t&gt;cot&lt;âˆ’cconF(c) =Î± 2."
  },
  {
    "objectID": "labs/lab02_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab02_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "10 AplicaciÃ³n en R (sobre los contenidos anteriores)",
    "text": "10 AplicaciÃ³n en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (segÃºn tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# VerificaciÃ³n\nif (!file.exists(file.path(data_path, \"auto_peso_consumo.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'auto_peso_consumo.xlsx' en data_path\")\n}\nif (!file.exists(file.path(data_path, \"annos_mantenimiento.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'annos_mantenimiento.xlsx' en data_path\")\n}\n\n# LibrerÃ­as necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\n\n\n# Cargar datos de autos\ndatos &lt;- read.xlsx(file.path(data_path, \"auto_peso_consumo.xlsx\"), sheet=\"Hoja1\", colNames = TRUE)\n\n# Diagrama de dispersiÃ³n Peso vs Consumo\nplot(datos$Peso_Libras, datos$Consumo_Millas_por_galon,\n     main=\"RelaciÃ³n entre peso y consumo de autos\",\n     xlab=\"Peso (libras)\", ylab=\"Consumo (millas/galÃ³n)\")\n\n\n\n\n\n\n\n# Coeficiente de correlaciÃ³n\nr &lt;- cor(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\nr\n\n[1] -0.8549912\n\n# Prueba de hipÃ³tesis para la correlaciÃ³n\nsr &lt;- sqrt((1 - r) / (3)) # n = nÃºmero de datos menos 2\nt &lt;- r / sr\nc &lt;- qt(0.025, 3, lower.tail = F)\npt(-t, 3, lower.tail = F)\n\n[1] 0.1782267\n\n# Test de correlaciÃ³n con funciÃ³n base\ncor.test(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos$Peso_Libras and datos$Consumo_Millas_por_galon\nt = -2.8553, df = 3, p-value = 0.06483\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9902684  0.1110238\nsample estimates:\n       cor \n-0.8549912 \n\n\n\n# Cargar datos de mantenimiento\ndatos2 &lt;- read.xlsx(file.path(data_path, \"annos_mantenimiento.xlsx\"), sheet=\"Hoja1\", colNames = TRUE)\n\n# Diagrama de dispersiÃ³n\nplot(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento,\n     main=\"Costo de mantenimiento vs Tiempo de operaciÃ³n\",\n     xlab=\"Tiempo de operaciÃ³n (aÃ±os)\", ylab=\"Costo de mantenimiento\")\n\n\n\n\n\n\n\n# Coeficiente de correlaciÃ³n\nr &lt;- cor(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\nr\n\n[1] 0.9376733\n\n# Prueba de hipÃ³tesis para correlaciÃ³n\nsr &lt;- sqrt((1 - r) / (7))\nt &lt;- r / sr\nc &lt;- qt(0.025, 3, lower.tail = F)\ncor.test(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos2$Tiempo_operacion and datos2$Costo_Mantenimiento\nt = 7.1388, df = 7, p-value = 0.0001872\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7250800 0.9870994\nsample estimates:\n      cor \n0.9376733 \n\n\n\n# Ajuste del modelo lineal simple\nmodelo &lt;- lm(Costo_Mantenimiento ~ Tiempo_operacion, data=datos2)\nsummary(modelo)\n\n\nCall:\nlm(formula = Costo_Mantenimiento ~ Tiempo_operacion, data = datos2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-138.47 -124.55   40.88   83.45  119.21 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       208.203     75.002   2.776 0.027457 *  \nTiempo_operacion   70.918      9.934   7.139 0.000187 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 111.6 on 7 degrees of freedom\nMultiple R-squared:  0.8792,    Adjusted R-squared:  0.862 \nF-statistic: 50.96 on 1 and 7 DF,  p-value: 0.0001872\n\n# PredicciÃ³n para 5 aÃ±os de operaciÃ³n\nnuevo &lt;- data.frame(Tiempo_operacion = c(5))\nvalor_predicho &lt;- predict(object=modelo, newdata=nuevo)\nvalor_predicho\n\n      1 \n562.794 \n\n\n\n# AnÃ¡lisis de residuos\nmodelo$residuals\n\n         1          2          3          4          5          6          7 \n  83.45158  119.20599   50.04225 -138.46655  105.69718 -126.03961   40.87852 \n         8          9 \n-124.54842  -10.22095 \n\nhist(modelo$residuals, main=\"Histograma de residuos\", col=\"#cdeac0\", border=\"#2b9348\")\n\n\n\n\n\n\n\nplot(density(modelo$residuals), main=\"Densidad de residuos\")\n\n\n\n\n\n\n\nmean(modelo$residuals) # Debe ser ~0\n\n[1] -2.368187e-15\n\n# CÃ¡lculo de error estÃ¡ndar de la estimaciÃ³n\ns_yx &lt;- sqrt(sum(modelo$residuals^2) / 7)\n\n# Intervalos de predicciÃ³n\nraiz &lt;- sqrt(1 + 1/9 + ((5 - mean(datos2$Tiempo_operacion))^2 /\n        sum((datos2$Tiempo_operacion - mean(datos2$Tiempo_operacion))^2)))\ns_hatyx &lt;- s_yx * raiz\nt &lt;- qt(0.025, 7, lower.tail = F)\n\nlimitsup &lt;- valor_predicho + t * s_hatyx\nlimitinf &lt;- valor_predicho - t * s_hatyx\nc(limitsup = limitsup, limitinf = limitinf)\n\nlimitsup.1 limitinf.1 \n  843.3746   282.2134 \n\n# Intervalos de confianza\nvalor_predicho &lt;- predict(object=modelo, newdata=nuevo, interval = c(\"confidence\"))\nvalor_predicho\n\n      fit     lwr     upr\n1 562.794 467.535 658.053"
  },
  {
    "objectID": "labs/lab02_epg.html#bibliografÃ­a",
    "href": "labs/lab02_epg.html#bibliografÃ­a",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "11 BibliografÃ­a",
    "text": "11 BibliografÃ­a\nCrespo, F. A. (2021). CorrelaciÃ³n y RegresiÃ³n Simple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "index.html#docentes-y-ayudante",
    "href": "index.html#docentes-y-ayudante",
    "title": "",
    "section": "Docentes y Ayudante",
    "text": "Docentes y Ayudante\n\nRocÃ­o Valdebenito: Docente e Investigadora\nLa Dra. RocÃ­o Valdebenito es una acadÃ©mica especializada en EconomÃ­a Aplicada con un fuerte enfoque en el anÃ¡lisis de temas sociales y de desarrollo.\n\nFormaciÃ³n y AfiliaciÃ³n\n\nDoctorado (Ph.D.) en EconomÃ­a Aplicada de la University of Illinois at Urbana-Champaign (EE. UU., 2024).\nIngeniera Comercial y MÃ¡ster en Management de la Universidad Adolfo IbÃ¡Ã±ez (UAI).\nActualmente es Profesora en la Facultad de EconomÃ­a y Negocios (FEN) de la Universidad Alberto Hurtado (UAH).\n\n\n\nÃreas Clave de EspecializaciÃ³n e InvestigaciÃ³n\nLa Dra. Valdebenito utiliza la EconometrÃ­a y la MicroeconomÃ­a Aplicada para estudiar temas de alta relevancia social. Sus principales Ã¡reas de investigaciÃ³n son:\n\nEconomÃ­a de la EducaciÃ³n: Se interesa en el impacto de la educaciÃ³n tÃ©cnica-profesional, el rol de los compaÃ±eros en la elecciÃ³n de carreras STEM (Ciencia, TecnologÃ­a, IngenierÃ­a y MatemÃ¡ticas) y los efectos de shocks ambientales en los resultados de los estudiantes.\nEconomÃ­a de GÃ©nero y Desarrollo: Su trabajo aborda explÃ­citamente las brechas de gÃ©nero en la sociedad y examina polÃ­ticas relacionadas con la planificaciÃ³n familiar y el empleo en paÃ­ses en desarrollo (ej. India).\nEconomÃ­a Regional: Investiga la migraciÃ³n interregional de graduados de educaciÃ³n media y las desigualdades en calidad de vida y educaciÃ³n a nivel regional.\n\n\n\nDocencia\nEn su rol docente, la profesora Valdebenito imparte cursos fundamentales que conectan la teorÃ­a econÃ³mica con la evidencia empÃ­rica:\n\nEconometrÃ­a\nMicroeconomÃ­a III\nOrganizaciÃ³n Industrial\n\nSu experiencia docente se extiende a la enseÃ±anza de mÃ©todos estadÃ­sticos aplicados y Data Science a nivel de postgrado.\nLa descripciÃ³n del profesional proviene del sitio web:\n\nrvaldebenito.github.io\n\n\n\n\nFernando Crespo: Docente e Investigador\nEl profesor Fernando Crespo es un experto en Ciencia de Datos, Machine Learning y Modelos MatemÃ¡ticos Aplicados. Es Doctor en Ciencias de la IngenierÃ­a por la Pontificia Universidad CatÃ³lica de Chile y actualmente se desempeÃ±a como Profesor en la Universidad Alberto Hurtado.\n\nÃreas Clave de EspecializaciÃ³n\nSu investigaciÃ³n combina las matemÃ¡ticas avanzadas con la informÃ¡tica, centrÃ¡ndose en:\n\nInteligencia Artificial y Redes Neuronales.\nInvestigaciÃ³n Operacional y SimulaciÃ³n.\nMinerÃ­a de Datos (Data Mining) y Reconocimiento de Patrones.\n\n\n\nImpacto y Enfoque Multidisciplinario\nEl Dr.Â Crespo mantiene una trayectoria productiva con aproximadamente 72 participaciones en publicaciones y mÃ¡s de 700 citas registradas. Su trabajo destaca por su aplicaciÃ³n a problemas de gran relevancia social, realizando investigaciones en diversas Ã¡reas como:\n\nEconomÃ­a y Negocios (valoraciÃ³n, innovaciÃ³n).\nSalud PÃºblica (anÃ¡lisis de demencias, cobertura hospitalaria, obesidad).\nSeguridad y Sociedad (modelado de delitos, segregaciÃ³n residencial).\n\nEn resumen, el profesor Crespo utiliza el anÃ¡lisis de datos y la modelaciÃ³n avanzada para generar conocimiento aplicado y soluciones en un amplio espectro de disciplinas.\nLa descripciÃ³n del profesional proviene del sitio web:\n\nhttps://www.researchgate.net/profile/Fernando-Crespo-3\n\n\n\n\nManuel LabraÃ±a Rojas: Perfil AcadÃ©mico y Profesional\nManuel LabraÃ±a Rojas es un estudiante de IngenierÃ­a Comercial con MenciÃ³n en EconomÃ­a de la Universidad Alberto Hurtado (UAH).\n\nExperiencia AcadÃ©mica y Docencia (UAH)\nHa demostrado compromiso con la formaciÃ³n acadÃ©mica, desempeÃ±Ã¡ndose como Ayudante de CÃ¡tedra en las siguientes asignaturas:\n\nMatemÃ¡ticas II\nMicroeconomÃ­a I\nEconometrÃ­a para la GestiÃ³n\n\nAdemÃ¡s, colabora en el Ã¡rea de investigaciÃ³n como Ayudante del proyecto â€œRepositorio de EconometrÃ­aâ€, contribuyendo a su funcionamiento y desarrollo web.\n\n\nExperiencia Profesional\nPrÃ¡ctica Intermedia: RealizÃ³ su prÃ¡ctica intermedia en el Ministerio de Agricultura, especÃ­ficamente en INDAP, dentro del Departamento SAT. Sus responsabilidades incluyeron el manejo de bases de datos y la generaciÃ³n de informes estadÃ­sticos descriptivos utilizando herramientas como RStudio y aplicaciones de Microsoft 365.\nTrabajo Actual: Actualmente, trabaja en la consultora FV-Consulting, enfocada en Servicios y Soluciones Integrales y ConsultorÃ­a. Su labor profesional se centra en Ã¡reas temÃ¡ticas de aplicaciÃ³n econÃ³mica, incluyendo:\n\nEconomÃ­a\nEconomÃ­a AgrÃ­cola\nEconometrÃ­a\nEstudios de Mercados\n\n\n\nAgradecimientos\nAgradezco a los profesores por la oportunidad y la confianza en mi desarrollo. Extiendo mi gratitud a mis padres, JosuÃ© Rojas y Cristina LabraÃ±a, por su apoyo incondicional."
  },
  {
    "objectID": "labs/lab02_epg.html#covarianza-y-correlaciÃ³n",
    "href": "labs/lab02_epg.html#covarianza-y-correlaciÃ³n",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "1 Covarianza y CorrelaciÃ³n",
    "text": "1 Covarianza y CorrelaciÃ³n\nHasta ahora hemos visto distribuciones conjuntas, medias y varianzas, las cuales entregan informaciÃ³n Ãºtil sobre las distribuciones marginales.\nSin embargo, ellas no muestran la relaciÃ³n entre dos variables, es decir, cÃ³mo varÃ­an juntas.\n\n\n1.1 DefiniciÃ³n: Covarianza\nSean \\(X\\) y \\(Y\\) variables aleatorias con distribuciÃ³n conjunta, medias \\(\\mu_X, \\mu_Y\\) y varianzas \\(\\sigma_X^2, \\sigma_Y^2\\).\nLa covarianza entre \\(X\\) y \\(Y\\) se define como:\n\\[\n\\text{Cov}(X, Y) = E[(X - \\mu_X)(Y - \\mu_Y)]\n\\]\nSi \\(\\sigma_X^2 &lt; \\infty\\) y \\(\\sigma_Y^2 &lt; \\infty\\), la covarianza es finita y puede tomar cualquier valor real.\n\n\n\n1.2 DefiniciÃ³n: CorrelaciÃ³n\nSi \\(0 &lt; \\sigma_X^2 &lt; \\infty\\) y \\(0 &lt; \\sigma_Y^2 &lt; \\infty\\), la correlaciÃ³n de Pearson entre \\(X\\) y \\(Y\\) se define como:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\]\n\n\n\n1.3 Teorema 2.1: Desigualdad de Cauchy-Schwarz\nPara cualesquiera variables aleatorias \\(U\\) y \\(V\\):\n\\[\n[E(UV)]^2 \\leq E(U^2) \\, E(V^2)\n\\]\nDe esta desigualdad se deduce que:\n\\[\n-1 \\leq \\rho(X, Y) \\leq 1\n\\]\n\n\n\n1.4 Teorema 2.2\nPara variables aleatorias \\(X\\) y \\(Y\\) con varianzas finitas:\n\\[\n\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\n\\]\n\n\n\n1.5 Teorema 2.3\nSi \\(X\\) y \\(Y\\) son independientes con \\(0 &lt; \\sigma_X^2, \\sigma_Y^2 &lt; \\infty\\), entonces:\n\\[\n\\text{Cov}(X, Y) = \\rho(X, Y) = 0\n\\]\n\nNota: Independencia implica covarianza nula, pero no al revÃ©s.\n\n\n\n\n1.6 Ejemplo\nVariables aleatorias dependientes pero no correlacionadas:\nSea \\(X\\) que toma los valores \\(-1, 0, 1\\) con igual probabilidad, y defÃ­nase \\(Y = X^2\\).\nAquÃ­ \\(X\\) y \\(Y\\) no son independientes, pero su correlaciÃ³n es cero.\n\n\n\n1.7 Teorema 2.4\nSea \\(Y = aX + b\\), con \\(a \\neq 0\\).\nEntonces:\n\\[\n\\rho(X, Y) =\n\\begin{cases}\n1, & \\text{si } a &gt; 0 \\\\\n-1, & \\text{si } a &lt; 0\n\\end{cases}\n\\]\n\n\n\n1.8 Teorema 2.5\nSi \\(X\\) y \\(Y\\) tienen varianzas finitas:\n\\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\,\\text{Cov}(X, Y)\n\\]\nDe aquÃ­ se derivan:\n\\[\n\\text{Var}(aX + bY + c) = a^2 \\text{Var}(X) + b^2 \\text{Var}(Y) + 2ab\\,\\text{Cov}(X, Y)\n\\]\n\\[\n\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\,\\text{Cov}(X, Y)\n\\]\n\n\n\n1.9 Teorema 2.6\nPara \\(X_1, X_2, \\ldots, X_n\\) con varianzas finitas:\n\\[\n\\text{Var}\\left( \\sum_{i=1}^{n} X_i \\right)\n= \\sum_{i=1}^{n} \\text{Var}(X_i)\n+ 2 \\sum_{i&lt;j} \\text{Cov}(X_i, X_j)\n\\]\n\n\n\n1.10 CÃ¡lculos PrÃ¡cticos\nMedia y desviaciÃ³n estÃ¡ndar:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i,\n\\qquad\n\\sigma_X = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\]\n\\[\n\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n} Y_i,\n\\qquad\n\\sigma_Y = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2}\n\\]\nCovarianza y correlaciÃ³n de Pearson:\n\\[\n\\sigma_{XY} = \\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\n\\[\nr = \\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#diagramas-de-dispersiÃ³n",
    "href": "labs/lab02_epg.html#diagramas-de-dispersiÃ³n",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "2 Diagramas de DispersiÃ³n",
    "text": "2 Diagramas de DispersiÃ³n\nUn diagrama de dispersiÃ³n es la representaciÃ³n grÃ¡fica de pares de observaciones \\((x_i, y_i)\\), permitiendo visualizar la relaciÃ³n entre dos variables.\nEjemplos famosos: - Ley de Hooke - Ley de Hubble-LemaÃ®tre - Ondas gravitacionales (LIGO)\nEjemplo aplicado: analizar el rendimiento de automÃ³viles respecto a su peso."
  },
  {
    "objectID": "labs/lab02_epg.html#prueba-de-hipÃ³tesis-sobre-la-correlaciÃ³n",
    "href": "labs/lab02_epg.html#prueba-de-hipÃ³tesis-sobre-la-correlaciÃ³n",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "3 Prueba de HipÃ³tesis sobre la CorrelaciÃ³n",
    "text": "3 Prueba de HipÃ³tesis sobre la CorrelaciÃ³n\nSe desea probar:\n\\[\nH_0: \\rho = 0 \\quad \\text{vs.} \\quad H_1: \\rho \\neq 0\n\\]\nEl error estÃ¡ndar del coeficiente de correlaciÃ³n es:\n\\[\ns_r = \\frac{1 - r^2}{\\sqrt{n - 2}}\n\\]\nEl estadÃ­stico de prueba es:\n\\[\nt = \\frac{r - \\rho}{s_r}\n\\]\ndonde \\(t \\sim t_{n-2}\\) (distribuciÃ³n t de Student con \\(n - 2\\) grados de libertad).\nSe rechaza \\(H_0\\) si \\(|t| &gt; t_{\\alpha/2, n-2}\\).\n\nUna correlaciÃ³n significativa no implica causalidad."
  },
  {
    "objectID": "labs/lab02_epg.html#ecuaciones-lineales",
    "href": "labs/lab02_epg.html#ecuaciones-lineales",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "4 Ecuaciones Lineales",
    "text": "4 Ecuaciones Lineales\nEn regresiÃ³n lineal simple, se busca modelar cÃ³mo cambia una variable dependiente \\(y\\) en funciÃ³n de una variable independiente \\(x\\).\nEl modelo lineal se plantea como:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\ndonde: - \\(\\beta_0\\): intercepto (ordenada al origen)\n- \\(\\beta_1\\): pendiente (efecto de \\(x\\) sobre \\(y\\))\nIncluyendo el error aleatorio \\(\\varepsilon\\):\n\\[\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n\\]\n\n\n4.1 Supuestos clÃ¡sicos del modelo lineal\n\n\\(\\varepsilon \\sim N(0, \\sigma^2)\\) (normalidad).\n\nHomocedasticidad: varianza constante de \\(\\varepsilon\\).\n\n\\(E(\\varepsilon) = 0\\).\n\nIndependencia entre los errores."
  },
  {
    "objectID": "labs/lab02_epg.html#mÃ©todo-de-mÃ­nimos-cuadrados-ols",
    "href": "labs/lab02_epg.html#mÃ©todo-de-mÃ­nimos-cuadrados-ols",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "5 MÃ©todo de MÃ­nimos Cuadrados (OLS)",
    "text": "5 MÃ©todo de MÃ­nimos Cuadrados (OLS)\nPara estimar \\(\\beta_0\\) y \\(\\beta_1\\), se minimiza la suma de los cuadrados de los residuos:\n\\[\n\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\n\\]\nLas soluciones son:\n\\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\]\n\\[\n\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\]\n\n\n5.1 Ejemplo\nCosto de mantenimiento anual de buses (USD) en funciÃ³n de los aÃ±os de operaciÃ³n.\nPasos: 1. Graficar el diagrama de dispersiÃ³n.\n2. Evaluar la relaciÃ³n entre variables.\n3. Calcular el coeficiente de correlaciÃ³n.\n4. Probar su significancia (\\(\\alpha = 0.05\\)).\n5. Estimar la ecuaciÃ³n del modelo.\n6. Calcular el costo estimado para un bus con 5 aÃ±os de operaciÃ³n."
  },
  {
    "objectID": "labs/lab02_epg.html#residuos",
    "href": "labs/lab02_epg.html#residuos",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "6 Residuos",
    "text": "6 Residuos\nLos residuos se definen como:\n\\[\n\\hat{\\varepsilon} = y - \\hat{y}\n\\]\nEl error estÃ¡ndar de la estimaciÃ³n mide la dispersiÃ³n de los valores observados de \\(y\\) respecto a la recta estimada:\n\\[\ns_{y,x} = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n - 2}}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#predicciÃ³n-e-intervalos-de-confianza",
    "href": "labs/lab02_epg.html#predicciÃ³n-e-intervalos-de-confianza",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "7 PredicciÃ³n e Intervalos de Confianza",
    "text": "7 PredicciÃ³n e Intervalos de Confianza\nUna estimaciÃ³n puntual no informa sobre la precisiÃ³n del pronÃ³stico.\nPor ello se construye un intervalo de confianza:\n\\[\n\\hat{y} \\pm t_{\\alpha/2, n-2} \\, s_{\\hat{y},x}\n\\]\nEl error estÃ¡ndar de predicciÃ³n se calcula como:\n\\[\ns_{\\hat{y},x} = s_{y,x} \\sqrt{1 + \\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]\ndonde \\(x_p\\) es el valor dado de \\(X\\).\n\nPara estimar el valor medio de muchos experimentos en \\(x_p\\):\n\\[\n\\hat{y} \\pm t_{\\alpha/2, n-2} \\, s_{\\hat{\\mu},x}\n\\]\ncon:\n\\[\ns_{\\hat{\\mu},x} = s_{y,x} \\sqrt{\\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#coeficiente-de-determinaciÃ³n-simple",
    "href": "labs/lab02_epg.html#coeficiente-de-determinaciÃ³n-simple",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "8 Coeficiente de DeterminaciÃ³n Simple",
    "text": "8 Coeficiente de DeterminaciÃ³n Simple\nEl coeficiente de determinaciÃ³n \\(R^2\\) mide la proporciÃ³n de la variabilidad en \\(y\\) explicada por el modelo:\n\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#prueba-de-hipÃ³tesis-en-la-regresiÃ³n",
    "href": "labs/lab02_epg.html#prueba-de-hipÃ³tesis-en-la-regresiÃ³n",
    "title": "Laboratorio 2_epg: CorrelaciÃ³n y RegresiÃ³n Lineal Simple",
    "section": "9 Prueba de HipÃ³tesis en la RegresiÃ³n",
    "text": "9 Prueba de HipÃ³tesis en la RegresiÃ³n\nSe plantea:\n\\[\nH_0: \\beta_1 = 0 \\quad \\text{vs.} \\quad H_1: \\beta_1 \\neq 0\n\\]\nEl error estÃ¡ndar del estimador es:\n\\[\ns_{\\hat{\\beta}_1} = \\frac{s_{y,x}}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]\ny el estadÃ­stico de prueba:\n\\[\nt = \\frac{\\hat{\\beta}_1 - \\beta_1}{s_{\\hat{\\beta}_1}}\n\\]\ndonde \\(t \\sim t_{n-2}\\).\nSe rechaza \\(H_0\\) si \\(|t| &gt; t_{\\alpha/2, n-2}\\).\n\n\nâœ… ConclusiÃ³n:\nLa correlaciÃ³n mide fuerza y direcciÃ³n de relaciÃ³n lineal;\nla regresiÃ³n permite cuantificar y predecir dicha relaciÃ³n, bajo supuestos estadÃ­sticos formales."
  },
  {
    "objectID": "labs/lab03_epg.html",
    "href": "labs/lab03_epg.html",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso EconometrÃ­a para la GestiÃ³n â€” FEN-UAH."
  },
  {
    "objectID": "labs/lab03_epg.html#regresiÃ³n-mÃºltiple",
    "href": "labs/lab03_epg.html#regresiÃ³n-mÃºltiple",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "1 RegresiÃ³n MÃºltiple",
    "text": "1 RegresiÃ³n MÃºltiple\nLo primero en un modelo de regresiÃ³n mÃºltiple es estudiar la relaciÃ³n entre las variables.\nPara ello se utiliza la matriz de correlaciÃ³n, donde se despliegan los coeficientes de correlaciÃ³n para cada par de variables.\nMulticolinealidad: ocurre cuando dos o mÃ¡s variables presentan una alta correlaciÃ³n entre ellas.\nEsto implica que existe una relaciÃ³n directa entre las variables, haciendo difÃ­cil determinar cuÃ¡nto aporta cada una a la explicaciÃ³n de la variable dependiente.\nDos variables con alta correlaciÃ³n no proporcionan informaciÃ³n adicional.\nRegla general para elegir variables:\n\nNo debe haber correlaciÃ³n alta entre variables predictoras o explicativas (\\(x\\)).\n\nSe debe preferir incluir variables independientes entre sÃ­."
  },
  {
    "objectID": "labs/lab03_epg.html#marco-teÃ³rico-modelo-clÃ¡sico-de-regresiÃ³n-mÃºltiple-lineal",
    "href": "labs/lab03_epg.html#marco-teÃ³rico-modelo-clÃ¡sico-de-regresiÃ³n-mÃºltiple-lineal",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "2 Marco TeÃ³rico: Modelo ClÃ¡sico de RegresiÃ³n MÃºltiple Lineal",
    "text": "2 Marco TeÃ³rico: Modelo ClÃ¡sico de RegresiÃ³n MÃºltiple Lineal\nEl modelo lineal mÃºltiple se puede escribir de forma matricial como:\n\\[\ny = 1_n \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + \\dots + x_k \\beta_k + \\varepsilon\n\\tag{3.1}\n\\]\no en forma compacta:\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.2}\n\\]\ndonde:\n- \\(Y\\) es el vector de observaciones dependientes (\\(n \\times 1\\)).\n- \\(X\\) es la matriz de observaciones de las variables explicativas (\\(n \\times (k+1)\\)).\n- \\(\\beta\\) es el vector de parÃ¡metros desconocidos (\\(\\beta_0, \\beta_1, \\dots, \\beta_k\\)).\n- \\(\\varepsilon\\) es el vector de errores aleatorios."
  },
  {
    "objectID": "labs/lab03_epg.html#supuestos-del-modelo-clÃ¡sico",
    "href": "labs/lab03_epg.html#supuestos-del-modelo-clÃ¡sico",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "3 Supuestos del Modelo ClÃ¡sico",
    "text": "3 Supuestos del Modelo ClÃ¡sico\n\n3.1 Supuesto 1\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.3}\n\\]\n\n\n3.2 Supuesto 2\n\\(X \\in \\mathbb{R}^{n \\times (k+1)}\\) tiene rango completo (condiciÃ³n de identificaciÃ³n).\n\n\n3.3 Supuesto 3\nEl error tiene esperanza condicional nula:\n\\[\nE[\\varepsilon | X] =\n\\begin{bmatrix}\nE[\\varepsilon_1|X] \\\\\nE[\\varepsilon_2|X] \\\\\n\\vdots \\\\\nE[\\varepsilon_n|X]\n\\end{bmatrix}\n= 0\n\\tag{3.4}\n\\]\nAdemÃ¡s:\n\\[\n\\text{Var}[\\varepsilon_j | X] = \\sigma^2, \\quad j = 1, \\dots, n\n\\tag{3.5}\n\\]\n\\[\n\\text{Cov}[\\varepsilon_i, \\varepsilon_j | X] = 0, \\quad i \\neq j\n\\tag{3.6}\n\\]\nEsto implica homocedasticidad (varianza constante) y no autocorrelaciÃ³n entre los errores.\n\n\n3.4 Supuesto 4\n\\[\nE[\\varepsilon \\varepsilon'] = \\sigma^2 I_n\n\\tag{3.7}\n\\]\n\n\n3.5 Supuesto 5\n\\(X\\) es no estocÃ¡stica, es decir, se asume conocida o fija en el muestreo.\n\n\n3.6 Supuesto 6\nLos errores son normales:\n\\[\n\\varepsilon | X \\sim N(0, \\sigma^2 I_n)\n\\tag{3.8}\n\\]"
  },
  {
    "objectID": "labs/lab03_epg.html#estimadores-de-la-regresiÃ³n",
    "href": "labs/lab03_epg.html#estimadores-de-la-regresiÃ³n",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "4 Estimadores de la RegresiÃ³n",
    "text": "4 Estimadores de la RegresiÃ³n\nLos estimadores se pueden obtener por dos vÃ­as:\n\nMÃ¡xima verosimilitud, dada la normalidad de los errores.\n\nMÃ­nimos cuadrados ordinarios (OLS).\n\nMinimizamos la suma de cuadrados de los errores:\n\\[\nS(\\beta) = (Y - X\\beta)'(Y - X\\beta)\n\\tag{3.9}\n\\]\nDesarrollando:\n\\[\nS(\\beta) = Y'Y - 2Y'X\\beta + \\beta'(X'X)\\beta\n\\tag{3.10}\n\\]\nDerivando respecto a \\(\\beta\\) e igualando a cero:\n\\[\nS'(\\beta) = -2X'Y + 2(X'X)\\beta = 0\n\\tag{3.11}\n\\]\nDe donde obtenemos el estimador:\n\\[\n\\hat{\\beta} = (X'X)^{-1}X'Y\n\\tag{3.12}\n\\]\nEl vector estimado de valores ajustados es:\n\\[\n\\hat{Y} = X\\hat{\\beta} = X(X'X)^{-1}X'Y\n\\tag{3.13}\n\\]\nY los residuos estimados:\n\\[\n\\hat{\\varepsilon} = Y - \\hat{Y} = (I - X(X'X)^{-1}X')Y\n\\tag{3.14}\n\\]\n\nPropiedades Ãºtiles:\n\\[\nX'\\hat{\\varepsilon} = 0, \\qquad \\hat{Y}'\\hat{\\varepsilon} = 0\n\\tag{3.15}\n\\]\nLa variaciÃ³n cuadrÃ¡tica de los residuos es:\n\\[\n\\hat{\\varepsilon}'\\hat{\\varepsilon} = Y'(I - X(X'X)^{-1}X')Y\n\\tag{3.16}\n\\]"
  },
  {
    "objectID": "labs/lab03_epg.html#coeficiente-de-determinaciÃ³n-r2",
    "href": "labs/lab03_epg.html#coeficiente-de-determinaciÃ³n-r2",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "5 Coeficiente de DeterminaciÃ³n (\\(R^2\\))",
    "text": "5 Coeficiente de DeterminaciÃ³n (\\(R^2\\))\nA partir de (3.16):\n\\[\nY'Y = (\\hat{Y} + \\hat{\\varepsilon})'(\\hat{Y} + \\hat{\\varepsilon}) = \\hat{Y}'\\hat{Y} + \\hat{\\varepsilon}'\\hat{\\varepsilon}\n\\tag{3.17}\n\\]\nEn tÃ©rminos de varianzas:\n\\[\n\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2 = \\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2 + \\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2\n\\tag{3.18}\n\\]\nPor tanto:\n\\[\nR^2 = 1 - \\frac{\\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n= \\frac{\\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n\\tag{3.19}\n\\]\n\n\n5.1 Contraste F global\nHipÃ³tesis:\n\\[\nH_0: \\beta_1 = \\beta_2 = \\dots = \\beta_k = 0\n\\tag{3.20}\n\\]\nEl estadÃ­stico es:\n\\[\nF = \\frac{R^2 / k}{(1 - R^2) / (n - k - 1)} \\sim F_{k,\\, n - k - 1}\n\\tag{3.21}\n\\]\nRechazamos \\(H_0\\) si \\(P(F \\ge f) \\le \\alpha\\).\n\n\n\n5.2 Propiedades de los estimadores\n\\[\nE[\\hat{\\beta}] = \\beta, \\qquad\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X'X)^{-1}\n\\tag{3.22}\n\\]\nPara los residuos:\n\\[\nE[\\hat{\\varepsilon}] = 0, \\qquad\n\\text{Cov}(\\hat{\\varepsilon}) = \\sigma^2 [I - X(X'X)^{-1}X']\n\\tag{3.23}\n\\]\nEstimador insesgado de \\(\\sigma^2\\):\n\\[\ns^2 = \\frac{\\hat{\\varepsilon}'\\hat{\\varepsilon}}{n - k - 1}\n\\tag{3.24}\n\\]\n\n\n\n5.3 Contraste individual para \\(\\beta_j\\)\n\\[\nH_0: \\beta_j = \\beta_j^*, \\qquad H_1: \\beta_j \\neq \\beta_j^*\n\\tag{3.25}\n\\]\nEl estadÃ­stico:\n\\[\nt_j = \\frac{\\hat{\\beta}_j - \\beta_j^*}{s \\sqrt{(X'X)^{-1}_{jj}}}\n\\sim t_{n - k - 1}\n\\tag{3.26}\n\\]\nRechazamos \\(H_0\\) si \\(|t_j| &gt; t_{\\alpha/2,\\, n - k - 1}\\).\nEl p-valor se obtiene como:\n\\[\np = P(|t_j| &gt; |t_j^{obs}|)\n\\tag{3.27}\n\\]\n\n\n\n5.4 Intervalos de confianza\nPara cada \\(\\beta_j\\):\n\\[\n\\hat{\\beta}_j \\pm t_{\\alpha/2,\\, n - k - 1} \\, s \\sqrt{(X'X)^{-1}_{jj}}\n\\tag{3.28}\n\\]\nPara la varianza del error:\n\\[\n\\left[\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, 1 - \\alpha/2}},\n\\quad\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, \\alpha/2}}\n\\right]\n\\tag{3.29}\n\\]\n\n\n\n5.5 PredicciÃ³n\nPara un nuevo vector \\(x_0\\) (incluyendo el valor 1 si el modelo tiene constante):\n\\[\n\\hat{y}_0 = x_0' \\hat{\\beta}\n\\tag{3.30}\n\\]\nVarianza del estimador:\n\\[\nh_0 = x_0'(X'X)^{-1}x_0\n\\tag{3.31}\n\\]\nIntervalo de confianza para la predicciÃ³n:\n\\[\n\\hat{y}_0 \\pm s \\sqrt{1 + h_0} \\; t_{\\alpha/2,\\, n - k - 1}\n\\tag{3.32}\n\\]\n\n\n\n5.6 DiagnÃ³sticos de supuestos\nDurbinâ€“Watson (autocorrelaciÃ³n de errores):\n\\[\nD = \\frac{\\sum_{i=2}^{n} (e_i - e_{i-1})^2}{\\sum_{i=1}^{n} e_i^2}\n\\tag{3.33}\n\\]\n\nSi \\(D \\approx 2\\): no hay autocorrelaciÃ³n.\n\nSi \\(D \\approx 0\\): autocorrelaciÃ³n positiva.\n\nSi \\(D \\approx 4\\): autocorrelaciÃ³n negativa.\n\n\nTest de Breuschâ€“Pagan (homocedasticidad):\n\\[\nH_0: \\text{Var}(\\varepsilon_i) = \\sigma^2 \\quad \\forall i\n\\tag{3.34}\n\\]\nSi el valor-p es mayor que 0.05, se asume que los errores tienen varianza constante.\n\n\nâœ… Resumen:\nEl modelo clÃ¡sico de regresiÃ³n mÃºltiple lineal supone linealidad, independencia, homocedasticidad y normalidad.\nLos estimadores OLS son BLUE (Best Linear Unbiased Estimators) bajo estos supuestos."
  },
  {
    "objectID": "labs/lab03_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab03_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "6 AplicaciÃ³n en R (sobre los contenidos anteriores)",
    "text": "6 AplicaciÃ³n en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (segÃºn tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# VerificaciÃ³n de archivos necesarios\nif (!file.exists(file.path(data_path, \"costos.xlsx\"))) {\n  stop(\"âš ï¸ No se encontrÃ³ 'costos.xlsx' en data_path\")\n}\n\n# LibrerÃ­as necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"corrplot\",\"lmtest\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(corrplot)\nlibrary(lmtest)\n\n\n# Cargar datos\ndatos &lt;- read.xlsx(file.path(data_path, \"costos.xlsx\"), sheet = \"Hoja1\", colNames = TRUE)\n\n# Matriz de correlaciÃ³n y grÃ¡ficos exploratorios\nr &lt;- cor(datos, use = \"pairwise.complete.obs\")\npairs(datos, main = \"GrÃ¡ficos de dispersiÃ³n por pares\")\n\n\n\n\n\n\n\ncorrplot(r, method = \"circle\", type = \"lower\", diag = FALSE,\n         tl.col = \"black\", tl.cex = 1, tl.offset = 0.1, tl.srt = 45)\n\n\n\n\n\n\n\n\n\n# Modelo de regresiÃ³n mÃºltiple (con intercepto)\nmodelo &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones, data = datos)\n\n# EstadÃ­sticos del modelo\nsummary(modelo)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones, \n    data = datos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7157  -2827    768   1449   9407 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          19796.44   12787.83   1.548 0.156013    \nHoras_maquina           65.44       6.74   9.709 4.57e-06 ***\nNumero_preparaciones   322.21      58.66   5.493 0.000384 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4951 on 9 degrees of freedom\nMultiple R-squared:  0.9472,    Adjusted R-squared:  0.9354 \nF-statistic: 80.66 on 2 and 9 DF,  p-value: 1.792e-06\n\n# Guardando los residuos\nepsilon &lt;- modelo$residuals\n\n\n# AnÃ¡lisis de residuos\nhist(epsilon, main = \"Histograma de residuos\", col = \"#cdeac0\", border = \"#2b9348\")\n\n\n\n\n\n\n\nplot(density(epsilon), main = \"Densidad de residuos\")\n\n\n\n\n\n\n\nshapiro.test(epsilon)  # Normalidad de residuos\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95577, p-value = 0.7222\n\n# AutocorrelaciÃ³n de residuos (Durbin-Watson) y heterocedasticidad (Breusch-Pagan)\ndwtest(modelo, alternative = \"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0815, p-value = 0.7416\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 1.0153, df = 2, p-value = 0.6019\n\n\n\n# CÃ¡lculo manual del estadÃ­stico F (usando un R2 dado)\nR2 &lt;- 0.9472\nF  &lt;- (R2/2) / ((1 - R2) / (12 - 3))\nF\n\n[1] 80.72727\n\n# Valor crÃ­tico F (Î± = 0.05, gl1 = 2, gl2 = 9)\nqf(0.05, 2, 9, lower.tail = FALSE)\n\n[1] 4.256495\n\n\n\n# DesviaciÃ³n estÃ¡ndar del error\ns &lt;- sqrt(sum(epsilon^2) / (12 - 2 - 1))\ns\n\n[1] 4951.106\n\n# Intervalos de confianza para coeficientes\nconfint(modelo)\n\n                           2.5 %     97.5 %\n(Intercept)          -9131.64046 48724.5095\nHoras_maquina           50.18894    80.6827\nNumero_preparaciones   189.50994   454.9046\n\nout &lt;- summary(modelo)\nout$coefficients[, 1]  # Betas\n\n         (Intercept)        Horas_maquina Numero_preparaciones \n         19796.43452             65.43582            322.20728 \n\nout$coefficients[, 2]  # Error estÃ¡ndar\n\n         (Intercept)        Horas_maquina Numero_preparaciones \n        12787.827235             6.739972            58.659648 \n\n# EstimaciÃ³n manual de IC para un coeficiente (ejemplo)\ntcrit &lt;- -1 * qt(0.025, 12 - 2 - 1, lower.tail = FALSE)\nBHM  &lt;- 65.44\nsbhm &lt;- 6.74\nlimitsupBHM &lt;- BHM + tcrit * sbhm\nlimitinfBHM &lt;- BHM - tcrit * sbhm\nc(liminfBHM = limitinfBHM, limitsupBHM = limitsupBHM)\n\n  liminfBHM limitsupBHM \n   80.68694    50.19306 \n\n\n\n# IC para la varianza del error (chi-cuadrado)\ngamma1 &lt;- qchisq(0.025, 12 - 2 - 1)\ngamma2 &lt;- qchisq(0.975, 12 - 2 - 1)\ns2_LI  &lt;- (12 - 2 - 1) * s^2 / gamma2\ns2_LS  &lt;- (12 - 2 - 1) * s^2 / gamma1\nc(s2_LI = s2_LI, s2_LS = s2_LS)\n\n   s2_LI    s2_LS \n11597739 81699732 \n\n\n\n# PredicciÃ³n para un nuevo valor\nnuevo &lt;- data.frame(Horas_maquina = c(2000), Numero_preparaciones = c(220))\nvalor_predicho  &lt;- predict(object = modelo, newdata = nuevo)\nvalor_predicho2 &lt;- predict(object = modelo, newdata = nuevo, interval = \"confidence\")\nvalor_predicho\n\n       1 \n221553.7 \n\nvalor_predicho2\n\n       fit      lwr      upr\n1 221553.7 210265.6 232841.8\n\n\n\n# PredicciÃ³n manual con matrices\nX &lt;- cbind(1, datos$Horas_maquina, datos$Numero_preparaciones)\nM &lt;- solve(t(X) %*% X)\nbeta &lt;- M %*% t(X) %*% datos$Costos_generales\n\nx0 &lt;- c(1, 2000, 220)\nh0 &lt;- t(x0) %*% M %*% x0\ny0 &lt;- t(beta) %*% x0\n\ny_limsup &lt;- y0 + s * sqrt(1 + h0) * qt(0.975, 12 - 2 - 1, lower.tail = FALSE)\ny_liminf &lt;- y0 - s * sqrt(1 + h0) * qt(0.975, 12 - 2 - 1, lower.tail = FALSE)\nc(y_liminf = y_liminf, y_limsup = y_limsup)\n\ny_liminf y_limsup \n237455.4 205651.9 \n\n\n\n# GrÃ¡fico: valor Y estimado vs Y real\nplot(modelo$fitted.values, datos$Costos_generales,\n     main = \"RevisiÃ³n Valor Real vs Valor Predicho\",\n     xlab = \"Y estimado\", ylab = \"Y real\")\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\n# Modelo sin constante\nmodelo2 &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones - 1, data = datos)\nsummary(modelo2)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones - \n    1, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9042.2 -3486.9   739.7  3467.0  9300.3 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \nHoras_maquina          69.994      6.472  10.814 7.72e-07 ***\nNumero_preparaciones  390.723     41.098   9.507 2.52e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5286 on 10 degrees of freedom\nMultiple R-squared:  0.9992,    Adjusted R-squared:  0.999 \nF-statistic:  6095 on 2 and 10 DF,  p-value: 3.699e-16\n\nepsilon2 &lt;- modelo2$residuals\nhist(epsilon2, main = \"Histograma de residuos (sin constante)\", col = \"#cdeac0\", border = \"#2b9348\")\n\n\n\n\n\n\n\nplot(density(epsilon2), main = \"Densidad de residuos (sin constante)\")\n\n\n\n\n\n\n\nshapiro.test(epsilon2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon2\nW = 0.97973, p-value = 0.9825\n\ndwtest(modelo2, alternative = \"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo2\nDW = 2.1284, p-value = 0.9776\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo2\nBP = 0.33027, df = 1, p-value = 0.5655\n\nplot(modelo2$fitted.values, datos$Costos_generales,\n     main = \"RevisiÃ³n Valor Real vs Valor Predicho (sin constante)\",\n     xlab = \"Y estimado\", ylab = \"Y real\")\nabline(a = 0, b = 1, col = \"red\")"
  },
  {
    "objectID": "labs/lab03_epg.html#bibliografÃ­a",
    "href": "labs/lab03_epg.html#bibliografÃ­a",
    "title": "Laboratorio 3_epg: RegresiÃ³n MÃºltiple",
    "section": "7 BibliografÃ­a",
    "text": "7 BibliografÃ­a\nCrespo, F. A. (2021). RegresiÃ³n MÃºltiple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "codigos.html#econometrÃ­a-para-la-gestiÃ³n",
    "href": "codigos.html#econometrÃ­a-para-la-gestiÃ³n",
    "title": "Material de Estudio",
    "section": "",
    "text": "ImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresiÃ³n mÃºltiple, EliminaciÃ³n de variables irrelevantes, RegresiÃ³n polinomial, etc.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n prÃ¡ctica en R.\nVer Laboratorio\n\n\n\nModelaciÃ³n de variables dependientes binarias.\nVer Laboratorio\n\n\n\nModelos de efectos fijos y aleatorios con R.\nVer Laboratorio\n\n\n\nEvaluaciÃ³n de polÃ­ticas pÃºblicas y experimentos naturales.\nVer Laboratorio\n\n\n\nDiseÃ±os RD y RD local en contextos aplicados.\nVer Laboratorio\n\n\n\nIV con heterogeneidad y dos etapas en R.\nVer Laboratorio\n\n\n\n\n\n## EconometrÃ­a economÃ­a\n\n\n::::::::::::: labs-grid ::: lab-card ### Lab 1_ec: IntroducciÃ³n y EstadÃ­stica Descriptiva\n\n\nImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 2_ec: RegresiÃ³n Lineal Simple\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 3_ec: RegresiÃ³n Lineal MÃºltiple\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 4_ec: Usos y aplicaciones de RLM\n\n\nOtras funciones para estudiar la regresiÃ³n mÃºltiple, EliminaciÃ³n de variables irrelevantes, RegresiÃ³n polinomial, etc.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 5_ec: Variables Instrumentales\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n prÃ¡ctica en R.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 6_ec: Modelos de Probabilidad Lineal, Logit y Probit\n\n\nModelaciÃ³n de variables dependientes binarias.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 7_ec: Panel de Datos\n\n\nModelos de efectos fijos y aleatorios con R.\nVer Laboratorio :::\n\n\n::: lab-card ### Lab 8_ec: Diferencias en Diferencias\n\n\nEvaluaciÃ³n de polÃ­ticas pÃºblicas y experimentos naturales.\nVer Laboratorio ::: :::::::::::::\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "codigos.html#econometrÃ­a-economÃ­a",
    "href": "codigos.html#econometrÃ­a-economÃ­a",
    "title": "Material de Estudio",
    "section": "",
    "text": "ImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresiÃ³n mÃºltiple, EliminaciÃ³n de variables irrelevantes, RegresiÃ³n polinomial, etc.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n prÃ¡ctica en R.\nVer Laboratorio\n\n\n\nModelaciÃ³n de variables dependientes binarias.\nVer Laboratorio\n\n\n\nModelos de efectos fijos y aleatorios con R.\nVer Laboratorio\n\n\n\nEvaluaciÃ³n de polÃ­ticas pÃºblicas y experimentos naturales.\nVer Laboratorio\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "codigos.html#laboratorios",
    "href": "codigos.html#laboratorios",
    "title": "Material de Estudio",
    "section": "",
    "text": "ImportaciÃ³n de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimaciÃ³n e interpretaciÃ³n del modelo OLS bÃ¡sico.\nVer Laboratorio\n\n\n\nExtensiÃ³n del modelo con variables adicionales y anÃ¡lisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresiÃ³n mÃºltiple, EliminaciÃ³n de variables irrelevantes, RegresiÃ³n polinomial, etc.\nVer Laboratorio\n\n\n\nMotivaciÃ³n, teorÃ­a y aplicaciÃ³n de logit y probit.\nVer Laboratorio\n\n\n\n\nğŸ’¡ Cada laboratorio estÃ¡ alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automÃ¡ticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "labs/lab04_epg.html",
    "href": "labs/lab04_epg.html",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso EconometrÃ­a para la GestiÃ³n â€” FEN-UAH."
  },
  {
    "objectID": "labs/lab04_epg.html#uso-de-la-regresiÃ³n-mÃºltiple",
    "href": "labs/lab04_epg.html#uso-de-la-regresiÃ³n-mÃºltiple",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "1 Uso de la RegresiÃ³n MÃºltiple",
    "text": "1 Uso de la RegresiÃ³n MÃºltiple"
  },
  {
    "objectID": "labs/lab04_epg.html#anÃ¡lisis-de-correlaciones-simultÃ¡neas",
    "href": "labs/lab04_epg.html#anÃ¡lisis-de-correlaciones-simultÃ¡neas",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "2 AnÃ¡lisis de Correlaciones SimultÃ¡neas",
    "text": "2 AnÃ¡lisis de Correlaciones SimultÃ¡neas\nEl anÃ¡lisis inicial en regresiÃ³n mÃºltiple se centra en la relaciÃ³n entre las variables explicativas. Una herramienta fundamental es la matriz de correlaciÃ³n.\nUna alta correlaciÃ³n entre las variables explicativas (\\(X_i, X_j\\)) es un indicio de multicolinealidad, lo que puede inestabilizar los coeficientes estimados.\nLa librerÃ­a MASS es comÃºnmente utilizada en R, aunque la funciÃ³n cor() pertenece al paquete base.\nR\nlibrary(MASS) # Ejemplo de uso # Permite ver correlaciones simultÃ¡neas cor(Datos[, c(\"X1\", \"X2\", \"X3\")])"
  },
  {
    "objectID": "labs/lab04_epg.html#eliminaciÃ³n-de-variables-irrelevantes-del-modelo",
    "href": "labs/lab04_epg.html#eliminaciÃ³n-de-variables-irrelevantes-del-modelo",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "3 4.2 EliminaciÃ³n de Variables Irrelevantes del Modelo",
    "text": "3 4.2 EliminaciÃ³n de Variables Irrelevantes del Modelo\nDurante la construcciÃ³n del modelo, conviene eliminar variables irrelevantes, es decir, no significativas, manteniendo la significancia global del modelo.\nTambiÃ©n puede ser Ãºtil agregar interacciones entre variables explicativas para capturar efectos conjuntos sobre la respuesta. Ejemplo:\nX3â€…â€Š=â€…â€ŠX2Ã—X1X_3 ;=; X_2 X_1X3â€‹=X2â€‹Ã—X1â€‹\nEn R, se implementa asÃ­:\nmodelo_inter &lt;- lm(mpg ~ wt * hp, data = mtcars) summary(modelo_inter)"
  },
  {
    "objectID": "labs/lab04_epg.html#regresiÃ³n-polinomial",
    "href": "labs/lab04_epg.html#regresiÃ³n-polinomial",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "4 RegresiÃ³n Polinomial",
    "text": "4 RegresiÃ³n Polinomial\nLa regresiÃ³n polinomial se utiliza para modelar relaciones no lineales entre \\(X\\) y \\(Y\\) manteniendo la linealidad en los parÃ¡metros (\\(\\beta\\)).\nEl modelo de regresiÃ³n polinomial de grado \\(k\\) es:\n$$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\cdots + \\beta_k x^k + \\varepsilon$$\ndonde \\(\\varepsilon\\) representa el tÃ©rmino de perturbaciÃ³n aleatoria.\nNo existe una regla estricta para determinar el grado \\(k\\), pero la prÃ¡ctica sugiere incrementar el grado del polinomio hasta que el nuevo tÃ©rmino deje de ser significativo. Esto se evalÃºa formalmente mediante una prueba ANOVA (o prueba \\(F\\)) que compara la mejora de ajuste entre el modelo de grado \\(k\\) y el modelo de grado \\(k+1\\)."
  },
  {
    "objectID": "labs/lab04_epg.html#transformaciÃ³n-de-variables",
    "href": "labs/lab04_epg.html#transformaciÃ³n-de-variables",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "5 TransformaciÃ³n de Variables",
    "text": "5 TransformaciÃ³n de Variables\nTanto la variable dependiente (\\(Y\\)) como las independientes (\\(X_i\\)) pueden transformarse mediante funciones matemÃ¡ticas (\\(f(\\cdot)\\)) para:\n\nEstabilizar la varianza de los residuos (resolver heterocedasticidad).\nMejorar la linealidad de la relaciÃ³n.\nNormalizar la distribuciÃ³n de los errores.\n\n$$yâ€™ = f(y), \\qquad xâ€™ = g(x)$$\n\n5.1 TransformaciÃ³n LogarÃ­tmica\nSi se utiliza el logaritmo y alguna variable toma el valor cero (\\(0\\)), se debe aplicar un desplazamiento para evitar la indeterminaciÃ³n, usando:\n$$\\log(1 + y) \\quad \\text{o} \\quad \\log(1 + x)$$\n\n\n5.2 Otras Transformaciones\nOtras transformaciones comunes para estabilizar la varianza incluyen la raÃ­z cuadrada:\n$$yâ€™ = \\sqrt{y}$$\nEl objetivo principal es encontrar la transformaciÃ³n que minimice la varianza de los residuos (\\(\\sigma_{\\varepsilon}^2\\)) y asegure que el modelo cumpla con los supuestos clÃ¡sicos de la regresiÃ³n lineal."
  },
  {
    "objectID": "labs/lab04_epg.html#conclusiÃ³n",
    "href": "labs/lab04_epg.html#conclusiÃ³n",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "6 ConclusiÃ³n",
    "text": "6 ConclusiÃ³n\nLa fase de especificaciÃ³n del modelo, que abarca el manejo de multicolinealidad, la selecciÃ³n de variables, la incorporaciÃ³n de efectos no lineales (polinomiales) y las transformaciones adecuadas, es crucial. Estas herramientas permiten construir modelos economÃ©tricos sÃ³lidos, vÃ¡lidos y parsimoniosos, mejorando la interpretaciÃ³n, la validez estadÃ­stica y la capacidad predictiva del modelo de regresiÃ³n mÃºltiple."
  },
  {
    "objectID": "labs/lab04_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab04_epg.html#aplicaciÃ³n-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "7 AplicaciÃ³n en R (sobre los contenidos anteriores)",
    "text": "7 AplicaciÃ³n en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (segÃºn tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\nif (!file.exists(file.path(data_path, \"millaje.txt\"))) {\n  message(\"â„¹ï¸ Aviso: 'millaje.txt' no se encontrÃ³ en data_path; el bloque DAAG usa dataset interno 'carprice'.\")\n}\n\n\n# LibrerÃ­as necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"MASS\",\"corrplot\",\"lmtest\",\"DAAG\",\"ggplot2\"))\nlibrary(tidyverse); library(openxlsx); library(MASS); library(corrplot)\nlibrary(lmtest); library(DAAG); library(ggplot2)\n\n\n7.1 1) Ejemplo publicitario: tv, radio, periÃ³dico â†’ ventas\n\ntv &lt;- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2, 228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6, 95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1, 175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9, 7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5, 139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5, 5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0, 139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177.0, 283.6, 232.1)\nradio &lt;- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0, 35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9, 12.6, 3.5, 29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1, 43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5, 15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5, 2.0, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3, 33.0, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5, 43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14.0, 31.6, 3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11.0, 0.3, 0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3, 0.8, 36.9, 16.0, 26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0, 39.6, 2.9, 27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2, 5.7, 14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6, 43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2, 23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0, 2.6, 5.4, 5.7, 43.0, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8, 4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6)\nperiodico &lt;- c(69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2, 4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5, 49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0, 0.3, 7.4, 8.5, 5.0, 45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3, 31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0, 41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2, 11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4, 23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2, 73.4, 51.4, 9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8, 100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2, 2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6, 12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6, 8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9.0, 8.7, 44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3, 45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6, 6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6, 8.3, 27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0, 31.6, 3.6, 6.0, 13.8, 8.1, 6.4, 66.2, 8.7)\nventas &lt;- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5, 9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4, 8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6, 21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6, 3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0, 12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4)\ndatos &lt;- data.frame(tv, radio, periodico, ventas)\n\npairs(datos)\n\n\n\n\n\n\n\nr &lt;- cor(datos)\ncorrplot(r, method=\"circle\", type=\"lower\", diag=FALSE, tl.col=\"black\", tl.cex=1, tl.offset=0.1, tl.srt=45)\n\n\n\n\n\n\n\n\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio + periodico, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + periodico, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\ntv           0.045765   0.001395  32.809   &lt;2e-16 ***\nradio        0.188530   0.008611  21.893   &lt;2e-16 ***\nperiodico   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7977 -0.8752  0.2422  1.1708  2.8328 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\ntv           0.04575    0.00139  32.909   &lt;2e-16 ***\nradio        0.18799    0.00804  23.382   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.681 on 197 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 \nF-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones,\n                    theta = 18, phi = 20,\n                    col = \"lightblue\", shade = 0.1,\n                    xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\",\n                    main = \"PredicciÃ³n ventas ~ TV y Radio\")\n\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo), superficie)\npoints(observaciones, col = \"red\", pch = 16)\nsegments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nshapiro.test(modelo$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo$residuals\nW = 0.91804, p-value = 4.19e-09\n\nhist(modelo$residuals); plot(density(modelo$residuals))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0808, p-value = 0.5656\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 4.8093, df = 2, p-value = 0.0903\n\nplot(modelo$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\ntv_radio &lt;- tv*radio\nmodelo_interaccion &lt;- lm(formula = ventas ~ tv + radio + tv*radio, data = datos)\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***\ntv          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \ntv:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_interaccion$residuals); hist(modelo_interaccion$residuals); plot(density(modelo_interaccion$residuals))\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion$residuals\nW = 0.8469, p-value = 3.047e-13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo_interaccion,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion\nDW = 2.2236, p-value = 0.1103\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion\nBP = 14.324, df = 3, p-value = 0.002495\n\nplot(modelo_interaccion$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo_interaccion, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones, theta = 18, phi = 20, col = \"lightblue\",\n                    shade = 0.1, xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\", main = \"PredicciÃ³n ventas ~ TV y Radio (interacciÃ³n)\")\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo_interaccion), superficie)\npoints(observaciones, col = \"red\", pch = 16); segments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nanova(modelo, modelo_interaccion)\n\nAnalysis of Variance Table\n\nModel 1: ventas ~ tv + radio\nModel 2: ventas ~ tv + radio + tv * radio\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    197 556.91                                  \n2    196 174.48  1    382.43 429.59 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodelo_interaccion_1 &lt;- lm(formula = ventas ~ tv + radio + I(tv^2)+ tv*radio, data = datos)\nsummary(modelo_interaccion_1)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + I(tv^2) + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9949 -0.2969 -0.0066  0.3798  1.1686 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.137e+00  1.927e-01  26.663  &lt; 2e-16 ***\ntv           5.092e-02  2.232e-03  22.810  &lt; 2e-16 ***\nradio        3.516e-02  5.901e-03   5.959 1.17e-08 ***\nI(tv^2)     -1.097e-04  6.893e-06 -15.920  &lt; 2e-16 ***\ntv:radio     1.077e-03  3.466e-05  31.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6238 on 195 degrees of freedom\nMultiple R-squared:  0.986, Adjusted R-squared:  0.9857 \nF-statistic:  3432 on 4 and 195 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_interaccion_1$fitted.values, datos$ventas); lines(c(0,27), c(0,27))\n\n\n\n\n\n\n\nhist(modelo_interaccion_1$residuals); plot(density(modelo_interaccion_1$residuals)); shapiro.test(modelo_interaccion_1$residuals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion_1$residuals\nW = 0.80888, p-value = 6.359e-15\n\ndwtest(modelo_interaccion_1,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion_1)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion_1\nDW = 2.204, p-value = 0.1432\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion_1\nBP = 19.986, df = 4, p-value = 0.0005027\n\n\n\n\n7.2 2) Ejemplo adicional: dataset carprice (DAAG)\n\ndata(carprice)\npairs(carprice[,-c(1,8,9)]); \n\n\n\n\n\n\n\ncorrplot(cor(carprice[,-c(1,8,9)]),method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n\n\n\n\n\n\n\n\n\ncarprice1.lm &lt;- lm(gpm100 ~ Type + Min.Price + Price + Max.Price + Range.Price, data=carprice)\nsummary(carprice1.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Min.Price + Price + Max.Price + \n    Range.Price, data = carprice)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.48431 -0.22731 -0.03417  0.19004  0.49651 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.2874     0.1531  21.467  &lt; 2e-16 ***\nTypeLarge     0.3235     0.1733   1.867   0.0695 .  \nTypeMidsize   0.1849     0.1660   1.114   0.2722    \nTypeSmall    -0.3895     0.1681  -2.317   0.0258 *  \nTypeSporty    0.2055     0.1747   1.176   0.2467    \nTypeVan       1.3487     0.1927   6.997 2.16e-08 ***\nMin.Price     0.6997     0.9894   0.707   0.4836    \nPrice        -1.3773     1.9829  -0.695   0.4914    \nMax.Price     0.7106     0.9943   0.715   0.4791    \nRange.Price       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3059 on 39 degrees of freedom\nMultiple R-squared:  0.8149,    Adjusted R-squared:  0.777 \nF-statistic: 21.47 on 8 and 39 DF,  p-value: 4.768e-12\n\ncarprice2.lm &lt;- lm(gpm100 ~ Type + Max.Price, data=carprice)\nsummary(carprice2.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Max.Price, data = carprice)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5468 -0.2379 -0.0241  0.1842  0.5311 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.298110   0.150746  21.879  &lt; 2e-16 ***\nTypeLarge    0.368524   0.165541   2.226   0.0316 *  \nTypeMidsize  0.214006   0.162030   1.321   0.1939    \nTypeSmall   -0.386042   0.162609  -2.374   0.0224 *  \nTypeSporty   0.209540   0.166663   1.257   0.2158    \nTypeVan      1.367463   0.183242   7.463 3.69e-09 ***\nMax.Price    0.029982   0.006837   4.385 7.89e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3027 on 41 degrees of freedom\nMultiple R-squared:  0.8096,    Adjusted R-squared:  0.7817 \nF-statistic: 29.05 on 6 and 41 DF,  p-value: 2.782e-13\n\n\n\nepsilon &lt;- carprice2.lm$residuals\nhist(epsilon); shapiro.test(epsilon)\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95934, p-value = 0.09497\n\ndwtest(carprice2.lm,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  carprice2.lm\nDW = 1.7034, p-value = 0.295\nalternative hypothesis: true autocorrelation is not 0\n\ns &lt;- sqrt(sum(epsilon^2)/(41))\nplot(carprice$gpm100, carprice2.lm$fitted.values); lines(c(2,5.5),c(2,5.5))\n\n\n\n\n\n\n\nconfint(carprice2.lm)\n\n                  2.5 %      97.5 %\n(Intercept)  2.99367329  3.60254758\nTypeLarge    0.03420650  0.70284211\nTypeMidsize -0.11322061  0.54123280\nTypeSmall   -0.71443686 -0.05764682\nTypeSporty  -0.12704297  0.54612217\nTypeVan      0.99739791  1.73752784\nMax.Price    0.01617507  0.04378964\n\nout &lt;- summary(carprice2.lm); out$coefficients[ , 1]; out$coefficients[ , 2]\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n 3.29811043  0.36852431  0.21400610 -0.38604184  0.20953960  1.36746287 \n  Max.Price \n 0.02998236 \n\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n0.150745713 0.165541483 0.162030238 0.162608744 0.166662906 0.183242118 \n  Max.Price \n0.006836843 \n\nse &lt;- sqrt(diag(vcov(carprice2.lm)))\n\n\nnuevo &lt;- data.frame(Type=c(\"Van\"), Max.Price=c(11))\nvalor_predicho &lt;- predict(object=carprice2.lm, newdata=nuevo)\nvalor_predicho\n\n       1 \n4.995379 \n\n\n\n\n7.3 3) Otro ejemplo con archivo externo millaje.txt (opcional)\n\nif (file.exists(file.path(data_path, \"millaje.txt\"))) {\n  millaje &lt;- read.table(file=file.path(data_path, \"millaje.txt\"), header=TRUE)\n  r_auto &lt;- cor(millaje); pairs(millaje); \n  corrplot(r_auto,method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\")\n  modelo_lineal &lt;- lm(formula = mpg ~ hp + vol, data = millaje); summary(modelo_lineal)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\"); abline(modelo_lineal, lwd = 3, col = \"red\")\n  modelo_pol2 &lt;- lm(formula = mpg ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2)\n  modelo_cuadratico &lt;- lm(formula = mpg ~ poly(hp, 2), data = millaje); summary(modelo_cuadratico)\n  plot(modelo_pol2$fitted.values, millaje$mpg); lines(c(10,60),c(10,60))\n  shapiro.test(modelo_pol2$residuals); hist(modelo_pol2$residuals); plot(density(modelo_pol2$residuals))\n  par(mfrow=c(2,2)); plot(modelo_pol2); par(mfrow=c(1,1))\n  anova(modelo_lineal, modelo_pol2)\n  plot(x = millaje$hp, y = millaje$mpg, main=\"Consumo vs potencia motor\", pch=20, col=\"grey\")\n  prediccion &lt;- predict(object = modelo_pol2, newdata = data.frame(hp = millaje$hp, vol=millaje$vol))\n  lines(sort(millaje$hp), prediccion[order(millaje$hp)], col = \"red\", lwd = 3)\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ hp + I(hp^2)) + labs(title = \"Consumo vs potencia motor\") + theme_bw()\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ poly(x, 2),  colour = \"red\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 5),  colour = \"blue\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 10), colour = \"green\", se = FALSE) + labs(title = \"Polinomios de grados 2, 5, 10\") + theme_bw()\n  modelo_5 &lt;- lm(formula = mpg ~ poly(hp, 5), data = millaje); summary(modelo_5)\n  modelo_5_correjido &lt;- lm(formula = mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje); summary(modelo_5_correjido)\n  anova(modelo_cuadratico, modelo_5_correjido)\n  shapiro.test(modelo_5_correjido$residuals); hist(modelo_5_correjido$residuals); plot(density(modelo_5_correjido$residuals))\n  plot(modelo_5_correjido$fitted.values, millaje$mpg)\n  modelo_pol2_trans &lt;- lm(formula = log(1+mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2_trans)\n  plot(modelo_pol2_trans$residuals,modelo_pol2_trans$fitted.values); plot(log(1+millaje$mpg),modelo_pol2_trans$fitted.values); lines(c(2,5),c(2,5))\n  shapiro.test(modelo_pol2_trans$residuals); hist(modelo_pol2_trans$residuals); plot(density(modelo_pol2_trans$residuals))\n  modelo_pol3_trans &lt;- lm(formula = sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol3_trans); shapiro.test(modelo_pol3_trans$residuals)\n  plot(modelo_pol3_trans$residuals,modelo_pol3_trans$fitted.values); plot(sqrt(millaje$mpg),modelo_pol3_trans$fitted.values); lines(c(4,8),c(4,8))\n  modelo_pol4_trans &lt;- lm(formula = 1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol4_trans)\n  plot(modelo_pol4_trans$residuals,modelo_pol4_trans$fitted.values); plot(1/sqrt(millaje$mpg),modelo_pol4_trans$fitted.values); shapiro.test(modelo_pol4_trans$residuals)\n  modelo_pol2_tran_2 &lt;- lm(formula = log(1+mpg) ~ vol + hp + log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_2)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_2$fitted.values); shapiro.test(modelo_pol2_tran_2$residuals); hist(modelo_pol2_tran_2$residuals); plot(density(modelo_pol2_tran_2$residuals)); plot(modelo_pol2_tran_2)\n  modelo_pol2_tran_3 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_3)\n  shapiro.test(modelo_pol2_tran_3$residuals); plot(modelo_pol2_tran_3); plot(log(1+millaje$mpg),modelo_pol2_tran_3$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_4 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_4)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_4$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_5 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_5)\n  shapiro.test(modelo_pol2_tran_5$residuals); plot(log(1+millaje$mpg),modelo_pol2_tran_5$fitted.values); lines(c(3,4.5),c(3,4.5)); plot(modelo_pol2_tran_5)\n  modelo_pol2_tran_6 &lt;- lm(formula = log(1+mpg) ~ log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_6)\n  shapiro.test(modelo_pol2_tran_6$residuals); hist(modelo_pol2_tran_6$residuals); plot(density(modelo_pol2_tran_6$residuals)); plot(modelo_pol2_tran_6)\n  modelo_pol2_tran_7 &lt;- lm(formula = log(1+mpg) ~ vol + log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_7)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = log(1 + mpg) ~ vol + log(1 + hp) - 1, data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3617 -0.3668  0.1028  0.4405  1.2853 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nvol         0.003047   0.002943   1.035    0.304    \nlog(1 + hp) 0.674633   0.063404  10.640   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.588 on 80 degrees of freedom\nMultiple R-squared:  0.9728,    Adjusted R-squared:  0.9721 \nF-statistic:  1429 on 2 and 80 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "labs/lab04_epg.html#bibliografÃ­a",
    "href": "labs/lab04_epg.html#bibliografÃ­a",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "8 BibliografÃ­a",
    "text": "8 BibliografÃ­a\nCrespo, F. A. (2021). Uso de la RegresiÃ³n MÃºltiple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "labs/lab04_epg.html#section",
    "href": "labs/lab04_epg.html#section",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "1 ",
    "text": "1"
  },
  {
    "objectID": "labs/lab04_epg.html#regresiÃ³n-polinomial-y-no-linealidad",
    "href": "labs/lab04_epg.html#regresiÃ³n-polinomial-y-no-linealidad",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "3 RegresiÃ³n Polinomial y No Linealidad",
    "text": "3 RegresiÃ³n Polinomial y No Linealidad\nLa regresiÃ³n polinomial se emplea para modelar relaciones no lineales entre una variable explicativa (\\(X\\)) y la variable dependiente (\\(Y\\)), manteniendo la linealidad en los parÃ¡metros (\\(\\beta_i\\)).\nEl modelo de grado \\(k\\) es:\n\\[y = \\beta\\_0 + \\beta\\_1 x + \\beta\\_2 x^2 + \\cdots + \\beta\\_k x^k + \\varepsilon\n\\]La prÃ¡ctica sugiere aumentar el grado del polinomio \\(k\\) hasta que el tÃ©rmino de grado \\(k\\) deje de ser estadÃ­sticamente significativo.\n\n3.1 EvaluaciÃ³n de Grado Polinomial\nLa mejora en el ajuste entre un modelo de grado \\(k\\) y uno de grado \\(k+1\\) se evalÃºa formalmente mediante una prueba ANOVA (o prueba \\(F\\)). \\[H_0: \\beta_{k+1} = 0 \\quad \\text{vs.} \\quad H_1: \\beta_{k+1} \\neq 0\\]\n# Modelos polinomiales de distinto grado\nmodelo_poli2 &lt;- lm(mpg ~ poly(hp, 2), data = mtcars)\nmodelo_poli3 &lt;- lm(mpg ~ poly(hp, 3), data = mtcars)\n\n# ComparaciÃ³n de modelos mediante ANOVA\nanova(modelo_poli2, modelo_poli3)\nSi el \\(p\\)-valor de la prueba \\(F\\) es alto, se acepta \\(H_0\\), lo que implica que el modelo mÃ¡s complejo no mejora significativamente el ajuste respecto al anterior.\nTambiÃ©n se recomienda analizar indicadores de ajuste con penalizaciÃ³n por complejidad: \\[R^2_{\\text{ajustado}}, \\quad \\text{Criterio de InformaciÃ³n de Akaike (AIC)}, \\quad \\text{Criterio de InformaciÃ³n Bayesiano (BIC)}\\] â€”â€“"
  },
  {
    "objectID": "labs/lab04_epg.html#criterios-de-especificaciÃ³n-del-modelo",
    "href": "labs/lab04_epg.html#criterios-de-especificaciÃ³n-del-modelo",
    "title": "Laboratorio 4_epg: Uso de la RegresiÃ³n MÃºltiple",
    "section": "3 Criterios de EspecificaciÃ³n del Modelo",
    "text": "3 Criterios de EspecificaciÃ³n del Modelo\n\n3.1 EliminaciÃ³n de Variables Irrelevantes\nSe deben eliminar las variables del modelo que no son estadÃ­sticamente significativas (\\(\\hat{\\beta}_i\\) no es distinto de cero), siempre y cuando el modelo global mantenga su significancia. El objetivo es obtener un modelo parsimonioso (simple y explicativo).\n\n\n3.2 InclusiÃ³n de Interacciones\nSe pueden agregar interacciones (\\(X_i \\times X_j\\)) para modelar un efecto conjunto o condicional de dos variables sobre la respuesta (\\(Y\\)):\n$$X_3 = X_2 \\times X_1$$"
  }
]