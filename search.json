[
  {
    "objectID": "labs/lab04_epg.html",
    "href": "labs/lab04_epg.html",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs/lab04_epg.html#uso-de-la-regresión-múltiple",
    "href": "labs/lab04_epg.html#uso-de-la-regresión-múltiple",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "1 Uso de la Regresión Múltiple",
    "text": "1 Uso de la Regresión Múltiple"
  },
  {
    "objectID": "labs/lab04_epg.html#análisis-de-correlaciones-simultáneas",
    "href": "labs/lab04_epg.html#análisis-de-correlaciones-simultáneas",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "2 Análisis de Correlaciones Simultáneas",
    "text": "2 Análisis de Correlaciones Simultáneas\nEl análisis inicial en regresión múltiple se centra en la relación entre las variables explicativas. Una herramienta fundamental es la matriz de correlación.\nUna alta correlación entre las variables explicativas (\\(X_i, X_j\\)) es un indicio de multicolinealidad, lo que puede inestabilizar los coeficientes estimados.\nLa librería MASS es comúnmente utilizada en R, aunque la función cor() pertenece al paquete base.\nR\nlibrary(MASS) # Ejemplo de uso # Permite ver correlaciones simultáneas cor(Datos[, c(\"X1\", \"X2\", \"X3\")])"
  },
  {
    "objectID": "labs/lab04_epg.html#criterios-de-especificación-del-modelo",
    "href": "labs/lab04_epg.html#criterios-de-especificación-del-modelo",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "3 Criterios de Especificación del Modelo",
    "text": "3 Criterios de Especificación del Modelo\n\n3.1 Eliminación de Variables Irrelevantes\nSe deben eliminar las variables del modelo que no son estadísticamente significativas (\\(\\hat{\\beta}_i\\) no es distinto de cero), siempre y cuando el modelo global mantenga su significancia. El objetivo es obtener un modelo parsimonioso (simple y explicativo).\n\n\n3.2 Inclusión de Interacciones\nSe pueden agregar interacciones (\\(X_i \\times X_j\\)) para modelar un efecto conjunto o condicional de dos variables sobre la respuesta (\\(Y\\)):\n$$X_3 = X_2 \\times X_1$$"
  },
  {
    "objectID": "labs/lab04_epg.html#regresión-polinomial",
    "href": "labs/lab04_epg.html#regresión-polinomial",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "4 Regresión Polinomial",
    "text": "4 Regresión Polinomial\nLa regresión polinomial se utiliza para modelar relaciones no lineales entre \\(X\\) y \\(Y\\) manteniendo la linealidad en los parámetros (\\(\\beta\\)).\nEl modelo de regresión polinomial de grado \\(k\\) es:\n$$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\cdots + \\beta_k x^k + \\varepsilon$$\ndonde \\(\\varepsilon\\) representa el término de perturbación aleatoria.\nNo existe una regla estricta para determinar el grado \\(k\\), pero la práctica sugiere incrementar el grado del polinomio hasta que el nuevo término deje de ser significativo. Esto se evalúa formalmente mediante una prueba ANOVA (o prueba \\(F\\)) que compara la mejora de ajuste entre el modelo de grado \\(k\\) y el modelo de grado \\(k+1\\)."
  },
  {
    "objectID": "labs/lab04_epg.html#transformación-de-variables",
    "href": "labs/lab04_epg.html#transformación-de-variables",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "5 Transformación de Variables",
    "text": "5 Transformación de Variables\nTanto la variable dependiente (\\(Y\\)) como las independientes (\\(X_i\\)) pueden transformarse mediante funciones matemáticas (\\(f(\\cdot)\\)) para:\n\nEstabilizar la varianza de los residuos (resolver heterocedasticidad).\nMejorar la linealidad de la relación.\nNormalizar la distribución de los errores.\n\n$$y’ = f(y), \\qquad x’ = g(x)$$\n\n5.1 Transformación Logarítmica\nSi se utiliza el logaritmo y alguna variable toma el valor cero (\\(0\\)), se debe aplicar un desplazamiento para evitar la indeterminación, usando:\n$$\\log(1 + y) \\quad \\text{o} \\quad \\log(1 + x)$$\n\n\n5.2 Otras Transformaciones\nOtras transformaciones comunes para estabilizar la varianza incluyen la raíz cuadrada:\n$$y’ = \\sqrt{y}$$\nEl objetivo principal es encontrar la transformación que minimice la varianza de los residuos (\\(\\sigma_{\\varepsilon}^2\\)) y asegure que el modelo cumpla con los supuestos clásicos de la regresión lineal."
  },
  {
    "objectID": "labs/lab04_epg.html#conclusión",
    "href": "labs/lab04_epg.html#conclusión",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "6 Conclusión",
    "text": "6 Conclusión\nLa fase de especificación del modelo, que abarca el manejo de multicolinealidad, la selección de variables, la incorporación de efectos no lineales (polinomiales) y las transformaciones adecuadas, es crucial. Estas herramientas permiten construir modelos econométricos sólidos, válidos y parsimoniosos, mejorando la interpretación, la validez estadística y la capacidad predictiva del modelo de regresión múltiple."
  },
  {
    "objectID": "labs/lab04_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab04_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "7 Aplicación en R (sobre los contenidos anteriores)",
    "text": "7 Aplicación en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (según tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\nif (!file.exists(file.path(data_path, \"millaje.txt\"))) {\n  message(\"ℹ️ Aviso: 'millaje.txt' no se encontró en data_path; el bloque DAAG usa dataset interno 'carprice'.\")\n}\n\n\n# Librerías necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"MASS\",\"corrplot\",\"lmtest\",\"DAAG\",\"ggplot2\"))\nlibrary(tidyverse); library(openxlsx); library(MASS); library(corrplot)\nlibrary(lmtest); library(DAAG); library(ggplot2)\n\n\n7.1 1) Ejemplo publicitario: tv, radio, periódico → ventas\n\ntv &lt;- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2, 228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6, 95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1, 175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9, 7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5, 139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5, 5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0, 139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177.0, 283.6, 232.1)\nradio &lt;- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0, 35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9, 12.6, 3.5, 29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1, 43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5, 15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5, 2.0, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3, 33.0, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5, 43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14.0, 31.6, 3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11.0, 0.3, 0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3, 0.8, 36.9, 16.0, 26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0, 39.6, 2.9, 27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2, 5.7, 14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6, 43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2, 23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0, 2.6, 5.4, 5.7, 43.0, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8, 4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6)\nperiodico &lt;- c(69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2, 4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5, 49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0, 0.3, 7.4, 8.5, 5.0, 45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3, 31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0, 41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2, 11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4, 23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2, 73.4, 51.4, 9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8, 100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2, 2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6, 12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6, 8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9.0, 8.7, 44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3, 45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6, 6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6, 8.3, 27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0, 31.6, 3.6, 6.0, 13.8, 8.1, 6.4, 66.2, 8.7)\nventas &lt;- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5, 9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4, 8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6, 21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6, 3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0, 12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4)\ndatos &lt;- data.frame(tv, radio, periodico, ventas)\n\npairs(datos)\n\n\n\n\n\n\n\nr &lt;- cor(datos)\ncorrplot(r, method=\"circle\", type=\"lower\", diag=FALSE, tl.col=\"black\", tl.cex=1, tl.offset=0.1, tl.srt=45)\n\n\n\n\n\n\n\n\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio + periodico, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + periodico, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\ntv           0.045765   0.001395  32.809   &lt;2e-16 ***\nradio        0.188530   0.008611  21.893   &lt;2e-16 ***\nperiodico   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7977 -0.8752  0.2422  1.1708  2.8328 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\ntv           0.04575    0.00139  32.909   &lt;2e-16 ***\nradio        0.18799    0.00804  23.382   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.681 on 197 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 \nF-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones,\n                    theta = 18, phi = 20,\n                    col = \"lightblue\", shade = 0.1,\n                    xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\",\n                    main = \"Predicción ventas ~ TV y Radio\")\n\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo), superficie)\npoints(observaciones, col = \"red\", pch = 16)\nsegments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nshapiro.test(modelo$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo$residuals\nW = 0.91804, p-value = 4.19e-09\n\nhist(modelo$residuals); plot(density(modelo$residuals))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0808, p-value = 0.5656\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 4.8093, df = 2, p-value = 0.0903\n\nplot(modelo$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\ntv_radio &lt;- tv*radio\nmodelo_interaccion &lt;- lm(formula = ventas ~ tv + radio + tv*radio, data = datos)\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***\ntv          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \ntv:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_interaccion$residuals); hist(modelo_interaccion$residuals); plot(density(modelo_interaccion$residuals))\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion$residuals\nW = 0.8469, p-value = 3.047e-13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo_interaccion,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion\nDW = 2.2236, p-value = 0.1103\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion\nBP = 14.324, df = 3, p-value = 0.002495\n\nplot(modelo_interaccion$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo_interaccion, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones, theta = 18, phi = 20, col = \"lightblue\",\n                    shade = 0.1, xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\", main = \"Predicción ventas ~ TV y Radio (interacción)\")\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo_interaccion), superficie)\npoints(observaciones, col = \"red\", pch = 16); segments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nanova(modelo, modelo_interaccion)\n\nAnalysis of Variance Table\n\nModel 1: ventas ~ tv + radio\nModel 2: ventas ~ tv + radio + tv * radio\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    197 556.91                                  \n2    196 174.48  1    382.43 429.59 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodelo_interaccion_1 &lt;- lm(formula = ventas ~ tv + radio + I(tv^2)+ tv*radio, data = datos)\nsummary(modelo_interaccion_1)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + I(tv^2) + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9949 -0.2969 -0.0066  0.3798  1.1686 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.137e+00  1.927e-01  26.663  &lt; 2e-16 ***\ntv           5.092e-02  2.232e-03  22.810  &lt; 2e-16 ***\nradio        3.516e-02  5.901e-03   5.959 1.17e-08 ***\nI(tv^2)     -1.097e-04  6.893e-06 -15.920  &lt; 2e-16 ***\ntv:radio     1.077e-03  3.466e-05  31.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6238 on 195 degrees of freedom\nMultiple R-squared:  0.986, Adjusted R-squared:  0.9857 \nF-statistic:  3432 on 4 and 195 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_interaccion_1$fitted.values, datos$ventas); lines(c(0,27), c(0,27))\n\n\n\n\n\n\n\nhist(modelo_interaccion_1$residuals); plot(density(modelo_interaccion_1$residuals)); shapiro.test(modelo_interaccion_1$residuals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion_1$residuals\nW = 0.80888, p-value = 6.359e-15\n\ndwtest(modelo_interaccion_1,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion_1)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion_1\nDW = 2.204, p-value = 0.1432\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion_1\nBP = 19.986, df = 4, p-value = 0.0005027\n\n\n\n\n7.2 2) Ejemplo adicional: dataset carprice (DAAG)\n\ndata(carprice)\npairs(carprice[,-c(1,8,9)]); \n\n\n\n\n\n\n\ncorrplot(cor(carprice[,-c(1,8,9)]),method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n\n\n\n\n\n\n\n\n\ncarprice1.lm &lt;- lm(gpm100 ~ Type + Min.Price + Price + Max.Price + Range.Price, data=carprice)\nsummary(carprice1.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Min.Price + Price + Max.Price + \n    Range.Price, data = carprice)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.48431 -0.22731 -0.03417  0.19004  0.49651 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.2874     0.1531  21.467  &lt; 2e-16 ***\nTypeLarge     0.3235     0.1733   1.867   0.0695 .  \nTypeMidsize   0.1849     0.1660   1.114   0.2722    \nTypeSmall    -0.3895     0.1681  -2.317   0.0258 *  \nTypeSporty    0.2055     0.1747   1.176   0.2467    \nTypeVan       1.3487     0.1927   6.997 2.16e-08 ***\nMin.Price     0.6997     0.9894   0.707   0.4836    \nPrice        -1.3773     1.9829  -0.695   0.4914    \nMax.Price     0.7106     0.9943   0.715   0.4791    \nRange.Price       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3059 on 39 degrees of freedom\nMultiple R-squared:  0.8149,    Adjusted R-squared:  0.777 \nF-statistic: 21.47 on 8 and 39 DF,  p-value: 4.768e-12\n\ncarprice2.lm &lt;- lm(gpm100 ~ Type + Max.Price, data=carprice)\nsummary(carprice2.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Max.Price, data = carprice)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5468 -0.2379 -0.0241  0.1842  0.5311 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.298110   0.150746  21.879  &lt; 2e-16 ***\nTypeLarge    0.368524   0.165541   2.226   0.0316 *  \nTypeMidsize  0.214006   0.162030   1.321   0.1939    \nTypeSmall   -0.386042   0.162609  -2.374   0.0224 *  \nTypeSporty   0.209540   0.166663   1.257   0.2158    \nTypeVan      1.367463   0.183242   7.463 3.69e-09 ***\nMax.Price    0.029982   0.006837   4.385 7.89e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3027 on 41 degrees of freedom\nMultiple R-squared:  0.8096,    Adjusted R-squared:  0.7817 \nF-statistic: 29.05 on 6 and 41 DF,  p-value: 2.782e-13\n\n\n\nepsilon &lt;- carprice2.lm$residuals\nhist(epsilon); shapiro.test(epsilon)\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95934, p-value = 0.09497\n\ndwtest(carprice2.lm,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  carprice2.lm\nDW = 1.7034, p-value = 0.295\nalternative hypothesis: true autocorrelation is not 0\n\ns &lt;- sqrt(sum(epsilon^2)/(41))\nplot(carprice$gpm100, carprice2.lm$fitted.values); lines(c(2,5.5),c(2,5.5))\n\n\n\n\n\n\n\nconfint(carprice2.lm)\n\n                  2.5 %      97.5 %\n(Intercept)  2.99367329  3.60254758\nTypeLarge    0.03420650  0.70284211\nTypeMidsize -0.11322061  0.54123280\nTypeSmall   -0.71443686 -0.05764682\nTypeSporty  -0.12704297  0.54612217\nTypeVan      0.99739791  1.73752784\nMax.Price    0.01617507  0.04378964\n\nout &lt;- summary(carprice2.lm); out$coefficients[ , 1]; out$coefficients[ , 2]\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n 3.29811043  0.36852431  0.21400610 -0.38604184  0.20953960  1.36746287 \n  Max.Price \n 0.02998236 \n\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n0.150745713 0.165541483 0.162030238 0.162608744 0.166662906 0.183242118 \n  Max.Price \n0.006836843 \n\nse &lt;- sqrt(diag(vcov(carprice2.lm)))\n\n\nnuevo &lt;- data.frame(Type=c(\"Van\"), Max.Price=c(11))\nvalor_predicho &lt;- predict(object=carprice2.lm, newdata=nuevo)\nvalor_predicho\n\n       1 \n4.995379 \n\n\n\n\n7.3 3) Otro ejemplo con archivo externo millaje.txt (opcional)\n\nif (file.exists(file.path(data_path, \"millaje.txt\"))) {\n  millaje &lt;- read.table(file=file.path(data_path, \"millaje.txt\"), header=TRUE)\n  r_auto &lt;- cor(millaje); pairs(millaje); \n  corrplot(r_auto,method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\")\n  modelo_lineal &lt;- lm(formula = mpg ~ hp + vol, data = millaje); summary(modelo_lineal)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\"); abline(modelo_lineal, lwd = 3, col = \"red\")\n  modelo_pol2 &lt;- lm(formula = mpg ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2)\n  modelo_cuadratico &lt;- lm(formula = mpg ~ poly(hp, 2), data = millaje); summary(modelo_cuadratico)\n  plot(modelo_pol2$fitted.values, millaje$mpg); lines(c(10,60),c(10,60))\n  shapiro.test(modelo_pol2$residuals); hist(modelo_pol2$residuals); plot(density(modelo_pol2$residuals))\n  par(mfrow=c(2,2)); plot(modelo_pol2); par(mfrow=c(1,1))\n  anova(modelo_lineal, modelo_pol2)\n  plot(x = millaje$hp, y = millaje$mpg, main=\"Consumo vs potencia motor\", pch=20, col=\"grey\")\n  prediccion &lt;- predict(object = modelo_pol2, newdata = data.frame(hp = millaje$hp, vol=millaje$vol))\n  lines(sort(millaje$hp), prediccion[order(millaje$hp)], col = \"red\", lwd = 3)\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ hp + I(hp^2)) + labs(title = \"Consumo vs potencia motor\") + theme_bw()\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ poly(x, 2),  colour = \"red\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 5),  colour = \"blue\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 10), colour = \"green\", se = FALSE) + labs(title = \"Polinomios de grados 2, 5, 10\") + theme_bw()\n  modelo_5 &lt;- lm(formula = mpg ~ poly(hp, 5), data = millaje); summary(modelo_5)\n  modelo_5_correjido &lt;- lm(formula = mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje); summary(modelo_5_correjido)\n  anova(modelo_cuadratico, modelo_5_correjido)\n  shapiro.test(modelo_5_correjido$residuals); hist(modelo_5_correjido$residuals); plot(density(modelo_5_correjido$residuals))\n  plot(modelo_5_correjido$fitted.values, millaje$mpg)\n  modelo_pol2_trans &lt;- lm(formula = log(1+mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2_trans)\n  plot(modelo_pol2_trans$residuals,modelo_pol2_trans$fitted.values); plot(log(1+millaje$mpg),modelo_pol2_trans$fitted.values); lines(c(2,5),c(2,5))\n  shapiro.test(modelo_pol2_trans$residuals); hist(modelo_pol2_trans$residuals); plot(density(modelo_pol2_trans$residuals))\n  modelo_pol3_trans &lt;- lm(formula = sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol3_trans); shapiro.test(modelo_pol3_trans$residuals)\n  plot(modelo_pol3_trans$residuals,modelo_pol3_trans$fitted.values); plot(sqrt(millaje$mpg),modelo_pol3_trans$fitted.values); lines(c(4,8),c(4,8))\n  modelo_pol4_trans &lt;- lm(formula = 1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol4_trans)\n  plot(modelo_pol4_trans$residuals,modelo_pol4_trans$fitted.values); plot(1/sqrt(millaje$mpg),modelo_pol4_trans$fitted.values); shapiro.test(modelo_pol4_trans$residuals)\n  modelo_pol2_tran_2 &lt;- lm(formula = log(1+mpg) ~ vol + hp + log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_2)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_2$fitted.values); shapiro.test(modelo_pol2_tran_2$residuals); hist(modelo_pol2_tran_2$residuals); plot(density(modelo_pol2_tran_2$residuals)); plot(modelo_pol2_tran_2)\n  modelo_pol2_tran_3 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_3)\n  shapiro.test(modelo_pol2_tran_3$residuals); plot(modelo_pol2_tran_3); plot(log(1+millaje$mpg),modelo_pol2_tran_3$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_4 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_4)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_4$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_5 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_5)\n  shapiro.test(modelo_pol2_tran_5$residuals); plot(log(1+millaje$mpg),modelo_pol2_tran_5$fitted.values); lines(c(3,4.5),c(3,4.5)); plot(modelo_pol2_tran_5)\n  modelo_pol2_tran_6 &lt;- lm(formula = log(1+mpg) ~ log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_6)\n  shapiro.test(modelo_pol2_tran_6$residuals); hist(modelo_pol2_tran_6$residuals); plot(density(modelo_pol2_tran_6$residuals)); plot(modelo_pol2_tran_6)\n  modelo_pol2_tran_7 &lt;- lm(formula = log(1+mpg) ~ vol + log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_7)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCall:\nlm(formula = log(1 + mpg) ~ vol + log(1 + hp) - 1, data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3617 -0.3668  0.1028  0.4405  1.2853 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nvol         0.003047   0.002943   1.035    0.304    \nlog(1 + hp) 0.674633   0.063404  10.640   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.588 on 80 degrees of freedom\nMultiple R-squared:  0.9728,    Adjusted R-squared:  0.9721 \nF-statistic:  1429 on 2 and 80 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "labs/lab04_epg.html#bibliografía",
    "href": "labs/lab04_epg.html#bibliografía",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "8 Bibliografía",
    "text": "8 Bibliografía\nCrespo, F. A. (2021). Uso de la Regresión Múltiple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "labs/lab02_epg.html",
    "href": "labs/lab02_epg.html",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs/lab02_epg.html#covarianza-y-correlación",
    "href": "labs/lab02_epg.html#covarianza-y-correlación",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "1 Covarianza y Correlación",
    "text": "1 Covarianza y Correlación\nHasta ahora hemos visto distribuciones conjuntas, medias y varianzas, las cuales entregan información útil sobre las distribuciones marginales.\nSin embargo, ellas no muestran la relación entre dos variables, es decir, cómo varían juntas.\n\n\n1.1 Definición: Covarianza\nSean \\(X\\) y \\(Y\\) variables aleatorias con distribución conjunta, medias \\(\\mu_X, \\mu_Y\\) y varianzas \\(\\sigma_X^2, \\sigma_Y^2\\).\nLa covarianza entre \\(X\\) y \\(Y\\) se define como:\n\\[\n\\text{Cov}(X, Y) = E[(X - \\mu_X)(Y - \\mu_Y)]\n\\]\nSi \\(\\sigma_X^2 &lt; \\infty\\) y \\(\\sigma_Y^2 &lt; \\infty\\), la covarianza es finita y puede tomar cualquier valor real.\n\n\n\n1.2 Definición: Correlación\nSi \\(0 &lt; \\sigma_X^2 &lt; \\infty\\) y \\(0 &lt; \\sigma_Y^2 &lt; \\infty\\), la correlación de Pearson entre \\(X\\) y \\(Y\\) se define como:\n\\[\n\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\]\n\n\n\n1.3 Teorema 2.1: Desigualdad de Cauchy-Schwarz\nPara cualesquiera variables aleatorias \\(U\\) y \\(V\\):\n\\[\n[E(UV)]^2 \\leq E(U^2) \\, E(V^2)\n\\]\nDe esta desigualdad se deduce que:\n\\[\n-1 \\leq \\rho(X, Y) \\leq 1\n\\]\n\n\n\n1.4 Teorema 2.2\nPara variables aleatorias \\(X\\) y \\(Y\\) con varianzas finitas:\n\\[\n\\text{Cov}(X, Y) = E(XY) - E(X)E(Y)\n\\]\n\n\n\n1.5 Teorema 2.3\nSi \\(X\\) y \\(Y\\) son independientes con \\(0 &lt; \\sigma_X^2, \\sigma_Y^2 &lt; \\infty\\), entonces:\n\\[\n\\text{Cov}(X, Y) = \\rho(X, Y) = 0\n\\]\n\nNota: Independencia implica covarianza nula, pero no al revés.\n\n\n\n\n1.6 Ejemplo\nVariables aleatorias dependientes pero no correlacionadas:\nSea \\(X\\) que toma los valores \\(-1, 0, 1\\) con igual probabilidad, y defínase \\(Y = X^2\\).\nAquí \\(X\\) y \\(Y\\) no son independientes, pero su correlación es cero.\n\n\n\n1.7 Teorema 2.4\nSea \\(Y = aX + b\\), con \\(a \\neq 0\\).\nEntonces:\n\\[\n\\rho(X, Y) =\n\\begin{cases}\n1, & \\text{si } a &gt; 0 \\\\\n-1, & \\text{si } a &lt; 0\n\\end{cases}\n\\]\n\n\n\n1.8 Teorema 2.5\nSi \\(X\\) y \\(Y\\) tienen varianzas finitas:\n\\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\,\\text{Cov}(X, Y)\n\\]\nDe aquí se derivan:\n\\[\n\\text{Var}(aX + bY + c) = a^2 \\text{Var}(X) + b^2 \\text{Var}(Y) + 2ab\\,\\text{Cov}(X, Y)\n\\]\n\\[\n\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\,\\text{Cov}(X, Y)\n\\]\n\n\n\n1.9 Teorema 2.6\nPara \\(X_1, X_2, \\ldots, X_n\\) con varianzas finitas:\n\\[\n\\text{Var}\\left( \\sum_{i=1}^{n} X_i \\right)\n= \\sum_{i=1}^{n} \\text{Var}(X_i)\n+ 2 \\sum_{i&lt;j} \\text{Cov}(X_i, X_j)\n\\]\n\n\n\n1.10 Cálculos Prácticos\nMedia y desviación estándar:\n\\[\n\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i,\n\\qquad\n\\sigma_X = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\]\n\\[\n\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^{n} Y_i,\n\\qquad\n\\sigma_Y = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2}\n\\]\nCovarianza y correlación de Pearson:\n\\[\n\\sigma_{XY} = \\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\n\\[\nr = \\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#diagramas-de-dispersión",
    "href": "labs/lab02_epg.html#diagramas-de-dispersión",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "2 Diagramas de Dispersión",
    "text": "2 Diagramas de Dispersión\nUn diagrama de dispersión es la representación gráfica de pares de observaciones \\((x_i, y_i)\\), permitiendo visualizar la relación entre dos variables.\nEjemplos famosos: - Ley de Hooke - Ley de Hubble-Lemaître - Ondas gravitacionales (LIGO)\nEjemplo aplicado: analizar el rendimiento de automóviles respecto a su peso."
  },
  {
    "objectID": "labs/lab02_epg.html#prueba-de-hipótesis-sobre-la-correlación",
    "href": "labs/lab02_epg.html#prueba-de-hipótesis-sobre-la-correlación",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "3 Prueba de Hipótesis sobre la Correlación",
    "text": "3 Prueba de Hipótesis sobre la Correlación\nSe desea probar:\n\\[\nH_0: \\rho = 0 \\quad \\text{vs.} \\quad H_1: \\rho \\neq 0\n\\]\nEl error estándar del coeficiente de correlación es:\n\\[\ns_r = \\frac{1 - r^2}{\\sqrt{n - 2}}\n\\]\nEl estadístico de prueba es:\n\\[\nt = \\frac{r - \\rho}{s_r}\n\\]\ndonde \\(t \\sim t_{n-2}\\) (distribución t de Student con \\(n - 2\\) grados de libertad).\nSe rechaza \\(H_0\\) si \\(|t| &gt; t_{\\alpha/2, n-2}\\).\n\nUna correlación significativa no implica causalidad."
  },
  {
    "objectID": "labs/lab02_epg.html#ecuaciones-lineales",
    "href": "labs/lab02_epg.html#ecuaciones-lineales",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "4 Ecuaciones Lineales",
    "text": "4 Ecuaciones Lineales\nEn regresión lineal simple, se busca modelar cómo cambia una variable dependiente \\(y\\) en función de una variable independiente \\(x\\).\nEl modelo lineal se plantea como:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\ndonde: - \\(\\beta_0\\): intercepto (ordenada al origen)\n- \\(\\beta_1\\): pendiente (efecto de \\(x\\) sobre \\(y\\))\nIncluyendo el error aleatorio \\(\\varepsilon\\):\n\\[\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n\\]\n\n\n4.1 Supuestos clásicos del modelo lineal\n\n\\(\\varepsilon \\sim N(0, \\sigma^2)\\) (normalidad).\n\nHomocedasticidad: varianza constante de \\(\\varepsilon\\).\n\n\\(E(\\varepsilon) = 0\\).\n\nIndependencia entre los errores."
  },
  {
    "objectID": "labs/lab02_epg.html#método-de-mínimos-cuadrados-ols",
    "href": "labs/lab02_epg.html#método-de-mínimos-cuadrados-ols",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "5 Método de Mínimos Cuadrados (OLS)",
    "text": "5 Método de Mínimos Cuadrados (OLS)\nPara estimar \\(\\beta_0\\) y \\(\\beta_1\\), se minimiza la suma de los cuadrados de los residuos:\n\\[\n\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\n\\]\nLas soluciones son:\n\\[\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\]\n\\[\n\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\]\n\n\n5.1 Ejemplo\nCosto de mantenimiento anual de buses (USD) en función de los años de operación.\nPasos: 1. Graficar el diagrama de dispersión.\n2. Evaluar la relación entre variables.\n3. Calcular el coeficiente de correlación.\n4. Probar su significancia (\\(\\alpha = 0.05\\)).\n5. Estimar la ecuación del modelo.\n6. Calcular el costo estimado para un bus con 5 años de operación."
  },
  {
    "objectID": "labs/lab02_epg.html#residuos",
    "href": "labs/lab02_epg.html#residuos",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "6 Residuos",
    "text": "6 Residuos\nLos residuos se definen como:\n\\[\n\\hat{\\varepsilon} = y - \\hat{y}\n\\]\nEl error estándar de la estimación mide la dispersión de los valores observados de \\(y\\) respecto a la recta estimada:\n\\[\ns_{y,x} = \\sqrt{\\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n - 2}}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#predicción-e-intervalos-de-confianza",
    "href": "labs/lab02_epg.html#predicción-e-intervalos-de-confianza",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "7 Predicción e Intervalos de Confianza",
    "text": "7 Predicción e Intervalos de Confianza\nUna estimación puntual no informa sobre la precisión del pronóstico.\nPor ello se construye un intervalo de confianza:\n\\[\n\\hat{y} \\pm t_{\\alpha/2, n-2} \\, s_{\\hat{y},x}\n\\]\nEl error estándar de predicción se calcula como:\n\\[\ns_{\\hat{y},x} = s_{y,x} \\sqrt{1 + \\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]\ndonde \\(x_p\\) es el valor dado de \\(X\\).\n\nPara estimar el valor medio de muchos experimentos en \\(x_p\\):\n\\[\n\\hat{y} \\pm t_{\\alpha/2, n-2} \\, s_{\\hat{\\mu},x}\n\\]\ncon:\n\\[\ns_{\\hat{\\mu},x} = s_{y,x} \\sqrt{\\frac{1}{n} + \\frac{(x_p - \\bar{x})^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#coeficiente-de-determinación-simple",
    "href": "labs/lab02_epg.html#coeficiente-de-determinación-simple",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "8 Coeficiente de Determinación Simple",
    "text": "8 Coeficiente de Determinación Simple\nEl coeficiente de determinación \\(R^2\\) mide la proporción de la variabilidad en \\(y\\) explicada por el modelo:\n\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n\\]"
  },
  {
    "objectID": "labs/lab02_epg.html#prueba-de-hipótesis-en-la-regresión",
    "href": "labs/lab02_epg.html#prueba-de-hipótesis-en-la-regresión",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "9 Prueba de Hipótesis en la Regresión",
    "text": "9 Prueba de Hipótesis en la Regresión\nSe plantea:\n\\[\nH_0: \\beta_1 = 0 \\quad \\text{vs.} \\quad H_1: \\beta_1 \\neq 0\n\\]\nEl error estándar del estimador es:\n\\[\ns_{\\hat{\\beta}_1} = \\frac{s_{y,x}}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}}\n\\]\ny el estadístico de prueba:\n\\[\nt = \\frac{\\hat{\\beta}_1 - \\beta_1}{s_{\\hat{\\beta}_1}}\n\\]\ndonde \\(t \\sim t_{n-2}\\).\nSe rechaza \\(H_0\\) si \\(|t| &gt; t_{\\alpha/2, n-2}\\).\n\n\n✅ Conclusión:\nLa correlación mide fuerza y dirección de relación lineal;\nla regresión permite cuantificar y predecir dicha relación, bajo supuestos estadísticos formales."
  },
  {
    "objectID": "labs/lab02_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab02_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "10 Aplicación en R (sobre los contenidos anteriores)",
    "text": "10 Aplicación en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (según tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# Verificación\nif (!file.exists(file.path(data_path, \"auto_peso_consumo.xlsx\"))) {\n  stop(\"⚠️ No se encontró 'auto_peso_consumo.xlsx' en data_path\")\n}\nif (!file.exists(file.path(data_path, \"annos_mantenimiento.xlsx\"))) {\n  stop(\"⚠️ No se encontró 'annos_mantenimiento.xlsx' en data_path\")\n}\n\n# Librerías necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\n\n\n# Cargar datos de autos\ndatos &lt;- read.xlsx(file.path(data_path, \"auto_peso_consumo.xlsx\"), sheet=\"Hoja1\", colNames = TRUE)\n\n# Diagrama de dispersión Peso vs Consumo\nplot(datos$Peso_Libras, datos$Consumo_Millas_por_galon,\n     main=\"Relación entre peso y consumo de autos\",\n     xlab=\"Peso (libras)\", ylab=\"Consumo (millas/galón)\")\n\n\n\n\n\n\n\n# Coeficiente de correlación\nr &lt;- cor(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\nr\n\n[1] -0.8549912\n\n# Prueba de hipótesis para la correlación\nsr &lt;- sqrt((1 - r) / (3)) # n = número de datos menos 2\nt &lt;- r / sr\nc &lt;- qt(0.025, 3, lower.tail = F)\npt(-t, 3, lower.tail = F)\n\n[1] 0.1782267\n\n# Test de correlación con función base\ncor.test(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos$Peso_Libras and datos$Consumo_Millas_por_galon\nt = -2.8553, df = 3, p-value = 0.06483\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9902684  0.1110238\nsample estimates:\n       cor \n-0.8549912 \n\n\n\n# Cargar datos de mantenimiento\ndatos2 &lt;- read.xlsx(file.path(data_path, \"annos_mantenimiento.xlsx\"), sheet=\"Hoja1\", colNames = TRUE)\n\n# Diagrama de dispersión\nplot(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento,\n     main=\"Costo de mantenimiento vs Tiempo de operación\",\n     xlab=\"Tiempo de operación (años)\", ylab=\"Costo de mantenimiento\")\n\n\n\n\n\n\n\n# Coeficiente de correlación\nr &lt;- cor(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\nr\n\n[1] 0.9376733\n\n# Prueba de hipótesis para correlación\nsr &lt;- sqrt((1 - r) / (7))\nt &lt;- r / sr\nc &lt;- qt(0.025, 3, lower.tail = F)\ncor.test(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos2$Tiempo_operacion and datos2$Costo_Mantenimiento\nt = 7.1388, df = 7, p-value = 0.0001872\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7250800 0.9870994\nsample estimates:\n      cor \n0.9376733 \n\n\n\n# Ajuste del modelo lineal simple\nmodelo &lt;- lm(Costo_Mantenimiento ~ Tiempo_operacion, data=datos2)\nsummary(modelo)\n\n\nCall:\nlm(formula = Costo_Mantenimiento ~ Tiempo_operacion, data = datos2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-138.47 -124.55   40.88   83.45  119.21 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       208.203     75.002   2.776 0.027457 *  \nTiempo_operacion   70.918      9.934   7.139 0.000187 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 111.6 on 7 degrees of freedom\nMultiple R-squared:  0.8792,    Adjusted R-squared:  0.862 \nF-statistic: 50.96 on 1 and 7 DF,  p-value: 0.0001872\n\n# Predicción para 5 años de operación\nnuevo &lt;- data.frame(Tiempo_operacion = c(5))\nvalor_predicho &lt;- predict(object=modelo, newdata=nuevo)\nvalor_predicho\n\n      1 \n562.794 \n\n\n\n# Análisis de residuos\nmodelo$residuals\n\n         1          2          3          4          5          6          7 \n  83.45158  119.20599   50.04225 -138.46655  105.69718 -126.03961   40.87852 \n         8          9 \n-124.54842  -10.22095 \n\nhist(modelo$residuals, main=\"Histograma de residuos\", col=\"#cdeac0\", border=\"#2b9348\")\n\n\n\n\n\n\n\nplot(density(modelo$residuals), main=\"Densidad de residuos\")\n\n\n\n\n\n\n\nmean(modelo$residuals) # Debe ser ~0\n\n[1] -2.368187e-15\n\n# Cálculo de error estándar de la estimación\ns_yx &lt;- sqrt(sum(modelo$residuals^2) / 7)\n\n# Intervalos de predicción\nraiz &lt;- sqrt(1 + 1/9 + ((5 - mean(datos2$Tiempo_operacion))^2 /\n        sum((datos2$Tiempo_operacion - mean(datos2$Tiempo_operacion))^2)))\ns_hatyx &lt;- s_yx * raiz\nt &lt;- qt(0.025, 7, lower.tail = F)\n\nlimitsup &lt;- valor_predicho + t * s_hatyx\nlimitinf &lt;- valor_predicho - t * s_hatyx\nc(limitsup = limitsup, limitinf = limitinf)\n\nlimitsup.1 limitinf.1 \n  843.3746   282.2134 \n\n# Intervalos de confianza\nvalor_predicho &lt;- predict(object=modelo, newdata=nuevo, interval = c(\"confidence\"))\nvalor_predicho\n\n      fit     lwr     upr\n1 562.794 467.535 658.053"
  },
  {
    "objectID": "labs/lab02_epg.html#bibliografía",
    "href": "labs/lab02_epg.html#bibliografía",
    "title": "Laboratorio 2_epg: Correlación y Regresión Lineal Simple",
    "section": "11 Bibliografía",
    "text": "11 Bibliografía\nCrespo, F. A. (2021). Correlación y Regresión Simple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "proyectos.html",
    "href": "proyectos.html",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "proyectos.html#section",
    "href": "proyectos.html#section",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES\n\n  Nombre del estudiante:\n  \n\n  Selecciona tu archivo (.pdf, .qmd, .zip):\n  \n\n  Subir proyecto"
  },
  {
    "objectID": "datos.html",
    "href": "datos.html",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\n\nAdemás, se proyecta integrar información de ODEPA, INDAP y otros organismos públicos vinculados al ámbito económico y agrícola."
  },
  {
    "objectID": "datos.html#section",
    "href": "datos.html#section",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\n\nAdemás, se proyecta integrar información de ODEPA, INDAP y otros organismos públicos vinculados al ámbito económico y agrícola."
  },
  {
    "objectID": "datos.html#tabla-de-bases-de-datos",
    "href": "datos.html#tabla-de-bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Tabla de bases de datos",
    "text": "Tabla de bases de datos\nDebajo encontrarás una tabla interactiva que contiene la siguiente información para cada base:\n\nAños: periodo temporal cubierto.\nSiglas: abreviación con la que se conoce la encuesta o base.\nNombre de la base: denominación oficial de la fuente de datos.\nEnlace: acceso directo al sitio web o repositorio correspondiente.\nDescripción: breve explicación del contenido y posibles usos de la base."
  },
  {
    "objectID": "datos.html#buscador",
    "href": "datos.html#buscador",
    "title": "Repositorio de Datos",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (“search”) que facilita la exploración, que funciona a nivel de palabras claves, por ejemplo, si se escribe “economía”, el sistema buscará esa palabra en todas las columnas de la tabla (años, siglas, nombre, enlace y descripción). Esto permite filtrar de manera rápida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "datos.html#bases-de-datos",
    "href": "datos.html#bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Bases de Datos",
    "text": "Bases de Datos"
  },
  {
    "objectID": "index.html#descripción-del-sitio-web",
    "href": "index.html#descripción-del-sitio-web",
    "title": "",
    "section": "Descripción del Sitio Web",
    "text": "Descripción del Sitio Web\nEste sitio web es una iniciativa conjunta de los profesores Fernando Crespo y Rocío Valdebenito, docentes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado (UAH). Está dirigido a los estudiantes de la carrera de Ingeniería Comercial, con mención en Economía y Administración de Empresas, que cursan las asignaturas de Econometría.\nEl objetivo principal de estos cursos es que los estudiantes se familiaricen con el uso de bases de datos y aprendan a utilizar el software R y Rstudio como herramienta para analizar y responder preguntas de investigación. Como parte fundamental del aprendizaje, los estudiantes desarrollan un proyecto aplicado, el cual es presentado en formato de póster y expuesto frente a la comunidad académica.\nPara acompañar este proceso, el sitio web se organiza en tres secciones principales:\n\nDatos:\nEspacio donde se recopilan bases de datos que pueden ser utilizadas en proyectos de investigacion con metodologías econometricas. Cada base de datos incluye enlaces de acceso o descarga, así como una breve descripción de su contenido y posibles aplicaciones.\n\n\nMaterial de Estudio:\n\nUna sección de apoyo que ofrece códigos en Rstudio, apuntes de econometría y laboratorios, que abarcan desde operaciones básicas en R (como crear variables, realizar estadística descriptiva y generar tablas) hasta la elaboración de gráficos y análisis más avanzados. Esta sección busca ser un recurso de referencia constante para los estudiantes.\n\n\nProyectos:\n\nEspacio dedicado a la difusión de los trabajos de los estudiantes, donde se podrán visualizar sus pósters y presentaciones, sirviendo como inspiración y guía para generaciones futuras.\nEn conjunto, este sitio busca convertirse en un centro de recursos para la formación en econometría, promoviendo el uso de datos y herramientas de análisis como competencias clave para la futura labor profesional de los estudiantes de Ingeniería Comercial de la UAH."
  },
  {
    "objectID": "index.html#docentes-y-ayudante",
    "href": "index.html#docentes-y-ayudante",
    "title": "",
    "section": "Docentes y Ayudante",
    "text": "Docentes y Ayudante\n\nRocío Valdebenito: Docente e Investigadora\nLa Dra. Rocío Valdebenito es una académica especializada en Economía Aplicada con un fuerte enfoque en el análisis de temas sociales y de desarrollo.\n\nFormación y Afiliación\n\nDoctorado (Ph.D.) en Economía Aplicada de la University of Illinois at Urbana-Champaign (EE. UU., 2024).\nIngeniera Comercial y Máster en Management de la Universidad Adolfo Ibáñez (UAI).\nActualmente es Profesora en la Facultad de Economía y Negocios (FEN) de la Universidad Alberto Hurtado (UAH).\n\n\n\nÁreas Clave de Especialización e Investigación\nLa Dra. Valdebenito utiliza la Econometría y la Microeconomía Aplicada para estudiar temas de alta relevancia social. Sus principales áreas de investigación son:\n\nEconomía de la Educación: Se interesa en el impacto de la educación técnica-profesional, el rol de los compañeros en la elección de carreras STEM (Ciencia, Tecnología, Ingeniería y Matemáticas) y los efectos de shocks ambientales en los resultados de los estudiantes.\nEconomía de Género y Desarrollo: Su trabajo aborda explícitamente las brechas de género en la sociedad y examina políticas relacionadas con la planificación familiar y el empleo en países en desarrollo (ej. India).\nEconomía Regional: Investiga la migración interregional de graduados de educación media y las desigualdades en calidad de vida y educación a nivel regional.\n\n\n\nDocencia\nEn su rol docente, la profesora Valdebenito imparte cursos fundamentales que conectan la teoría económica con la evidencia empírica:\n\nEconometría\nMicroeconomía III\nOrganización Industrial\n\nSu experiencia docente se extiende a la enseñanza de métodos estadísticos aplicados y Data Science a nivel de postgrado.\nLa descripción del profesional proviene del sitio web:\n\nrvaldebenito.github.io\n\n\n\n\nFernando Crespo: Docente e Investigador\nEl profesor Fernando Crespo es un experto en Ciencia de Datos, Machine Learning y Modelos Matemáticos Aplicados. Es Doctor en Ciencias de la Ingeniería por la Pontificia Universidad Católica de Chile y actualmente se desempeña como Profesor en la Universidad Alberto Hurtado.\n\nÁreas Clave de Especialización\nSu investigación combina las matemáticas avanzadas con la informática, centrándose en:\n\nInteligencia Artificial y Redes Neuronales.\nInvestigación Operacional y Simulación.\nMinería de Datos (Data Mining) y Reconocimiento de Patrones.\n\n\n\nImpacto y Enfoque Multidisciplinario\nEl Dr. Crespo mantiene una trayectoria productiva con aproximadamente 72 participaciones en publicaciones y más de 700 citas registradas. Su trabajo destaca por su aplicación a problemas de gran relevancia social, realizando investigaciones en diversas áreas como:\n\nEconomía y Negocios (valoración, innovación).\nSalud Pública (análisis de demencias, cobertura hospitalaria, obesidad).\nSeguridad y Sociedad (modelado de delitos, segregación residencial).\n\nEn resumen, el profesor Crespo utiliza el análisis de datos y la modelación avanzada para generar conocimiento aplicado y soluciones en un amplio espectro de disciplinas.\nLa descripción del profesional proviene del sitio web:\n\nhttps://www.researchgate.net/profile/Fernando-Crespo-3\n\n\n\n\nManuel Labraña Rojas: Perfil Académico y Profesional\nManuel Labraña Rojas es un estudiante de Ingeniería Comercial con Mención en Economía de la Universidad Alberto Hurtado (UAH).\n\nExperiencia Académica y Docencia (UAH)\nHa demostrado compromiso con la formación académica, desempeñándose como Ayudante de Cátedra en las siguientes asignaturas:\n\nMatemáticas II\nMicroeconomía I\nEconometría para la Gestión\n\nAdemás, colabora en el área de investigación como Ayudante del proyecto “Repositorio de Econometría”, contribuyendo a su funcionamiento y desarrollo web.\n\n\nExperiencia Profesional\nPráctica Intermedia: Realizó su práctica intermedia en el Ministerio de Agricultura, específicamente en INDAP, dentro del Departamento SAT. Sus responsabilidades incluyeron el manejo de bases de datos y la generación de informes estadísticos descriptivos utilizando herramientas como RStudio y aplicaciones de Microsoft 365.\nTrabajo Actual: Actualmente, trabaja en la consultora FV-Consulting, enfocada en Servicios y Soluciones Integrales y Consultoría. Su labor profesional se centra en áreas temáticas de aplicación económica, incluyendo:\n\nEconomía\nEconomía Agrícola\nEconometría\nEstudios de Mercados\n\n\n\nAgradecimientos\nAgradezco a los profesores por la oportunidad y la confianza en mi desarrollo. Extiendo mi gratitud a mis padres, Josué Rojas y Cristina Labraña, por su apoyo incondicional."
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Material de Estudio",
    "section": "",
    "text": "Bienvenido al Repositorio de Laboratorios y Materiales Prácticos del curso de Econometría FEN-UAH.\nAquí encontrarás guías paso a paso en Rstudio respaldadas con teoria y conceptos escenciales para el curso que acompañan el aprendizaje aplicado de la econometría, desde regresión simple hasta modelos avanzados.\nCada laboratorio se puede abrir directamente en formato HTML renderizado desde RStudio/Quarto.\nLos documentos que contengan las siglas “epg” corresponden al curso Econometría para la Gestión, mientras que los “ec” pertenecen a Econometría (mención Economía).\n\n\n\n\n\nImportación de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimación e interpretación del modelo OLS básico.\nVer Laboratorio\n\n\n\nExtensión del modelo con variables adicionales y análisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresión múltiple, Eliminación de variables irrelevantes, Regresión polinomial, etc.\nVer Laboratorio\n\n\n\nMotivación, teoría y aplicación de logit y probit.\nVer Laboratorio\n\n\n\n\n💡 Cada laboratorio está alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automáticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "codigos.html#laboratorios",
    "href": "codigos.html#laboratorios",
    "title": "Material de Estudio",
    "section": "",
    "text": "Importación de datos, tablas de frecuencia y medidas descriptivas.\nVer Laboratorio\n\n\n\nEstimación e interpretación del modelo OLS básico.\nVer Laboratorio\n\n\n\nExtensión del modelo con variables adicionales y análisis de supuestos.\nVer Laboratorio\n\n\n\nOtras funciones para estudiar la regresión múltiple, Eliminación de variables irrelevantes, Regresión polinomial, etc.\nVer Laboratorio\n\n\n\nMotivación, teoría y aplicación de logit y probit.\nVer Laboratorio\n\n\n\n\n💡 Cada laboratorio está alojado en la carpeta labs/ y utiliza los datos correspondientes del directorio labs/data_epg/.\nEl sitio se actualiza automáticamente cuando los archivos .qmd se renderizan a HTML. Esto lo puedes encontrar directamente en el GitHub del sitio web."
  },
  {
    "objectID": "labs/lab01_epg.html",
    "href": "labs/lab01_epg.html",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2023) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs/lab01_epg.html#definición-y-términos-básicos-de-la-estadística",
    "href": "labs/lab01_epg.html#definición-y-términos-básicos-de-la-estadística",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "1 Definición y términos básicos de la estadística",
    "text": "1 Definición y términos básicos de la estadística\nLa estadística es la ciencia de los datos.\nSe aplica comúnmente a dos tipos de problemas:\n\nResumir, describir y explorar datos.\nEjemplo: resultados del censo.\n\nUsar muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada.\nEjemplo: estudio de la sobrevida de las personas para calcular el valor de la prima de un seguro de vida.\n\nRamas de estudio de la estadística:\n\nLa rama que se dedica a resumir, describir y explorar datos se denomina estadística descriptiva.\n\nLa rama que usa muestras de datos para inferir la naturaleza del conjunto de datos desde los cuales la muestra fue seleccionada se denomina estadística inferencial.\n\nLa estadística busca comprender la variabilidad.\nEl pensamiento estadístico se desarrolla para poder enfrentar dicha variabilidad, que puede provenir de:\n\nDistintos factores que influyen en un fenómeno (por ejemplo, medir el rendimiento de un automóvil en km/l).\n\nFactores implícitos, porque las variables no se pueden medir con precisión o el fenómeno tiene variabilidad propia (genes, medidas atómicas, etc.).\n\nLa estadística, junto con el método científico, permite crear modelos coherentes capaces de soportar la variabilidad de los fenómenos."
  },
  {
    "objectID": "labs/lab01_epg.html#elementos-fundamentales-de-estadística",
    "href": "labs/lab01_epg.html#elementos-fundamentales-de-estadística",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "2 Elementos Fundamentales de Estadística",
    "text": "2 Elementos Fundamentales de Estadística\n\nPoblación estadística: conjunto (grande o conceptual) de datos que es el objetivo de interés.\n\nMuestra: subconjunto de datos seleccionados de la población.\n\nUnidad experimental: objeto sobre el cual se observan las medidas (persona, transacción, evento, etc.).\n\nVariable: característica o propiedad de una unidad experimental.\n\nEjemplo: estudio de esquinas con más accidentes en la comuna de Santiago.\n\n\nInferencia: afirmación sustentada a partir de los datos.\n\nEn un problema de inferencia estadística se pueden identificar cuatro puntos:\n\nUna población.\n\nUna o más variables.\n\nUna muestra.\n\nUna inferencia (más su medida de confiabilidad, que cuantifica el grado de incertidumbre).\n\nProblemas de estadística descriptiva:\n\nPoblación o muestra de interés.\n\nVariables investigadas.\n\nTablas, gráficos o resúmenes numéricos.\n\nProblemas de inferencia estadística:\n\nPoblación de interés.\n\nVariables investigadas.\n\nMuestra de unidades experimentales.\n\nInferencia sobre la población basada en la muestra.\n\nMedida de confiabilidad para la inferencia."
  },
  {
    "objectID": "labs/lab01_epg.html#tipos-de-datos",
    "href": "labs/lab01_epg.html#tipos-de-datos",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "3 Tipos de Datos",
    "text": "3 Tipos de Datos\n\nDatos cuantitativos: representan cantidades medidas en una escala numérica.\n\nDatos cualitativos: no poseen interpretación numérica; solo pueden clasificarse.\n\nEjemplo: tipo de trabajo de egresados, estrato socioeconómico (ordinal).\n\n\nLa herramienta estadística apropiada depende del tipo de dato, por lo que es esencial distinguir si es cuantitativo o cualitativo."
  },
  {
    "objectID": "labs/lab01_epg.html#estadística-descriptiva",
    "href": "labs/lab01_epg.html#estadística-descriptiva",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "4 Estadística Descriptiva",
    "text": "4 Estadística Descriptiva\nEl objetivo es presentar métodos gráficos y numéricos para explorar, resumir y describir datos.\n\n\n4.1 Métodos Gráficos y Numéricos para Describir Datos Cualitativos\nCuando los datos son cualitativos, se agrupan en categorías:\n\nFrecuencia: número de observaciones en cada categoría.\n\nFrecuencia relativa: proporción respecto del total.\n\nEjemplo: estudio sobre seguridad de reactores nucleares (Safety of Nuclear Power Reactors, 2004).\nGráficos más usados:\n\nGráfico de barras: largo proporcional a la frecuencia (o frecuencia relativa).\n\nGráfico de torta: cada sector del círculo representa una categoría proporcional a su frecuencia.\n\nDiagrama de Pareto: barras ordenadas de mayor a menor frecuencia, útil en control de calidad; puede incluir línea de acumulación.\n\n\n\n\n4.2 Métodos Gráficos para Describir Datos Cuantitativos\nLos datos cuantitativos se representan en escalas numéricas.\nEjemplo: rendimiento de vehículos (millas por galón) medido por la EPA.\nGráficos más comunes:\n\nHistograma: divide los datos en intervalos de clase y muestra su frecuencia o frecuencia relativa.\n\nGráfico de densidad: muestra la distribución de probabilidad de los datos.\n\nPasos para construir un histograma:\n\nCalcular el rango \\(=\\) máximo \\(-\\) mínimo.\n\nDividir el rango en 5–20 clases de igual ancho.\n\nContar las observaciones en cada clase (frecuencia).\n\nCalcular la frecuencia relativa \\(=\\) frecuencia / total de observaciones.\n\nDibujar las barras adyacentes con altura según frecuencia o frecuencia relativa.\n\n\n\n\n4.3 Métodos Numéricos para Describir Datos Cuantitativos\nLas medidas numéricas descriptivas ayudan a visualizar la distribución de los datos.\nSe agrupan en tres categorías:\n\nMedidas de tendencia central (centro).\n\nMedidas de dispersión (variabilidad).\n\nMedidas de posición relativa (comparación).\n\n\nEstadística: medida numérica calculada desde la muestra.\n\nParámetro: medida descriptiva de la población (usualmente con símbolos griegos).\n\n\n\n\n4.4 Medidas de Tendencia Central\nMedia aritmética\nLa media aritmética de un conjunto de observaciones se define como:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\n\nMediana\nLa mediana es el valor central cuando los datos están ordenados.\nSi \\(x_{(i)}\\) representa el i-ésimo valor ordenado:\n\\[\nm =\n\\begin{cases}\nx_{\\left(\\frac{n+1}{2}\\right)}, & \\text{si } n \\text{ es impar} \\\\\n\\\\[-0.5em]\n\\dfrac{x_{\\left(\\frac{n}{2}\\right)} + x_{\\left(\\frac{n}{2} + 1\\right)}}{2}, & \\text{si } n \\text{ es par}\n\\end{cases}\n\\]\n\nModa\nLa moda es el valor que ocurre con mayor frecuencia en el conjunto de datos.\n\nLa media es sensible a valores extremos.\n\nLa mediana es resistente a valores extremos.\n\nLa moda es útil en datos categóricos o con repeticiones frecuentes.\n\n\n\n\n4.5 Medidas de Variación\nLas medidas más usadas son el rango, la varianza y la desviación estándar.\nRango\n\\[\n\\text{Rango} = \\text{máximo} - \\text{mínimo}\n\\]\n\nVarianza muestral\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}\n\\]\n\nVarianza poblacional\n\\[\n\\sigma^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}\n\\]\n\nDesviación estándar\n\\[\ns = \\sqrt{s^2}\n\\qquad \\text{y} \\qquad\n\\sigma = \\sqrt{\\sigma^2}\n\\]\n\n\n\n4.6 Medidas de Posición Relativa\nIndican la ubicación de una observación respecto al resto.\nPercentiles\nEl percentil \\(p\\) deja el \\(p\\%\\) de las observaciones a su izquierda:\n\n\\(Q_L = P_{25}\\): cuartil inferior\n\n\\(m = P_{50}\\): mediana\n\n\\(Q_U = P_{75}\\): cuartil superior\n\nPasos para calcular cuartiles:\n\nOrdenar los datos de menor a mayor.\n\nCalcular \\(l = \\frac{1}{4}(n + 1)\\) → primer cuartil.\n\nCalcular \\(u = \\frac{3}{4}(n + 1)\\) → tercer cuartil.\n\n\nZ-score\nEl puntaje z mide cuántas desviaciones estándar está un valor respecto a la media:\n\\[\nz = \\frac{x - \\bar{x}}{s}\n\\quad \\text{(muestra)}, \\qquad\nz = \\frac{x - \\mu}{\\sigma}\n\\quad \\text{(población)}\n\\]\n\n\n\n4.7 Medidas de Asimetría\nEl coeficiente de asimetría de Fisher mide la dirección y magnitud de la cola de la distribución:\n\\[\n\\gamma_1 = \\frac{\\mu_3}{\\sigma^3}\n\\]\n\nSi \\(\\gamma_1 &gt; 0\\): asimetría positiva (cola hacia la derecha).\n\nSi \\(\\gamma_1 &lt; 0\\): asimetría negativa (cola hacia la izquierda).\n\n\n\n\n4.8 Medidas de Concentración de Datos\nLa curtosis o kurtosis mide el grado de concentración de los datos alrededor de la media:\n\\[\n\\beta_2 = \\frac{\\mu_4}{\\sigma^4}\n\\]\n\nSi \\(\\beta_2 &gt; 3\\): distribución más apuntada (colas gruesas).\n\nSi \\(\\beta_2 &lt; 3\\): distribución más plana (colas delgadas).\n\nSi \\(\\beta_2 = 3\\): distribución normal."
  },
  {
    "objectID": "labs/lab01_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab01_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "5 Aplicación en R (sobre los contenidos anteriores)",
    "text": "5 Aplicación en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (según tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# Verificación\nif (!file.exists(file.path(data_path, \"Ejemplo1.xlsx\"))) {\n  stop(\"⚠️ No se encontró 'Ejemplo1.xlsx' en data_path\")\n}\nif (!file.exists(file.path(data_path, \"tabla_ejemplo_R.xlsx\"))) {\n  stop(\"⚠️ No se encontró 'tabla_ejemplo_R.xlsx' en data_path\")\n}\n\n# Librerías necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"psych\",\"moments\",\"qcc\",\"modeest\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(psych)\nlibrary(moments)\nlibrary(qcc)\nlibrary(modeest)\n\n\n5.1 1) Datos cualitativos: tabla de frecuencias, barras y Pareto\n\nej1 &lt;- read.xlsx(file.path(data_path, \"Ejemplo1.xlsx\"), sheet = 1, colNames = TRUE)\ntotal &lt;- sum(ej1$Frecuencia, na.rm = TRUE)\nej1 &lt;- ej1 |&gt;\n  mutate(Relativa = Frecuencia / total,\n         Porcentaje = 100 * Relativa)\nej1\n\n                  Categoria Frecuencia Acumulado   Relativa Porcentaje\n1          Explosion de Gas         28        28 0.62222222  62.222222\n2 Colapso de mina de carbon          7        35 0.15555556  15.555556\n3             Falla Represa          4        39 0.08888889   8.888889\n4      Incendio Combustible          4        43 0.08888889   8.888889\n5        Descarga electrica          1        44 0.02222222   2.222222\n6           Reactor Nuclear          1        45 0.02222222   2.222222\n\n\n\nggplot(ej1, aes(x = reorder(Categoria, -Frecuencia), y = Frecuencia)) +\n  geom_col(fill = \"#2b9348\") +\n  labs(title = \"Distribución de Categorías\", x = \"Categoría\", y = \"Frecuencia\") +\n  theme_minimal()\n\n\n\n\n\n\n\nqcc::pareto.chart(ej1$Frecuencia, names = ej1$Categoria,\n                  main = \"Gráfico de Pareto por categoría\")\n\n\n\n\n\n\n\n\n   \nPareto chart analysis for ej1$Frecuencia\n     Frequency  Cum.Freq. Percentage Cum.Percent.\n  A  28.000000  28.000000  62.222222    62.222222\n  B   7.000000  35.000000  15.555556    77.777778\n  C   4.000000  39.000000   8.888889    86.666667\n  D   4.000000  43.000000   8.888889    95.555556\n  E   1.000000  44.000000   2.222222    97.777778\n  F   1.000000  45.000000   2.222222   100.000000\n\n\n\n\n5.2 2) Datos cuantitativos: medidas y gráficos\n\ndatos &lt;- read.xlsx(file.path(data_path, \"tabla_ejemplo_R.xlsx\"), sheet = 1, colNames = TRUE)\nx &lt;- datos$Precio\n\nmedia   &lt;- mean(x, na.rm = TRUE)\nmediana &lt;- median(x, na.rm = TRUE)\nmoda    &lt;- modeest::mlv(x, method = \"mfv\", na.rm = TRUE)\nrango   &lt;- diff(range(x, na.rm = TRUE))\nvar_x   &lt;- var(x, na.rm = TRUE)\nsd_x    &lt;- sd(x, na.rm = TRUE)\niqr_x   &lt;- IQR(x, na.rm = TRUE)\n\ntibble(Media = media, Mediana = mediana, Moda = moda,\n       Rango = rango, Varianza = var_x, `Desv.Est` = sd_x, IQR = iqr_x)\n\n# A tibble: 1 × 7\n  Media Mediana  Moda Rango Varianza Desv.Est   IQR\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1   179     162   200   325    8805.     93.8    95\n\n\n\nhist(x, breaks = \"FD\", probability = TRUE,\n     main = \"Histograma con densidad\",\n     xlab = \"Variable X\", col = \"#cdeac0\", border = \"#2b9348\")\nlines(density(x, na.rm = TRUE))\ncurve(dnorm(x, mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE)),\n      add = TRUE, col = \"red\")\n\n\n\n\n\n\n\nqqnorm(x); qqline(x, col = \"red\")\n\n\n\n\n\n\n\n\n\ntibble(Asimetría = moments::skewness(x, na.rm = TRUE),\n       Curtosis  = moments::kurtosis(x, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  Asimetría Curtosis\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      1.01     3.13\n\n\n\n\n5.3 3) Exploración bivariada (opcional)\n\nplot(datos$Superficie, datos$Antiguedad,\n     main = \"Diagrama de Dispersión\",\n     xlab = \"Superficie\", ylab = \"Antigüedad\",\n     col = \"#2b9348\", pch = 19)"
  },
  {
    "objectID": "labs/lab01_epg.html#bibliografía",
    "href": "labs/lab01_epg.html#bibliografía",
    "title": "Laboratorio 1_epg: Introducción y Estadística Descriptiva",
    "section": "6 Bibliografía",
    "text": "6 Bibliografía\nCrespo, F. A. (2023). Introducción y Estadística Descriptiva. Universidad Alberto Hurtado."
  },
  {
    "objectID": "labs/lab03_epg.html",
    "href": "labs/lab03_epg.html",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs/lab03_epg.html#regresión-múltiple",
    "href": "labs/lab03_epg.html#regresión-múltiple",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "1 Regresión Múltiple",
    "text": "1 Regresión Múltiple\nLo primero en un modelo de regresión múltiple es estudiar la relación entre las variables.\nPara ello se utiliza la matriz de correlación, donde se despliegan los coeficientes de correlación para cada par de variables.\nMulticolinealidad: ocurre cuando dos o más variables presentan una alta correlación entre ellas.\nEsto implica que existe una relación directa entre las variables, haciendo difícil determinar cuánto aporta cada una a la explicación de la variable dependiente.\nDos variables con alta correlación no proporcionan información adicional.\nRegla general para elegir variables:\n\nNo debe haber correlación alta entre variables predictoras o explicativas (\\(x\\)).\n\nSe debe preferir incluir variables independientes entre sí."
  },
  {
    "objectID": "labs/lab03_epg.html#marco-teórico-modelo-clásico-de-regresión-múltiple-lineal",
    "href": "labs/lab03_epg.html#marco-teórico-modelo-clásico-de-regresión-múltiple-lineal",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "2 Marco Teórico: Modelo Clásico de Regresión Múltiple Lineal",
    "text": "2 Marco Teórico: Modelo Clásico de Regresión Múltiple Lineal\nEl modelo lineal múltiple se puede escribir de forma matricial como:\n\\[\ny = 1_n \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + \\dots + x_k \\beta_k + \\varepsilon\n\\tag{3.1}\n\\]\no en forma compacta:\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.2}\n\\]\ndonde:\n- \\(Y\\) es el vector de observaciones dependientes (\\(n \\times 1\\)).\n- \\(X\\) es la matriz de observaciones de las variables explicativas (\\(n \\times (k+1)\\)).\n- \\(\\beta\\) es el vector de parámetros desconocidos (\\(\\beta_0, \\beta_1, \\dots, \\beta_k\\)).\n- \\(\\varepsilon\\) es el vector de errores aleatorios."
  },
  {
    "objectID": "labs/lab03_epg.html#supuestos-del-modelo-clásico",
    "href": "labs/lab03_epg.html#supuestos-del-modelo-clásico",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "3 Supuestos del Modelo Clásico",
    "text": "3 Supuestos del Modelo Clásico\n\n3.1 Supuesto 1\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.3}\n\\]\n\n\n3.2 Supuesto 2\n\\(X \\in \\mathbb{R}^{n \\times (k+1)}\\) tiene rango completo (condición de identificación).\n\n\n3.3 Supuesto 3\nEl error tiene esperanza condicional nula:\n\\[\nE[\\varepsilon | X] =\n\\begin{bmatrix}\nE[\\varepsilon_1|X] \\\\\nE[\\varepsilon_2|X] \\\\\n\\vdots \\\\\nE[\\varepsilon_n|X]\n\\end{bmatrix}\n= 0\n\\tag{3.4}\n\\]\nAdemás:\n\\[\n\\text{Var}[\\varepsilon_j | X] = \\sigma^2, \\quad j = 1, \\dots, n\n\\tag{3.5}\n\\]\n\\[\n\\text{Cov}[\\varepsilon_i, \\varepsilon_j | X] = 0, \\quad i \\neq j\n\\tag{3.6}\n\\]\nEsto implica homocedasticidad (varianza constante) y no autocorrelación entre los errores.\n\n\n3.4 Supuesto 4\n\\[\nE[\\varepsilon \\varepsilon'] = \\sigma^2 I_n\n\\tag{3.7}\n\\]\n\n\n3.5 Supuesto 5\n\\(X\\) es no estocástica, es decir, se asume conocida o fija en el muestreo.\n\n\n3.6 Supuesto 6\nLos errores son normales:\n\\[\n\\varepsilon | X \\sim N(0, \\sigma^2 I_n)\n\\tag{3.8}\n\\]"
  },
  {
    "objectID": "labs/lab03_epg.html#estimadores-de-la-regresión",
    "href": "labs/lab03_epg.html#estimadores-de-la-regresión",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "4 Estimadores de la Regresión",
    "text": "4 Estimadores de la Regresión\nLos estimadores se pueden obtener por dos vías:\n\nMáxima verosimilitud, dada la normalidad de los errores.\n\nMínimos cuadrados ordinarios (OLS).\n\nMinimizamos la suma de cuadrados de los errores:\n\\[\nS(\\beta) = (Y - X\\beta)'(Y - X\\beta)\n\\tag{3.9}\n\\]\nDesarrollando:\n\\[\nS(\\beta) = Y'Y - 2Y'X\\beta + \\beta'(X'X)\\beta\n\\tag{3.10}\n\\]\nDerivando respecto a \\(\\beta\\) e igualando a cero:\n\\[\nS'(\\beta) = -2X'Y + 2(X'X)\\beta = 0\n\\tag{3.11}\n\\]\nDe donde obtenemos el estimador:\n\\[\n\\hat{\\beta} = (X'X)^{-1}X'Y\n\\tag{3.12}\n\\]\nEl vector estimado de valores ajustados es:\n\\[\n\\hat{Y} = X\\hat{\\beta} = X(X'X)^{-1}X'Y\n\\tag{3.13}\n\\]\nY los residuos estimados:\n\\[\n\\hat{\\varepsilon} = Y - \\hat{Y} = (I - X(X'X)^{-1}X')Y\n\\tag{3.14}\n\\]\n\nPropiedades útiles:\n\\[\nX'\\hat{\\varepsilon} = 0, \\qquad \\hat{Y}'\\hat{\\varepsilon} = 0\n\\tag{3.15}\n\\]\nLa variación cuadrática de los residuos es:\n\\[\n\\hat{\\varepsilon}'\\hat{\\varepsilon} = Y'(I - X(X'X)^{-1}X')Y\n\\tag{3.16}\n\\]"
  },
  {
    "objectID": "labs/lab03_epg.html#coeficiente-de-determinación-r2",
    "href": "labs/lab03_epg.html#coeficiente-de-determinación-r2",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "5 Coeficiente de Determinación (\\(R^2\\))",
    "text": "5 Coeficiente de Determinación (\\(R^2\\))\nA partir de (3.16):\n\\[\nY'Y = (\\hat{Y} + \\hat{\\varepsilon})'(\\hat{Y} + \\hat{\\varepsilon}) = \\hat{Y}'\\hat{Y} + \\hat{\\varepsilon}'\\hat{\\varepsilon}\n\\tag{3.17}\n\\]\nEn términos de varianzas:\n\\[\n\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2 = \\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2 + \\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2\n\\tag{3.18}\n\\]\nPor tanto:\n\\[\nR^2 = 1 - \\frac{\\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n= \\frac{\\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n\\tag{3.19}\n\\]\n\n\n5.1 Contraste F global\nHipótesis:\n\\[\nH_0: \\beta_1 = \\beta_2 = \\dots = \\beta_k = 0\n\\tag{3.20}\n\\]\nEl estadístico es:\n\\[\nF = \\frac{R^2 / k}{(1 - R^2) / (n - k - 1)} \\sim F_{k,\\, n - k - 1}\n\\tag{3.21}\n\\]\nRechazamos \\(H_0\\) si \\(P(F \\ge f) \\le \\alpha\\).\n\n\n\n5.2 Propiedades de los estimadores\n\\[\nE[\\hat{\\beta}] = \\beta, \\qquad\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X'X)^{-1}\n\\tag{3.22}\n\\]\nPara los residuos:\n\\[\nE[\\hat{\\varepsilon}] = 0, \\qquad\n\\text{Cov}(\\hat{\\varepsilon}) = \\sigma^2 [I - X(X'X)^{-1}X']\n\\tag{3.23}\n\\]\nEstimador insesgado de \\(\\sigma^2\\):\n\\[\ns^2 = \\frac{\\hat{\\varepsilon}'\\hat{\\varepsilon}}{n - k - 1}\n\\tag{3.24}\n\\]\n\n\n\n5.3 Contraste individual para \\(\\beta_j\\)\n\\[\nH_0: \\beta_j = \\beta_j^*, \\qquad H_1: \\beta_j \\neq \\beta_j^*\n\\tag{3.25}\n\\]\nEl estadístico:\n\\[\nt_j = \\frac{\\hat{\\beta}_j - \\beta_j^*}{s \\sqrt{(X'X)^{-1}_{jj}}}\n\\sim t_{n - k - 1}\n\\tag{3.26}\n\\]\nRechazamos \\(H_0\\) si \\(|t_j| &gt; t_{\\alpha/2,\\, n - k - 1}\\).\nEl p-valor se obtiene como:\n\\[\np = P(|t_j| &gt; |t_j^{obs}|)\n\\tag{3.27}\n\\]\n\n\n\n5.4 Intervalos de confianza\nPara cada \\(\\beta_j\\):\n\\[\n\\hat{\\beta}_j \\pm t_{\\alpha/2,\\, n - k - 1} \\, s \\sqrt{(X'X)^{-1}_{jj}}\n\\tag{3.28}\n\\]\nPara la varianza del error:\n\\[\n\\left[\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, 1 - \\alpha/2}},\n\\quad\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, \\alpha/2}}\n\\right]\n\\tag{3.29}\n\\]\n\n\n\n5.5 Predicción\nPara un nuevo vector \\(x_0\\) (incluyendo el valor 1 si el modelo tiene constante):\n\\[\n\\hat{y}_0 = x_0' \\hat{\\beta}\n\\tag{3.30}\n\\]\nVarianza del estimador:\n\\[\nh_0 = x_0'(X'X)^{-1}x_0\n\\tag{3.31}\n\\]\nIntervalo de confianza para la predicción:\n\\[\n\\hat{y}_0 \\pm s \\sqrt{1 + h_0} \\; t_{\\alpha/2,\\, n - k - 1}\n\\tag{3.32}\n\\]\n\n\n\n5.6 Diagnósticos de supuestos\nDurbin–Watson (autocorrelación de errores):\n\\[\nD = \\frac{\\sum_{i=2}^{n} (e_i - e_{i-1})^2}{\\sum_{i=1}^{n} e_i^2}\n\\tag{3.33}\n\\]\n\nSi \\(D \\approx 2\\): no hay autocorrelación.\n\nSi \\(D \\approx 0\\): autocorrelación positiva.\n\nSi \\(D \\approx 4\\): autocorrelación negativa.\n\n\nTest de Breusch–Pagan (homocedasticidad):\n\\[\nH_0: \\text{Var}(\\varepsilon_i) = \\sigma^2 \\quad \\forall i\n\\tag{3.34}\n\\]\nSi el valor-p es mayor que 0.05, se asume que los errores tienen varianza constante.\n\n\n✅ Resumen:\nEl modelo clásico de regresión múltiple lineal supone linealidad, independencia, homocedasticidad y normalidad.\nLos estimadores OLS son BLUE (Best Linear Unbiased Estimators) bajo estos supuestos."
  },
  {
    "objectID": "labs/lab03_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "href": "labs/lab03_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "6 Aplicación en R (sobre los contenidos anteriores)",
    "text": "6 Aplicación en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (según tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\n# Verificación de archivos necesarios\nif (!file.exists(file.path(data_path, \"costos.xlsx\"))) {\n  stop(\"⚠️ No se encontró 'costos.xlsx' en data_path\")\n}\n\n# Librerías necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"corrplot\",\"lmtest\"))\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(corrplot)\nlibrary(lmtest)\n\n\n# Cargar datos\ndatos &lt;- read.xlsx(file.path(data_path, \"costos.xlsx\"), sheet = \"Hoja1\", colNames = TRUE)\n\n# Matriz de correlación y gráficos exploratorios\nr &lt;- cor(datos, use = \"pairwise.complete.obs\")\npairs(datos, main = \"Gráficos de dispersión por pares\")\n\n\n\n\n\n\n\ncorrplot(r, method = \"circle\", type = \"lower\", diag = FALSE,\n         tl.col = \"black\", tl.cex = 1, tl.offset = 0.1, tl.srt = 45)\n\n\n\n\n\n\n\n\n\n# Modelo de regresión múltiple (con intercepto)\nmodelo &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones, data = datos)\n\n# Estadísticos del modelo\nsummary(modelo)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones, \n    data = datos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7157  -2827    768   1449   9407 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          19796.44   12787.83   1.548 0.156013    \nHoras_maquina           65.44       6.74   9.709 4.57e-06 ***\nNumero_preparaciones   322.21      58.66   5.493 0.000384 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4951 on 9 degrees of freedom\nMultiple R-squared:  0.9472,    Adjusted R-squared:  0.9354 \nF-statistic: 80.66 on 2 and 9 DF,  p-value: 1.792e-06\n\n# Guardando los residuos\nepsilon &lt;- modelo$residuals\n\n\n# Análisis de residuos\nhist(epsilon, main = \"Histograma de residuos\", col = \"#cdeac0\", border = \"#2b9348\")\n\n\n\n\n\n\n\nplot(density(epsilon), main = \"Densidad de residuos\")\n\n\n\n\n\n\n\nshapiro.test(epsilon)  # Normalidad de residuos\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95577, p-value = 0.7222\n\n# Autocorrelación de residuos (Durbin-Watson) y heterocedasticidad (Breusch-Pagan)\ndwtest(modelo, alternative = \"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0815, p-value = 0.7416\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 1.0153, df = 2, p-value = 0.6019\n\n\n\n# Cálculo manual del estadístico F (usando un R2 dado)\nR2 &lt;- 0.9472\nF  &lt;- (R2/2) / ((1 - R2) / (12 - 3))\nF\n\n[1] 80.72727\n\n# Valor crítico F (α = 0.05, gl1 = 2, gl2 = 9)\nqf(0.05, 2, 9, lower.tail = FALSE)\n\n[1] 4.256495\n\n\n\n# Desviación estándar del error\ns &lt;- sqrt(sum(epsilon^2) / (12 - 2 - 1))\ns\n\n[1] 4951.106\n\n# Intervalos de confianza para coeficientes\nconfint(modelo)\n\n                           2.5 %     97.5 %\n(Intercept)          -9131.64046 48724.5095\nHoras_maquina           50.18894    80.6827\nNumero_preparaciones   189.50994   454.9046\n\nout &lt;- summary(modelo)\nout$coefficients[, 1]  # Betas\n\n         (Intercept)        Horas_maquina Numero_preparaciones \n         19796.43452             65.43582            322.20728 \n\nout$coefficients[, 2]  # Error estándar\n\n         (Intercept)        Horas_maquina Numero_preparaciones \n        12787.827235             6.739972            58.659648 \n\n# Estimación manual de IC para un coeficiente (ejemplo)\ntcrit &lt;- -1 * qt(0.025, 12 - 2 - 1, lower.tail = FALSE)\nBHM  &lt;- 65.44\nsbhm &lt;- 6.74\nlimitsupBHM &lt;- BHM + tcrit * sbhm\nlimitinfBHM &lt;- BHM - tcrit * sbhm\nc(liminfBHM = limitinfBHM, limitsupBHM = limitsupBHM)\n\n  liminfBHM limitsupBHM \n   80.68694    50.19306 \n\n\n\n# IC para la varianza del error (chi-cuadrado)\ngamma1 &lt;- qchisq(0.025, 12 - 2 - 1)\ngamma2 &lt;- qchisq(0.975, 12 - 2 - 1)\ns2_LI  &lt;- (12 - 2 - 1) * s^2 / gamma2\ns2_LS  &lt;- (12 - 2 - 1) * s^2 / gamma1\nc(s2_LI = s2_LI, s2_LS = s2_LS)\n\n   s2_LI    s2_LS \n11597739 81699732 \n\n\n\n# Predicción para un nuevo valor\nnuevo &lt;- data.frame(Horas_maquina = c(2000), Numero_preparaciones = c(220))\nvalor_predicho  &lt;- predict(object = modelo, newdata = nuevo)\nvalor_predicho2 &lt;- predict(object = modelo, newdata = nuevo, interval = \"confidence\")\nvalor_predicho\n\n       1 \n221553.7 \n\nvalor_predicho2\n\n       fit      lwr      upr\n1 221553.7 210265.6 232841.8\n\n\n\n# Predicción manual con matrices\nX &lt;- cbind(1, datos$Horas_maquina, datos$Numero_preparaciones)\nM &lt;- solve(t(X) %*% X)\nbeta &lt;- M %*% t(X) %*% datos$Costos_generales\n\nx0 &lt;- c(1, 2000, 220)\nh0 &lt;- t(x0) %*% M %*% x0\ny0 &lt;- t(beta) %*% x0\n\ny_limsup &lt;- y0 + s * sqrt(1 + h0) * qt(0.975, 12 - 2 - 1, lower.tail = FALSE)\ny_liminf &lt;- y0 - s * sqrt(1 + h0) * qt(0.975, 12 - 2 - 1, lower.tail = FALSE)\nc(y_liminf = y_liminf, y_limsup = y_limsup)\n\ny_liminf y_limsup \n237455.4 205651.9 \n\n\n\n# Gráfico: valor Y estimado vs Y real\nplot(modelo$fitted.values, datos$Costos_generales,\n     main = \"Revisión Valor Real vs Valor Predicho\",\n     xlab = \"Y estimado\", ylab = \"Y real\")\nabline(a = 0, b = 1, col = \"red\")\n\n\n\n\n\n\n\n\n\n# Modelo sin constante\nmodelo2 &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones - 1, data = datos)\nsummary(modelo2)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones - \n    1, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9042.2 -3486.9   739.7  3467.0  9300.3 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \nHoras_maquina          69.994      6.472  10.814 7.72e-07 ***\nNumero_preparaciones  390.723     41.098   9.507 2.52e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5286 on 10 degrees of freedom\nMultiple R-squared:  0.9992,    Adjusted R-squared:  0.999 \nF-statistic:  6095 on 2 and 10 DF,  p-value: 3.699e-16\n\nepsilon2 &lt;- modelo2$residuals\nhist(epsilon2, main = \"Histograma de residuos (sin constante)\", col = \"#cdeac0\", border = \"#2b9348\")\n\n\n\n\n\n\n\nplot(density(epsilon2), main = \"Densidad de residuos (sin constante)\")\n\n\n\n\n\n\n\nshapiro.test(epsilon2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon2\nW = 0.97973, p-value = 0.9825\n\ndwtest(modelo2, alternative = \"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo2\nDW = 2.1284, p-value = 0.9776\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo2\nBP = 0.33027, df = 1, p-value = 0.5655\n\nplot(modelo2$fitted.values, datos$Costos_generales,\n     main = \"Revisión Valor Real vs Valor Predicho (sin constante)\",\n     xlab = \"Y estimado\", ylab = \"Y real\")\nabline(a = 0, b = 1, col = \"red\")"
  },
  {
    "objectID": "labs/lab03_epg.html#bibliografía",
    "href": "labs/lab03_epg.html#bibliografía",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "7 Bibliografía",
    "text": "7 Bibliografía\nCrespo, F. A. (2021). Regresión Múltiple. Universidad Alberto Hurtado."
  }
]