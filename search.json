[
  {
    "objectID": "labs_epg/lab07_epg.html",
    "href": "labs_epg/lab07_epg.html",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos\nDescargar PDF de contenidos teóricos"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#carga-de-librerías",
    "href": "labs_epg/lab07_epg.html#carga-de-librerías",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "3.1 Carga de librerías",
    "text": "3.1 Carga de librerías\n\n#install.packages(c(\n#  \"FactoMineR\",       # PCA y métodos multivariados \n#  \"psych\",            # Análisis psicométrico (KMO, etc.)\n#  \"corrplot\",         # Gráficos de correlación\n#  \"PerformanceAnalytics\"  # Estadísticos financieros y correlaciones\n#))\n\nlibrary(FactoMineR)       # PCA y funciones de análisis factorial\nlibrary(dplyr)            # Manipulación de datos\nlibrary(psych)            # KMO, análisis psicométrico\nlibrary(corrplot)         # Matriz de correlaciones graficadas\nlibrary(PerformanceAnalytics) # chart.Correlation"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#ruta-de-trabajo",
    "href": "labs_epg/lab07_epg.html#ruta-de-trabajo",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "3.2 Ruta de trabajo",
    "text": "3.2 Ruta de trabajo\nUsaremos la ruta estándar de tus labs:\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\""
  },
  {
    "objectID": "labs_epg/lab07_epg.html#importar-datos-de-decathlon",
    "href": "labs_epg/lab07_epg.html#importar-datos-de-decathlon",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.1 Importar datos de Decathlon",
    "text": "4.1 Importar datos de Decathlon\nEn el script original se usa un archivo CSV con ; como separador:\n\narchivo_decathlon &lt;- file.path(ruta_datos, \"data_PCA_Decathlon.csv\")\n\ndecathlon &lt;- read.table(\n  archivo_decathlon,\n  header      = TRUE,\n  sep         = \";\",\n  dec         = \".\",\n  row.names   = 1,\n  check.names = FALSE\n)\n\nsummary(decathlon)\n\n      100m         Long jump       Shot put       High jump          400m      \n Min.   :10.44   Min.   :6.61   Min.   :12.68   Min.   :1.850   Min.   :46.81  \n 1st Qu.:10.85   1st Qu.:7.03   1st Qu.:13.88   1st Qu.:1.920   1st Qu.:48.93  \n Median :10.98   Median :7.30   Median :14.57   Median :1.950   Median :49.40  \n Mean   :11.00   Mean   :7.26   Mean   :14.48   Mean   :1.977   Mean   :49.62  \n 3rd Qu.:11.14   3rd Qu.:7.48   3rd Qu.:14.97   3rd Qu.:2.040   3rd Qu.:50.30  \n Max.   :11.64   Max.   :7.96   Max.   :16.36   Max.   :2.150   Max.   :53.20  \n     110m H          Discus        Pole vault       Javeline    \n Min.   :13.97   Min.   :37.92   Min.   :4.200   Min.   :50.31  \n 1st Qu.:14.21   1st Qu.:41.90   1st Qu.:4.500   1st Qu.:55.27  \n Median :14.48   Median :44.41   Median :4.800   Median :58.36  \n Mean   :14.61   Mean   :44.33   Mean   :4.762   Mean   :58.32  \n 3rd Qu.:14.98   3rd Qu.:46.07   3rd Qu.:4.920   3rd Qu.:60.89  \n Max.   :15.67   Max.   :51.65   Max.   :5.400   Max.   :70.52  \n     1500m            Rank           Points     Competition       \n Min.   :262.1   Min.   : 1.00   Min.   :7313   Length:41         \n 1st Qu.:271.0   1st Qu.: 6.00   1st Qu.:7802   Class :character  \n Median :278.1   Median :11.00   Median :8021   Mode  :character  \n Mean   :279.0   Mean   :12.12   Mean   :8005                     \n 3rd Qu.:285.1   3rd Qu.:18.00   3rd Qu.:8122                     \n Max.   :317.0   Max.   :28.00   Max.   :8893                     \n\n\n\n\n\n\n\n\nTip\n\n\n\nObserva:\n\nNúmero de individuos (atletas).\n\nNúmero de variables cuantitativas activas (primeras 10 columnas).\n\nVariables adicionales (competición, ranking, etc.) que luego usaremos como suplementarias."
  },
  {
    "objectID": "labs_epg/lab07_epg.html#estandarización-manual-opcional",
    "href": "labs_epg/lab07_epg.html#estandarización-manual-opcional",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.2 Estandarización manual (opcional)",
    "text": "4.2 Estandarización manual (opcional)\nEl PCA de FactoMineR::PCA ya estandariza por defecto las variables cuantitativas, pero el script muestra cómo hacerlo explícitamente:\n\ndecathlonnorm &lt;- decathlon[, 1:10] %&gt;% \n  mutate_all(~ scale(.) %&gt;% as.vector)\n\nhead(decathlonnorm)\n\n                100m  Long jump    Shot put   High jump       400m      110m H\nSebrle    -0.5628739  1.8331131 2.283919585  1.60955474 -1.0892025 -1.17818270\nClay      -2.1216730  2.2123779 0.913271989  0.93502243 -0.3696226 -1.00861538\nKarpov    -1.8935560  1.7382969 1.762345721  1.27228858 -2.4329962 -1.34775002\nMacey     -0.4107959  0.6637134 1.519753226  1.94682089 -0.5603546 -0.09719103\nWarners   -1.4373221  1.5170591 0.003550134 -0.07677604 -1.4273183 -1.26296636\nZsivoczky -0.3347570 -0.3792648 1.010308987  1.60955474 -0.1875602  0.72944966\n              Discus Pole vault    Javeline       1500m\nSebrle     1.3009450  0.8545364  2.52825135  0.08439142\nClay       1.7124500  0.4948240  2.36043901  0.25486670\nKarpov     2.1683620 -0.5843134 -0.57524110 -0.07837391\nMacey      1.1884472 -1.3037383  0.02971203 -1.16547502\nWarners   -0.1763283  0.4948240 -0.60631746 -0.08351387\nZsivoczky  0.3832000 -0.2246009  1.06351893 -0.81253124"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#matriz-de-correlación",
    "href": "labs_epg/lab07_epg.html#matriz-de-correlación",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.3 Matriz de correlación",
    "text": "4.3 Matriz de correlación\nAntes de hacer PCA, miramos las correlaciones entre variables:\n\ncor.mat &lt;- round(cor(decathlon[, 1:10]), 2)\ncor.mat\n\n            100m Long jump Shot put High jump  400m 110m H Discus Pole vault\n100m        1.00     -0.60    -0.36     -0.25  0.52   0.58  -0.22      -0.08\nLong jump  -0.60      1.00     0.18      0.29 -0.60  -0.51   0.19       0.20\nShot put   -0.36      0.18     1.00      0.49 -0.14  -0.25   0.62       0.06\nHigh jump  -0.25      0.29     0.49      1.00 -0.19  -0.28   0.37      -0.16\n400m        0.52     -0.60    -0.14     -0.19  1.00   0.55  -0.12      -0.08\n110m H      0.58     -0.51    -0.25     -0.28  0.55   1.00  -0.33       0.00\nDiscus     -0.22      0.19     0.62      0.37 -0.12  -0.33   1.00      -0.15\nPole vault -0.08      0.20     0.06     -0.16 -0.08   0.00  -0.15       1.00\nJaveline   -0.16      0.12     0.37      0.17  0.00   0.01   0.16      -0.03\n1500m      -0.06     -0.03     0.12     -0.04  0.41   0.04   0.26       0.25\n           Javeline 1500m\n100m          -0.16 -0.06\nLong jump      0.12 -0.03\nShot put       0.37  0.12\nHigh jump      0.17 -0.04\n400m           0.00  0.41\n110m H         0.01  0.04\nDiscus         0.16  0.26\nPole vault    -0.03  0.25\nJaveline       1.00 -0.18\n1500m         -0.18  1.00\n\ncorrplot(\n  cor.mat,\n  type  = \"upper\",\n  order = \"hclust\",\n  tl.col = \"black\",\n  tl.srt = 45\n)\n\n\n\n\n\n\n\nchart.Correlation(decathlon[, 1:10],\n                  histogram = TRUE,\n                  pch       = 19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nCorrelaciones altas (en valor absoluto) entre variables sugieren redundancia de información, lo que hace atractivo aplicar PCA.\n\ncorrplot agrupa visualmente las variables con patrones de correlación similares."
  },
  {
    "objectID": "labs_epg/lab07_epg.html#pca-con-variables-activas-primeras-10-columnas",
    "href": "labs_epg/lab07_epg.html#pca-con-variables-activas-primeras-10-columnas",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.4 PCA con variables activas (primeras 10 columnas)",
    "text": "4.4 PCA con variables activas (primeras 10 columnas)\n\nres &lt;- PCA(decathlon[, 1:10], ncp = 5)\nsummary.PCA(res)\n\n\nCall:\nPCA(X = decathlon[, 1:10], ncp = 5) \n\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3   Dim.4   Dim.5   Dim.6   Dim.7\nVariance               3.272   1.737   1.405   1.057   0.685   0.599   0.451\n% of var.             32.719  17.371  14.049  10.569   6.848   5.993   4.512\nCumulative % of var.  32.719  50.090  64.140  74.708  81.556  87.548  92.061\n                       Dim.8   Dim.9  Dim.10\nVariance               0.397   0.215   0.182\n% of var.              3.969   2.148   1.822\nCumulative % of var.  96.030  98.178 100.000\n\nIndividuals (the 10 first)\n               Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nSebrle     |  4.843 |  4.038 12.158  0.695 |  1.366  2.619  0.080 | -0.290\nClay       |  4.647 |  3.919 11.451  0.711 |  0.837  0.984  0.032 |  0.231\nKarpov     |  5.006 |  4.620 15.911  0.852 |  0.040  0.002  0.000 | -0.042\nMacey      |  3.434 |  2.233  3.719  0.423 |  1.042  1.524  0.092 | -1.864\nWarners    |  2.979 |  2.168  3.505  0.530 | -1.803  4.565  0.366 |  0.851\nZsivoczky  |  2.566 |  0.925  0.638  0.130 |  1.169  1.918  0.207 | -1.477\nHernu      |  1.824 |  0.889  0.589  0.238 | -0.618  0.537  0.115 | -0.898\nNool       |  3.098 |  0.295  0.065  0.009 | -1.546  3.354  0.249 |  1.355\nBernard    |  2.827 |  1.906  2.709  0.455 | -0.086  0.010  0.001 | -0.757\nSchwarzl   |  1.971 |  0.081  0.005  0.002 | -1.353  2.572  0.472 |  0.822\n              ctr   cos2  \nSebrle      0.146  0.004 |\nClay        0.093  0.002 |\nKarpov      0.003  0.000 |\nMacey       6.034  0.295 |\nWarners     1.257  0.082 |\nZsivoczky   3.790  0.332 |\nHernu       1.401  0.242 |\nNool        3.189  0.191 |\nBernard     0.995  0.072 |\nSchwarzl    1.174  0.174 |\n\nVariables\n              Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr   cos2\n100m       | -0.775 18.344  0.600 |  0.187  2.016  0.035 | -0.184  2.420  0.034\nLong jump  |  0.742 16.822  0.550 | -0.345  6.869  0.119 |  0.182  2.363  0.033\nShot put   |  0.623 11.844  0.388 |  0.598 20.607  0.358 | -0.023  0.039  0.001\nHigh jump  |  0.572  9.998  0.327 |  0.350  7.064  0.123 | -0.260  4.794  0.067\n400m       | -0.680 14.116  0.462 |  0.569 18.666  0.324 |  0.131  1.230  0.017\n110m H     | -0.746 17.020  0.557 |  0.229  3.013  0.052 | -0.093  0.611  0.009\nDiscus     |  0.552  9.328  0.305 |  0.606 21.162  0.368 |  0.043  0.131  0.002\nPole vault |  0.050  0.077  0.003 | -0.180  1.873  0.033 |  0.692 34.061  0.479\nJaveline   |  0.277  2.347  0.077 |  0.317  5.784  0.100 | -0.390 10.807  0.152\n1500m      | -0.058  0.103  0.003 |  0.474 12.946  0.225 |  0.782 43.543  0.612\n            \n100m       |\nLong jump  |\nShot put   |\nHigh jump  |\n400m       |\n110m H     |\nDiscus     |\nPole vault |\nJaveline   |\n1500m      |\n\nprint(res)\n\n**Results for the Principal Component Analysis (PCA)**\nThe analysis was performed on 41 individuals, described by 10 variables\n*The results are available in the following objects:\n\n   name               description                          \n1  \"$eig\"             \"eigenvalues\"                        \n2  \"$var\"             \"results for the variables\"          \n3  \"$var$coord\"       \"coord. for the variables\"           \n4  \"$var$cor\"         \"correlations variables - dimensions\"\n5  \"$var$cos2\"        \"cos2 for the variables\"             \n6  \"$var$contrib\"     \"contributions of the variables\"     \n7  \"$ind\"             \"results for the individuals\"        \n8  \"$ind$coord\"       \"coord. for the individuals\"         \n9  \"$ind$cos2\"        \"cos2 for the individuals\"           \n10 \"$ind$contrib\"     \"contributions of the individuals\"   \n11 \"$call\"            \"summary statistics\"                 \n12 \"$call$centre\"     \"mean of the variables\"              \n13 \"$call$ecart.type\" \"standard error of the variables\"    \n14 \"$call$row.w\"      \"weights for the individuals\"        \n15 \"$call$col.w\"      \"weights for the variables\"          \n\n\nAquí usamos sólo las variables activas (sin incluir todavía variables suplementarias).\n\n4.4.1 Adecuación del análisis factorial: Bartlett y KMO\n\nbartlett.test(decathlon[, 1:10])\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  decathlon[, 1:10]\nBartlett's K-squared = 1268.8, df = 9, p-value &lt; 2.2e-16\n\nKMO(decathlon[, 1:10])\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = decathlon[, 1:10])\nOverall MSA =  0.6\nMSA for each item = \n      100m  Long jump   Shot put  High jump       400m     110m H     Discus \n      0.69       0.72       0.57       0.70       0.61       0.83       0.54 \nPole vault   Javeline      1500m \n      0.24       0.44       0.29 \n\n\n\n\n\n\n\n\nNota\n\n\n\n\nUn p-value pequeño en Bartlett indica que la matriz de correlaciones no es esférica, por lo que PCA tiene sentido.\n\nKMO cercano a 1 indica buena adecuación; valores muy bajos desaconsejan el análisis factorial."
  },
  {
    "objectID": "labs_epg/lab07_epg.html#pca-con-variables-suplementarias",
    "href": "labs_epg/lab07_epg.html#pca-con-variables-suplementarias",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.5 PCA con variables suplementarias",
    "text": "4.5 PCA con variables suplementarias\nSupongamos que las columnas 11 y 12 son cuantitativas suplementarias (no influyen en la construcción de las componentes) y la 13 es una cualitativa suplementaria (por ejemplo, tipo de competición).\n\nres &lt;- PCA(\n  decathlon,\n  ncp        = 5,\n  quanti.sup = 11:12,\n  quali.sup  = 13\n)\n\nsummary(res, nbelements = Inf)\n\n\nCall:\nPCA(X = decathlon, ncp = 5, quanti.sup = 11:12, quali.sup = 13) \n\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3   Dim.4   Dim.5   Dim.6   Dim.7\nVariance               3.272   1.737   1.405   1.057   0.685   0.599   0.451\n% of var.             32.719  17.371  14.049  10.569   6.848   5.993   4.512\nCumulative % of var.  32.719  50.090  64.140  74.708  81.556  87.548  92.061\n                       Dim.8   Dim.9  Dim.10\nVariance               0.397   0.215   0.182\n% of var.              3.969   2.148   1.822\nCumulative % of var.  96.030  98.178 100.000\n\nIndividuals\n                Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nSebrle      |  4.843 |  4.038 12.158  0.695 |  1.366  2.619  0.080 | -0.290\nClay        |  4.647 |  3.919 11.451  0.711 |  0.837  0.984  0.032 |  0.231\nKarpov      |  5.006 |  4.620 15.911  0.852 |  0.040  0.002  0.000 | -0.042\nMacey       |  3.434 |  2.233  3.719  0.423 |  1.042  1.524  0.092 | -1.864\nWarners     |  2.979 |  2.168  3.505  0.530 | -1.803  4.565  0.366 |  0.851\nZsivoczky   |  2.566 |  0.925  0.638  0.130 |  1.169  1.918  0.207 | -1.477\nHernu       |  1.824 |  0.889  0.589  0.238 | -0.618  0.537  0.115 | -0.898\nNool        |  3.098 |  0.295  0.065  0.009 | -1.546  3.354  0.249 |  1.355\nBernard     |  2.827 |  1.906  2.709  0.455 | -0.086  0.010  0.001 | -0.757\nSchwarzl    |  1.971 |  0.081  0.005  0.002 | -1.353  2.572  0.472 |  0.822\nPogorelov   |  2.383 |  0.540  0.217  0.051 |  0.771  0.834  0.105 |  1.348\nSchoenbeck  |  1.797 |  0.114  0.010  0.004 | -0.040  0.002  0.000 |  0.740\nBarras      |  2.224 |  0.002  0.000  0.000 |  0.360  0.182  0.026 | -1.570\nSmith       |  3.536 |  0.870  0.565  0.061 |  1.059  1.576  0.090 | -1.643\nAveryanov   |  2.521 |  0.349  0.091  0.019 | -1.559  3.411  0.382 |  0.283\nOjaniemi    |  2.338 |  0.380  0.108  0.026 | -0.772  0.838  0.109 | -0.371\nSmirnov     |  2.021 | -0.485  0.175  0.057 | -1.061  1.580  0.275 | -1.228\nQi          |  1.764 | -0.434  0.141  0.061 | -0.326  0.149  0.034 | -1.070\nDrews       |  3.423 | -0.249  0.046  0.005 | -3.082 13.334  0.811 |  1.055\nParkhomenko |  3.486 | -1.069  0.853  0.094 |  2.093  6.152  0.361 | -1.000\nTerek       |  3.282 | -0.682  0.347  0.043 |  0.536  0.403  0.027 |  2.209\nGomez       |  2.613 | -0.290  0.063  0.012 | -1.197  2.011  0.210 | -1.306\nTuri        |  3.069 | -1.542  1.772  0.252 |  0.427  0.256  0.019 |  0.514\nLorenzo     |  3.510 | -2.409  4.324  0.471 | -1.583  3.518  0.203 | -1.502\nKarlivans   |  2.704 | -1.994  2.965  0.544 | -0.294  0.122  0.012 | -0.343\nKorkizoglou |  3.975 | -0.958  0.684  0.058 |  2.066  5.995  0.270 |  2.587\nUldal       |  2.946 | -2.562  4.894  0.757 |  0.245  0.085  0.007 | -0.419\nCasarsa     |  4.921 | -2.857  6.085  0.337 |  3.798 20.252  0.596 |  0.031\nSEBRLE      |  2.369 |  0.792  0.467  0.112 |  0.772  0.836  0.106 |  0.827\nCLAY        |  3.507 |  1.235  1.137  0.124 |  0.575  0.464  0.027 |  2.141\nKARPOV      |  3.396 |  1.358  1.375  0.160 |  0.484  0.329  0.020 |  1.956\nBERNARD     |  2.763 | -0.610  0.277  0.049 | -0.875  1.074  0.100 |  0.890\nYURKOV      |  3.018 | -0.586  0.256  0.038 |  2.131  6.376  0.499 | -1.225\nWARNERS     |  2.428 |  0.357  0.095  0.022 | -1.685  3.986  0.482 |  0.767\nZSIVOCZKY   |  2.563 |  0.272  0.055  0.011 | -1.094  1.680  0.182 | -1.283\nMcMULLEN    |  2.561 |  0.588  0.257  0.053 |  0.231  0.075  0.008 | -0.418\nMARTINEAU   |  3.742 | -1.995  2.968  0.284 |  0.561  0.442  0.022 | -0.730\nHERNU       |  2.794 | -1.546  1.782  0.306 |  0.488  0.335  0.031 |  0.841\nBARRAS      |  1.952 | -1.342  1.342  0.472 | -0.311  0.136  0.025 |  0.000\nNOOL        |  3.734 | -2.345  4.099  0.394 | -1.966  5.429  0.277 | -1.336\nBOURGUIGNON |  4.299 | -3.979 11.802  0.857 |  0.200  0.056  0.002 |  1.326\n               ctr   cos2  \nSebrle       0.146  0.004 |\nClay         0.093  0.002 |\nKarpov       0.003  0.000 |\nMacey        6.034  0.295 |\nWarners      1.257  0.082 |\nZsivoczky    3.790  0.332 |\nHernu        1.401  0.242 |\nNool         3.189  0.191 |\nBernard      0.995  0.072 |\nSchwarzl     1.174  0.174 |\nPogorelov    3.153  0.320 |\nSchoenbeck   0.952  0.170 |\nBarras       4.278  0.498 |\nSmith        4.689  0.216 |\nAveryanov    0.139  0.013 |\nOjaniemi     0.239  0.025 |\nSmirnov      2.619  0.369 |\nQi           1.987  0.368 |\nDrews        1.932  0.095 |\nParkhomenko  1.736  0.082 |\nTerek        8.472  0.453 |\nGomez        2.962  0.250 |\nTuri         0.459  0.028 |\nLorenzo      3.918  0.183 |\nKarlivans    0.204  0.016 |\nKorkizoglou 11.615  0.423 |\nUldal        0.305  0.020 |\nCasarsa      0.002  0.000 |\nSEBRLE       1.187  0.122 |\nCLAY         7.960  0.373 |\nKARPOV       6.644  0.332 |\nBERNARD      1.375  0.104 |\nYURKOV       2.606  0.165 |\nWARNERS      1.020  0.100 |\nZSIVOCZKY    2.857  0.250 |\nMcMULLEN     0.303  0.027 |\nMARTINEAU    0.925  0.038 |\nHERNU        1.227  0.091 |\nBARRAS       0.000  0.000 |\nNOOL         3.101  0.128 |\nBOURGUIGNON  3.055  0.095 |\n\nVariables\n               Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3    ctr\n100m        | -0.775 18.344  0.600 |  0.187  2.016  0.035 | -0.184  2.420\nLong jump   |  0.742 16.822  0.550 | -0.345  6.869  0.119 |  0.182  2.363\nShot put    |  0.623 11.844  0.388 |  0.598 20.607  0.358 | -0.023  0.039\nHigh jump   |  0.572  9.998  0.327 |  0.350  7.064  0.123 | -0.260  4.794\n400m        | -0.680 14.116  0.462 |  0.569 18.666  0.324 |  0.131  1.230\n110m H      | -0.746 17.020  0.557 |  0.229  3.013  0.052 | -0.093  0.611\nDiscus      |  0.552  9.328  0.305 |  0.606 21.162  0.368 |  0.043  0.131\nPole vault  |  0.050  0.077  0.003 | -0.180  1.873  0.033 |  0.692 34.061\nJaveline    |  0.277  2.347  0.077 |  0.317  5.784  0.100 | -0.390 10.807\n1500m       | -0.058  0.103  0.003 |  0.474 12.946  0.225 |  0.782 43.543\n              cos2  \n100m         0.034 |\nLong jump    0.033 |\nShot put     0.001 |\nHigh jump    0.067 |\n400m         0.017 |\n110m H       0.009 |\nDiscus       0.002 |\nPole vault   0.479 |\nJaveline     0.152 |\n1500m        0.612 |\n\nSupplementary continuous variables\n               Dim.1   cos2    Dim.2   cos2    Dim.3   cos2  \nRank        | -0.671  0.450 |  0.051  0.003 | -0.058  0.003 |\nPoints      |  0.956  0.914 | -0.017  0.000 | -0.066  0.004 |\n\nSupplementary categories\n                Dist    Dim.1   cos2 v.test    Dim.2   cos2 v.test    Dim.3\nDecastar    |  0.946 | -0.600  0.403 -1.430 | -0.038  0.002 -0.123 |  0.289\nOlympicG    |  0.439 |  0.279  0.403  1.430 |  0.017  0.002  0.123 | -0.134\n              cos2 v.test  \nDecastar     0.093  1.050 |\nOlympicG     0.093 -1.050 |\n\nprint(res)\n\n**Results for the Principal Component Analysis (PCA)**\nThe analysis was performed on 41 individuals, described by 13 variables\n*The results are available in the following objects:\n\n   name               \n1  \"$eig\"             \n2  \"$var\"             \n3  \"$var$coord\"       \n4  \"$var$cor\"         \n5  \"$var$cos2\"        \n6  \"$var$contrib\"     \n7  \"$ind\"             \n8  \"$ind$coord\"       \n9  \"$ind$cos2\"        \n10 \"$ind$contrib\"     \n11 \"$quanti.sup\"      \n12 \"$quanti.sup$coord\"\n13 \"$quanti.sup$cor\"  \n14 \"$quali.sup\"       \n15 \"$quali.sup$coord\" \n16 \"$quali.sup$v.test\"\n17 \"$call\"            \n18 \"$call$centre\"     \n19 \"$call$ecart.type\" \n20 \"$call$row.w\"      \n21 \"$call$col.w\"      \n   description                                              \n1  \"eigenvalues\"                                            \n2  \"results for the variables\"                              \n3  \"coord. for the variables\"                               \n4  \"correlations variables - dimensions\"                    \n5  \"cos2 for the variables\"                                 \n6  \"contributions of the variables\"                         \n7  \"results for the individuals\"                            \n8  \"coord. for the individuals\"                             \n9  \"cos2 for the individuals\"                               \n10 \"contributions of the individuals\"                       \n11 \"results for the supplementary quantitative variables\"   \n12 \"coord. for the supplementary quantitative variables\"    \n13 \"correlations suppl. quantitative variables - dimensions\"\n14 \"results for the supplementary categorical variables\"    \n15 \"coord. for the supplementary categories\"                \n16 \"v-test of the supplementary categories\"                 \n17 \"summary statistics\"                                     \n18 \"mean of the variables\"                                  \n19 \"standard error of the variables\"                        \n20 \"weights for the individuals\"                            \n21 \"weights for the variables\"                              \n\n\n\n4.5.1 Valores propios y varianza explicada\n\neigenvalues &lt;- res$eig\neigenvalues[, 1:3]\n\n        eigenvalue percentage of variance cumulative percentage of variance\ncomp 1   3.2719055              32.719055                          32.71906\ncomp 2   1.7371310              17.371310                          50.09037\ncomp 3   1.4049167              14.049167                          64.13953\ncomp 4   1.0568504              10.568504                          74.70804\ncomp 5   0.6847735               6.847735                          81.55577\ncomp 6   0.5992687               5.992687                          87.54846\ncomp 7   0.4512353               4.512353                          92.06081\ncomp 8   0.3968766               3.968766                          96.02958\ncomp 9   0.2148149               2.148149                          98.17773\ncomp 10  0.1822275               1.822275                         100.00000\n\nbarplot(\n  eigenvalues[, 2],\n  names.arg = 1:nrow(eigenvalues),\n  main = \"Porcentaje de varianza explicada\",\n  xlab = \"Componentes principales\",\n  ylab = \"Porcentaje de varianza\",\n  col  = \"steelblue\"\n)\n\nlines(x = 1:nrow(eigenvalues),\n      y = eigenvalues[, 2],\n      type = \"b\",\n      pch  = 19,\n      col  = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nLa primera columna son los valores propios (lambda_i).\n\nLa segunda columna es el porcentaje de varianza explicada.\n\nFíjate cuántas componentes necesitas para explicar, por ejemplo, el 70%–80% de la varianza."
  },
  {
    "objectID": "labs_epg/lab07_epg.html#descripción-de-las-dimensiones",
    "href": "labs_epg/lab07_epg.html#descripción-de-las-dimensiones",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.6 Descripción de las dimensiones",
    "text": "4.6 Descripción de las dimensiones\ndimdesc ayuda a interpretar cada componente, relacionándola con las variables originales:\n\ndimdesc(res)\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nPoints      0.9561543 2.099191e-22\nLong jump   0.7418997 2.849886e-08\nShot put    0.6225026 1.388321e-05\nHigh jump   0.5719453 9.362285e-05\nDiscus      0.5524665 1.802220e-04\nRank       -0.6705104 1.616348e-06\n400m       -0.6796099 1.028175e-06\n110m H     -0.7462453 2.136962e-08\n100m       -0.7747198 2.778467e-09\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nDiscus      0.6063134 2.650745e-05\nShot put    0.5983033 3.603567e-05\n400m        0.5694378 1.020941e-04\n1500m       0.4742238 1.734405e-03\nHigh jump   0.3502936 2.475025e-02\nJaveline    0.3169891 4.344974e-02\nLong jump  -0.3454213 2.696969e-02\n\n$Dim.3\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n           correlation      p.value\n1500m        0.7821428 1.554450e-09\nPole vault   0.6917567 5.480172e-07\nJaveline    -0.3896554 1.179331e-02\n\ndimdesc(res, axes = c(1, 2, 3, 4, 5))\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nPoints      0.9561543 2.099191e-22\nLong jump   0.7418997 2.849886e-08\nShot put    0.6225026 1.388321e-05\nHigh jump   0.5719453 9.362285e-05\nDiscus      0.5524665 1.802220e-04\nRank       -0.6705104 1.616348e-06\n400m       -0.6796099 1.028175e-06\n110m H     -0.7462453 2.136962e-08\n100m       -0.7747198 2.778467e-09\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nDiscus      0.6063134 2.650745e-05\nShot put    0.5983033 3.603567e-05\n400m        0.5694378 1.020941e-04\n1500m       0.4742238 1.734405e-03\nHigh jump   0.3502936 2.475025e-02\nJaveline    0.3169891 4.344974e-02\nLong jump  -0.3454213 2.696969e-02\n\n$Dim.3\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n           correlation      p.value\n1500m        0.7821428 1.554450e-09\nPole vault   0.6917567 5.480172e-07\nJaveline    -0.3896554 1.179331e-02\n\n$Dim.4\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n           correlation      p.value\nJaveline     0.7122773 1.761578e-07\nPole vault   0.5515340 1.857748e-04\n\n$Dim.5\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n           correlation      p.value\nHigh jump    0.5554396 0.0001635051\nPole vault   0.3299593 0.0351316637\nRank        -0.3500257 0.0248682140\n\nLink between the variable and the categorical variable (1-way anova)\n=============================================\n                   R2   p.value\nCompetition 0.1092271 0.0348183\n\nLink between variable and the categories of the categorical variables\n================================================================\n                       Estimate   p.value\nCompetition=Decastar  0.2938609 0.0348183\nCompetition=OlympicG -0.2938609 0.0348183\n\ndimdesc(res, proba = 0.2)\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nPoints      0.9561543 2.099191e-22\nLong jump   0.7418997 2.849886e-08\nShot put    0.6225026 1.388321e-05\nHigh jump   0.5719453 9.362285e-05\nDiscus      0.5524665 1.802220e-04\nJaveline    0.2771108 7.942460e-02\nRank       -0.6705104 1.616348e-06\n400m       -0.6796099 1.028175e-06\n110m H     -0.7462453 2.136962e-08\n100m       -0.7747198 2.778467e-09\n\nLink between the variable and the categorical variable (1-way anova)\n=============================================\n                    R2   p.value\nCompetition 0.05110487 0.1552515\n\nLink between variable and the categories of the categorical variables\n================================================================\n                       Estimate   p.value\nCompetition=OlympicG  0.4393744 0.1552515\nCompetition=Decastar -0.4393744 0.1552515\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation      p.value\nDiscus      0.6063134 2.650745e-05\nShot put    0.5983033 3.603567e-05\n400m        0.5694378 1.020941e-04\n1500m       0.4742238 1.734405e-03\nHigh jump   0.3502936 2.475025e-02\nJaveline    0.3169891 4.344974e-02\n110m H      0.2287933 1.501925e-01\nLong jump  -0.3454213 2.696969e-02\n\n$Dim.3\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n           correlation      p.value\n1500m        0.7821428 1.554450e-09\nPole vault   0.6917567 5.480172e-07\nHigh jump   -0.2595119 1.013160e-01\nJaveline    -0.3896554 1.179331e-02"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#coordenadas-cos2-y-contribuciones-de-las-variables",
    "href": "labs_epg/lab07_epg.html#coordenadas-cos2-y-contribuciones-de-las-variables",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.7 Coordenadas, cos2 y contribuciones de las variables",
    "text": "4.7 Coordenadas, cos2 y contribuciones de las variables\n\n# Coordenadas de las variables\nres$var$coord\n\n                 Dim.1      Dim.2       Dim.3       Dim.4       Dim.5\n100m       -0.77471983  0.1871420 -0.18440714 -0.03781826  0.30219639\nLong jump   0.74189974 -0.3454213  0.18221105  0.10178564  0.03667805\nShot put    0.62250255  0.5983033 -0.02337844  0.19059161  0.11115082\nHigh jump   0.57194530  0.3502936 -0.25951193 -0.13559420  0.55543957\n400m       -0.67960994  0.5694378  0.13146970  0.02930198 -0.08769157\n110m H     -0.74624532  0.2287933 -0.09263738  0.29083103  0.16432095\nDiscus      0.55246652  0.6063134  0.04295225 -0.25967143 -0.10482712\nPole vault  0.05034151 -0.1803569  0.69175665  0.55153397  0.32995932\nJaveline    0.27711085  0.3169891 -0.38965541  0.71227728 -0.30512892\n1500m      -0.05807706  0.4742238  0.78214280 -0.16108904 -0.15356189\n\n# Calidad de representación (cos2)\nres$var$cos2\n\n                 Dim.1      Dim.2        Dim.3        Dim.4       Dim.5\n100m       0.600190812 0.03502213 0.0340059930 0.0014302206 0.091322660\nLong jump  0.550415232 0.11931587 0.0332008675 0.0103603165 0.001345279\nShot put   0.387509426 0.35796686 0.0005465513 0.0363251605 0.012354505\nHigh jump  0.327121422 0.12270561 0.0673464410 0.0183857880 0.308513117\n400m       0.461869674 0.32425938 0.0172842817 0.0008586058 0.007689811\n110m H     0.556882084 0.05234639 0.0085816841 0.0845826853 0.027001375\nDiscus     0.305219255 0.36761593 0.0018448960 0.0674292539 0.010988725\nPole vault 0.002534268 0.03252860 0.4785272696 0.3041897208 0.108873151\nJaveline   0.076790421 0.10048206 0.1518313365 0.5073389244 0.093103658\n1500m      0.003372945 0.22488818 0.6117473613 0.0259496775 0.023581254\n\n# Contribuciones (en %)\nres$var$contrib\n\n                 Dim.1     Dim.2       Dim.3       Dim.4     Dim.5\n100m       18.34376957  2.016090  2.42049891  0.13532858 13.336184\nLong jump  16.82246707  6.868559  2.36319121  0.98030118  0.196456\nShot put   11.84353954 20.606785  0.03890276  3.43711486  1.804174\nHigh jump   9.99788710  7.063694  4.79362526  1.73967752 45.053306\n400m       14.11622887 18.666374  1.23027094  0.08124195  1.122971\n110m H     17.02011495  3.013382  0.61083225  8.00327927  3.943110\nDiscus      9.32848615 21.162245  0.13131711  6.38020830  1.604724\nPole vault  0.07745541  1.872547 34.06090024 28.78266727 15.899147\nJaveline    2.34696326  5.784369 10.80714169 48.00480246 13.596270\n1500m       0.10308808 12.945954 43.54331962  2.45537861  3.443657\n\n\n\n4.7.1 Gráfico de variables\n\nplot(res, choix = \"var\", title = \"Variables - componentes 1 y 2\", axes = 1:2)\n\n\n\n\n\n\n\nplot(res, choix = \"var\", title = \"Variables - componentes 3 y 4\", axes = 3:4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nLas variables cercanas unas a otras están positivamente correlacionadas.\n\nVariables opuestas en un mismo eje tienen correlación negativa.\n\nLa distancia al origen indica la importancia en esas componentes (cos2 alto)."
  },
  {
    "objectID": "labs_epg/lab07_epg.html#individuos-coordenadas-cos2-y-contribuciones",
    "href": "labs_epg/lab07_epg.html#individuos-coordenadas-cos2-y-contribuciones",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "4.8 Individuos: coordenadas, cos2 y contribuciones",
    "text": "4.8 Individuos: coordenadas, cos2 y contribuciones\n\n# Coordenadas de los individuos\nhead(res$ind$coord)\n\n              Dim.1       Dim.2      Dim.3      Dim.4      Dim.5\nSebrle    4.0384485  1.36582606 -0.2899565  1.9411341  0.3769545\nClay      3.9193652  0.83696136  0.2311753  1.4939721 -1.0376085\nKarpov    4.6199873  0.03999523 -0.0415858 -1.3135257  0.1877295\nMacey     2.2334606  1.04176620 -1.8643620 -0.7432135  0.9772701\nWarners   2.1683964 -1.80320025  0.8510173 -0.2845996 -0.1513946\nZsivoczky 0.9251322  1.16865180 -1.4774803  0.8075947  0.8729726\n\n# Calidad de representación\nhead(res$ind$cos2)\n\n              Dim.1        Dim.2        Dim.3       Dim.4       Dim.5\nSebrle    0.6954102 7.954314e-02 0.0035849052 0.160665653 0.006058846\nClay      0.7112052 3.243204e-02 0.0024742661 0.103335239 0.049846023\nKarpov    0.8517553 6.383365e-05 0.0000690118 0.068851025 0.001406366\nMacey     0.4230486 9.203950e-02 0.2947774222 0.046844751 0.080995884\nWarners   0.5299437 3.664716e-01 0.0816261239 0.009128951 0.002583291\nZsivoczky 0.1299979 2.074432e-01 0.3315677581 0.099063996 0.115752425\n\n# Contribuciones\nhead(res$ind$contrib)\n\n               Dim.1       Dim.2       Dim.3     Dim.4      Dim.5\nSebrle    12.1575058 2.619234357 0.145959136 8.6958838 0.50611259\nClay      11.4510904 0.983545343 0.092778749 5.1509536 3.83474272\nKarpov    15.9109806 0.002245949 0.003002311 3.9818030 0.12552619\nMacey      3.7185358 1.523786399 6.034288443 1.2747642 3.40171873\nWarners    3.5050382 4.565322740 1.257310032 0.1869266 0.08163758\nZsivoczky  0.6380034 1.917581489 3.789736079 1.5051840 2.71437829\n\n\n\n4.8.1 Gráfico de individuos\n\n# Sin mostrar las variables cualitativas\nplot(res, cex = 0.8, invisible = \"quali\",\n     title = \"Individuos - PCA Decathlon\")\n\n\n\n\n\n\n\n# Coloreando por competición (columna 13)\nplot(res, cex = 0.8, habillage = 13,\n     title = \"Individuos por tipo de competición\")\n\n\n\n\n\n\n\n\n\n\n4.8.2 Elipses de confianza por categoría\n\nplotellipses(res)\n\n\n\n\n\n\n\n\n\n\n4.8.3 Otras vistas y selección de individuos\n\n# Dimensiones 3 y 4\nplot(res, choix = \"ind\", cex = 0.8, habillage = 13,\n     title = \"Individuos (dim 3 y 4)\", axes = 3:4)\n\n\n\n\n\n\n\n# Seleccionar individuos bien representados\nplot(res, cex = 0.8, habillage = 13, select = \"cos2 0.7\")\n\n\n\n\n\n\n\n# Seleccionar individuos con mayor contribución\nplot(res, cex = 0.8, habillage = 13, select = \"contrib 5\")\n\n\n\n\n\n\n\n# Seleccionar individuos específicos (por nombre)\nplot(res, cex = 0.8, habillage = 13,\n     select = c(\"Clay\", \"Karpov\"))\n\n\n\n\n\n\n\n\n\n\n4.8.4 Selección de variables importantes\n\nplot(res, choix = \"var\", select = \"contrib 5\")\n\n\n\n\n\n\n\n\n\n\n4.8.5 Gráfico con varios argumentos\n\nplot(\n  res,\n  cex        = 0.8,\n  habillage  = 13,\n  select     = \"cos2 0.7\",\n  title      = \"Decathlon\",\n  cex.main   = 1.1,\n  cex.axis   = 0.9,\n  shadow     = TRUE,\n  auto       = \"y\"\n)"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#importar-datos-de-orange",
    "href": "labs_epg/lab07_epg.html#importar-datos-de-orange",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.1 Importar datos de orange",
    "text": "5.1 Importar datos de orange\n\narchivo_orange &lt;- file.path(ruta_datos, \"orange.csv\")\n\norange &lt;- read.table(\n  archivo_orange,\n  header      = TRUE,\n  sep         = \";\",\n  dec         = \".\",\n  row.names   = 1,\n  check.names = FALSE\n)\n\nsummary(orange)\n\n Odour intensity Odour typicality   Pulpiness     Intensity of taste\n Min.   :2.760   Min.   :2.530    Min.   :1.660   Min.   :3.120     \n 1st Qu.:2.775   1st Qu.:2.625    1st Qu.:1.722   1st Qu.:3.265     \n Median :2.825   Median :2.775    Median :2.625   Median :3.410     \n Mean   :2.907   Mean   :2.762    Mean   :2.710   Mean   :3.362     \n 3rd Qu.:3.010   3rd Qu.:2.865    3rd Qu.:3.603   3rd Qu.:3.458     \n Max.   :3.200   Max.   :3.020    Max.   :4.000   Max.   :3.540     \n    Acidity        Bitterness      Sweetness        Glucose     \n Min.   :2.330   Min.   :1.760   Min.   :2.600   Min.   :17.33  \n 1st Qu.:2.453   1st Qu.:1.998   1st Qu.:2.825   1st Qu.:22.94  \n Median :2.800   Median :2.320   Median :3.110   Median :24.48  \n Mean   :2.802   Mean   :2.328   Mean   :3.057   Mean   :24.76  \n 3rd Qu.:3.125   3rd Qu.:2.612   3rd Qu.:3.335   3rd Qu.:26.70  \n Max.   :3.310   Max.   :2.970   Max.   :3.380   Max.   :32.42  \n    Fructose       Saccharose    Sweetening power       pH       \n Min.   :20.00   Min.   :22.92   Min.   : 82.55   Min.   :3.590  \n 1st Qu.:25.40   1st Qu.:37.07   1st Qu.: 90.14   1st Qu.:3.620  \n Median :26.50   Median :41.55   Median : 92.79   Median :3.750  \n Mean   :27.06   Mean   :40.06   Mean   : 92.80   Mean   :3.738  \n 3rd Qu.:28.95   3rd Qu.:45.39   3rd Qu.: 96.10   3rd Qu.:3.842  \n Max.   :34.54   Max.   :52.12   Max.   :102.22   Max.   :3.890  \n  Citric acid       Vitamin C     Way of preserving     Origin         \n Min.   :0.6700   Min.   :27.00   Length:6           Length:6          \n 1st Qu.:0.6950   1st Qu.:33.67   Class :character   Class :character  \n Median :0.7250   Median :36.80   Mode  :character   Mode  :character  \n Mean   :0.7667   Mean   :36.04                                        \n 3rd Qu.:0.8150   3rd Qu.:38.88                                        \n Max.   :0.9500   Max.   :43.44"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#pca-con-variables-activas-1-a-14",
    "href": "labs_epg/lab07_epg.html#pca-con-variables-activas-1-a-14",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.2 PCA con variables activas (1 a 14)",
    "text": "5.2 PCA con variables activas (1 a 14)\n\nres &lt;- PCA(orange[, 1:14], ncp = 3)\nsummary(res)\n\n\nCall:\nPCA(X = orange[, 1:14], ncp = 3) \n\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3   Dim.4   Dim.5\nVariance               8.065   2.583   1.461   1.011   0.880\n% of var.             57.607  18.450  10.438   7.220   6.285\nCumulative % of var.  57.607  76.057  86.496  93.715 100.000\n\nIndividuals\n                       Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nPampryl amb.       |  3.700 | -3.090 19.727  0.697 | -1.026  6.797  0.077 |\nTropicana amb.     |  3.885 |  2.358 11.486  0.368 | -2.825 51.491  0.529 |\nFruvita fr.        |  3.536 |  2.688 14.928  0.578 |  1.385 12.373  0.153 |\nJoker amb.         |  4.300 | -3.895 31.359  0.821 | -0.127  0.104  0.001 |\nTropicana fr.      |  3.800 |  3.092 19.757  0.662 |  0.533  1.830  0.020 |\nPampryl fr.        |  3.128 | -1.152  2.743  0.136 |  2.061 27.405  0.434 |\n                    Dim.3    ctr   cos2  \nPampryl amb.        0.022  0.006  0.000 |\nTropicana amb.     -1.076 13.205  0.077 |\nFruvita fr.        -0.076  0.067  0.000 |\nJoker amb.          1.184 15.976  0.076 |\nTropicana fr.       1.734 34.298  0.208 |\nPampryl fr.        -1.788 36.449  0.327 |\n\nVariables (the 10 first)\n                      Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nOdour intensity    |  0.352  1.533  0.124 |  0.561 12.192  0.315 |  0.168\nOdour typicality   |  0.938 10.898  0.879 |  0.205  1.626  0.042 |  0.185\nPulpiness          |  0.666  5.498  0.443 |  0.742 21.330  0.551 |  0.010\nIntensity of taste | -0.554  3.800  0.306 |  0.453  7.954  0.205 | -0.564\nAcidity            | -0.878  9.560  0.771 |  0.160  0.995  0.026 | -0.407\nBitterness         | -0.897  9.978  0.805 | -0.084  0.274  0.007 | -0.183\nSweetness          |  0.958 11.384  0.918 |  0.011  0.005  0.000 |  0.068\nGlucose            | -0.786  7.652  0.617 |  0.493  9.424  0.243 |  0.280\nFructose           | -0.781  7.554  0.609 |  0.489  9.251  0.239 |  0.288\nSaccharose         |  0.891  9.841  0.794 |  0.133  0.689  0.018 | -0.207\n                      ctr   cos2  \nOdour intensity     1.936  0.028 |\nOdour typicality    2.336  0.034 |\nPulpiness           0.006  0.000 |\nIntensity of taste 21.785  0.318 |\nAcidity            11.316  0.165 |\nBitterness          2.301  0.034 |\nSweetness           0.315  0.005 |\nGlucose             5.376  0.079 |\nFructose            5.683  0.083 |\nSaccharose          2.925  0.043 |\n\nprint(res)\n\n**Results for the Principal Component Analysis (PCA)**\nThe analysis was performed on 6 individuals, described by 14 variables\n*The results are available in the following objects:\n\n   name               description                          \n1  \"$eig\"             \"eigenvalues\"                        \n2  \"$var\"             \"results for the variables\"          \n3  \"$var$coord\"       \"coord. for the variables\"           \n4  \"$var$cor\"         \"correlations variables - dimensions\"\n5  \"$var$cos2\"        \"cos2 for the variables\"             \n6  \"$var$contrib\"     \"contributions of the variables\"     \n7  \"$ind\"             \"results for the individuals\"        \n8  \"$ind$coord\"       \"coord. for the individuals\"         \n9  \"$ind$cos2\"        \"cos2 for the individuals\"           \n10 \"$ind$contrib\"     \"contributions of the individuals\"   \n11 \"$call\"            \"summary statistics\"                 \n12 \"$call$centre\"     \"mean of the variables\"              \n13 \"$call$ecart.type\" \"standard error of the variables\"    \n14 \"$call$row.w\"      \"weights for the individuals\"        \n15 \"$call$col.w\"      \"weights for the variables\""
  },
  {
    "objectID": "labs_epg/lab07_epg.html#pca-con-variables-suplementarias-1",
    "href": "labs_epg/lab07_epg.html#pca-con-variables-suplementarias-1",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.3 PCA con variables suplementarias",
    "text": "5.3 PCA con variables suplementarias\nConsideramos ahora que las columnas 15 y 16 son cualitativas suplementarias (por ejemplo, origen del jugo).\n\nres2 &lt;- PCA(orange, quali.sup = 15:16)\nsummary(res2, nbelements = Inf)\n\n\nCall:\nPCA(X = orange, quali.sup = 15:16) \n\n\nEigenvalues\n                       Dim.1   Dim.2   Dim.3   Dim.4   Dim.5\nVariance               8.065   2.583   1.461   1.011   0.880\n% of var.             57.607  18.450  10.438   7.220   6.285\nCumulative % of var.  57.607  76.057  86.496  93.715 100.000\n\nIndividuals\n                       Dist    Dim.1    ctr   cos2    Dim.2    ctr   cos2  \nPampryl amb.       |  3.700 | -3.090 19.727  0.697 | -1.026  6.797  0.077 |\nTropicana amb.     |  3.885 |  2.358 11.486  0.368 | -2.825 51.491  0.529 |\nFruvita fr.        |  3.536 |  2.688 14.928  0.578 |  1.385 12.373  0.153 |\nJoker amb.         |  4.300 | -3.895 31.359  0.821 | -0.127  0.104  0.001 |\nTropicana fr.      |  3.800 |  3.092 19.757  0.662 |  0.533  1.830  0.020 |\nPampryl fr.        |  3.128 | -1.152  2.743  0.136 |  2.061 27.405  0.434 |\n                    Dim.3    ctr   cos2  \nPampryl amb.        0.022  0.006  0.000 |\nTropicana amb.     -1.076 13.205  0.077 |\nFruvita fr.        -0.076  0.067  0.000 |\nJoker amb.          1.184 15.976  0.076 |\nTropicana fr.       1.734 34.298  0.208 |\nPampryl fr.        -1.788 36.449  0.327 |\n\nVariables\n                      Dim.1    ctr   cos2    Dim.2    ctr   cos2    Dim.3\nOdour intensity    |  0.352  1.533  0.124 |  0.561 12.192  0.315 |  0.168\nOdour typicality   |  0.938 10.898  0.879 |  0.205  1.626  0.042 |  0.185\nPulpiness          |  0.666  5.498  0.443 |  0.742 21.330  0.551 |  0.010\nIntensity of taste | -0.554  3.800  0.306 |  0.453  7.954  0.205 | -0.564\nAcidity            | -0.878  9.560  0.771 |  0.160  0.995  0.026 | -0.407\nBitterness         | -0.897  9.978  0.805 | -0.084  0.274  0.007 | -0.183\nSweetness          |  0.958 11.384  0.918 |  0.011  0.005  0.000 |  0.068\nGlucose            | -0.786  7.652  0.617 |  0.493  9.424  0.243 |  0.280\nFructose           | -0.781  7.554  0.609 |  0.489  9.251  0.239 |  0.288\nSaccharose         |  0.891  9.841  0.794 |  0.133  0.689  0.018 | -0.207\nSweetening power   |  0.194  0.467  0.038 |  0.915 32.396  0.837 |  0.107\npH                 |  0.964 11.525  0.930 | -0.156  0.941  0.024 | -0.107\nCitric acid        | -0.906 10.173  0.820 | -0.018  0.012  0.000 |  0.389\nVitamin C          | -0.105  0.136  0.011 | -0.274  2.910  0.075 |  0.706\n                      ctr   cos2  \nOdour intensity     1.936  0.028 |\nOdour typicality    2.336  0.034 |\nPulpiness           0.006  0.000 |\nIntensity of taste 21.785  0.318 |\nAcidity            11.316  0.165 |\nBitterness          2.301  0.034 |\nSweetness           0.315  0.005 |\nGlucose             5.376  0.079 |\nFructose            5.683  0.083 |\nSaccharose          2.925  0.043 |\nSweetening power    0.778  0.011 |\npH                  0.776  0.011 |\nCitric acid        10.368  0.152 |\nVitamin C          34.099  0.498 |\n\nSupplementary categories\n                       Dist    Dim.1   cos2 v.test    Dim.2   cos2 v.test  \nAmbient            |  2.040 | -1.543  0.572 -1.215 | -1.326  0.423 -1.845 |\nFresh              |  2.040 |  1.543  0.572  1.215 |  1.326  0.423  1.845 |\nFlorida            |  2.741 |  2.712  0.979  2.136 | -0.303  0.012 -0.421 |\nOther              |  2.741 | -2.712  0.979 -2.136 |  0.303  0.012  0.421 |\n                    Dim.3   cos2 v.test  \nAmbient             0.043  0.000  0.080 |\nFresh              -0.043  0.000 -0.080 |\nFlorida             0.194  0.005  0.359 |\nOther              -0.194  0.005 -0.359 |"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#valores-propios-y-varianza-explicada-1",
    "href": "labs_epg/lab07_epg.html#valores-propios-y-varianza-explicada-1",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.4 Valores propios y varianza explicada",
    "text": "5.4 Valores propios y varianza explicada\n\neigenvalues &lt;- res$eig\neigenvalues[, 1:3]\n\n       eigenvalue percentage of variance cumulative percentage of variance\ncomp 1  8.0649505              57.606789                          57.60679\ncomp 2  2.5830341              18.450244                          76.05703\ncomp 3  1.4613887              10.438490                          86.49552\ncomp 4  1.0107601               7.219715                          93.71524\ncomp 5  0.8798667               6.284762                         100.00000"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#test-de-bartlett-y-kmo-para-orange",
    "href": "labs_epg/lab07_epg.html#test-de-bartlett-y-kmo-para-orange",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.5 Test de Bartlett y KMO para orange",
    "text": "5.5 Test de Bartlett y KMO para orange\n\nbartlett.test(orange[, 1:14])\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  orange[, 1:14]\nBartlett's K-squared = 210.49, df = 13, p-value &lt; 2.2e-16\n\nKMO(orange[, 1:14])\n\nError in solve.default(r) : \n  sistema es computacionalmente singular: número de condición recíproco = 1.37813e-18\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = orange[, 1:14])\nOverall MSA =  0.5\nMSA for each item = \n   Odour intensity   Odour typicality          Pulpiness Intensity of taste \n               0.5                0.5                0.5                0.5 \n           Acidity         Bitterness          Sweetness            Glucose \n               0.5                0.5                0.5                0.5 \n          Fructose         Saccharose   Sweetening power                 pH \n               0.5                0.5                0.5                0.5 \n       Citric acid          Vitamin C \n               0.5                0.5"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#descripción-de-las-dimensiones-1",
    "href": "labs_epg/lab07_epg.html#descripción-de-las-dimensiones-1",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.6 Descripción de las dimensiones",
    "text": "5.6 Descripción de las dimensiones\n\ndimdesc(res)\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation     p.value\npH                 0.9641128 0.001908728\nSweetness          0.9581672 0.002588371\nOdour typicality   0.9375068 0.005736073\nSaccharose         0.8908878 0.017208699\nAcidity           -0.8780844 0.021389085\nBitterness        -0.8970717 0.015346133\nCitric acid       -0.9057713 0.012900241\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation   p.value\nSweetening power   0.9147625 0.0105885\n\n$Dim.3\n\ndimdesc(res, axes = c(1, 2))\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation     p.value\npH                 0.9641128 0.001908728\nSweetness          0.9581672 0.002588371\nOdour typicality   0.9375068 0.005736073\nSaccharose         0.8908878 0.017208699\nAcidity           -0.8780844 0.021389085\nBitterness        -0.8970717 0.015346133\nCitric acid       -0.9057713 0.012900241\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation   p.value\nSweetening power   0.9147625 0.0105885\n\ndimdesc(res, proba = 0.2)\n\n$Dim.1\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation     p.value\npH                 0.9641128 0.001908728\nSweetness          0.9581672 0.002588371\nOdour typicality   0.9375068 0.005736073\nSaccharose         0.8908878 0.017208699\nPulpiness          0.6659126 0.148777121\nFructose          -0.7805085 0.066977593\nGlucose           -0.7856011 0.064022682\nAcidity           -0.8780844 0.021389085\nBitterness        -0.8970717 0.015346133\nCitric acid       -0.9057713 0.012900241\n\n$Dim.2\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n                 correlation    p.value\nSweetening power   0.9147625 0.01058850\nPulpiness          0.7422675 0.09107899\n\n$Dim.3\n\nLink between the variable and the continuous variables (R-square)\n=================================================================================\n          correlation   p.value\nVitamin C   0.7059171 0.1170103"
  },
  {
    "objectID": "labs_epg/lab07_epg.html#gráficos-de-individuos-y-variables",
    "href": "labs_epg/lab07_epg.html#gráficos-de-individuos-y-variables",
    "title": "Capitulo_7_Analisis_Factorial",
    "section": "5.7 Gráficos de individuos y variables",
    "text": "5.7 Gráficos de individuos y variables\n\n5.7.1 Individuos\n\n# Individuos sin variables cualitativas\nplot(res, cex = 0.8, invisible = \"quali\",\n     title = \"Individuos - PCA Orange\")\n\n\n\n\n\n\n\n# Coloreados según variable de origen (si existe en el dataset)\nplot(res2, cex = 0.8, habillage = \"Origin\")\n\n\n\n\n\n\n\n\n\n\n5.7.2 Elipses de confianza\n\nplotellipses(res)\n\nNULL\n\n\n\n\n5.7.3 Selección de individuos y variables\n\n# Individuos bien representados\nplot(res, cex = 0.8, habillage = 13, select = \"cos2 0.7\")\n\n\n\n\n\n\n\n# Individuos con mayor contribución\nplot(res, cex = 0.8, habillage = 13, select = \"contrib 5\")\n\n\n\n\n\n\n\n# Individuos específicos (ejemplo: marcas específicas)\nplot(res, cex = 0.8, habillage = 13,\n     select = c(\"Fruvita fr.\", \"Tropicana fr.\"))\n\n\n\n\n\n\n\n# Variables que más contribuyen\nplot(res, choix = \"var\", select = \"contrib 5\")\n\n\n\n\n\n\n\n\n\n\n5.7.4 Gráfico combinado (orange)\n\nplot(\n  res,\n  cex        = 0.8,\n  habillage  = 13,\n  select     = \"cos2 0.7\",\n  title      = \"Orange juices PCA\",\n  cex.main   = 1.1,\n  cex.axis   = 0.9,\n  shadow     = TRUE,\n  auto       = \"y\"\n)"
  },
  {
    "objectID": "labs_epg/lab05_epg.html",
    "href": "labs_epg/lab05_epg.html",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos\nDescargar PDF de contenidos teóricos\nEl documento “Capitulo 5 Logit y otros analisis” desarrolla, entre otros, los siguientes puntos:\n\nComplementos a la regresión múltiple lineal.\n\nModelo Logit:\n\nFormulación del modelo logístico para variables binarias.\n\nFunción logit e inversa logística.\n\nInterpretación de los coeficientes como odds ratios (OR).\n\nValidación mediante matrices de confusión y partición de datos (train/test).\n\n\nAnálisis de la Varianza (ANOVA):\n\nFactores y comparación de medias.\n\nUso del test de Tukey para comparar pares de medias.\n\n\nMANOVA:\n\nAnálisis de varianza con múltiples variables respuesta.\n\nSupuestos de normalidad y homogeneidad de varianzas.\n\n\nEn este laboratorio llevamos esa teoría a la práctica con distintos ejemplos en R."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#carga-de-librerías",
    "href": "labs_epg/lab05_epg.html#carga-de-librerías",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "2.1 Carga de librerías",
    "text": "2.1 Carga de librerías\nEn este capítulo usamos varias librerías especializadas:\n\n#install.packages(c(\n#  \"openxlsx\",\n#  \"DAAG\",\n#  \"ROCR\",\n#  \"ROCit\",\n#  \"caret\",\n#  \"pROC\",\n#  \"plotROC\",\n#  \"lattice\",\n#  \"ggpubr\",\n#  \"MVN\",\n#  \"biotools\",\n#  \"car\",\n#  \"lsr\",\n#  \"ggplot2\"\n#))\nlibrary(openxlsx)\nlibrary(DAAG)     # contiene datasets como frogs, sugar, appletaste, UCBAdmissions\nlibrary(ROCR)     # curvas ROC y AUC\nlibrary(ROCit)    # otra forma de construir ROC\nlibrary(caret)    # matriz de confusión y métricas de clasificación\nlibrary(pROC)     # ROC con intervalos de confianza\nlibrary(plotROC)  # ROC con ggplot2\nlibrary(lattice)  # gráficos tipo trellis (para sugar, appletaste)\nlibrary(ggpubr)   # boxplots lindos para datos de ratas\nlibrary(MVN)      # pruebas de normalidad multivariante\nlibrary(biotools) # Box's M\nlibrary(car)      # Levene (homogeneidad de varianzas)\nlibrary(lsr)      # etaSquared (tamaño de efecto)\nlibrary(ggplot2)"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#ruta-de-trabajo-si-la-necesitas",
    "href": "labs_epg/lab05_epg.html#ruta-de-trabajo-si-la-necesitas",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "2.2 Ruta de trabajo (si la necesitas)",
    "text": "2.2 Ruta de trabajo (si la necesitas)\nEn este lab la mayoría de los datos vienen de paquetes de R, no de archivos externos.\nPero mantenemos la misma lógica de ruta de tu proyecto por consistencia:\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\n# Puedes revisar qué archivos tienes ahí (opcional)\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\""
  },
  {
    "objectID": "labs_epg/lab05_epg.html#exploración-inicial-de-los-datos",
    "href": "labs_epg/lab05_epg.html#exploración-inicial-de-los-datos",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.1 Exploración inicial de los datos",
    "text": "3.1 Exploración inicial de los datos\n\ndata(frogs)  # carga el dataset desde DAAG\nstr(frogs)\n\n'data.frame':   212 obs. of  10 variables:\n $ pres.abs : num  1 1 1 1 1 1 1 1 1 1 ...\n $ northing : num  115 110 112 109 109 106 105 84 88 91 ...\n $ easting  : num  1047 1042 1040 1033 1032 ...\n $ altitude : num  1500 1520 1540 1590 1590 1600 1600 1560 1560 1560 ...\n $ distance : num  500 250 250 250 250 500 250 750 250 250 ...\n $ NoOfPools: num  232 66 32 9 67 12 30 13 4 14 ...\n $ NoOfSites: num  3 5 5 5 5 4 3 2 3 4 ...\n $ avrain   : num  155 158 160 165 165 ...\n $ meanmin  : num  3.57 3.47 3.4 3.2 3.2 ...\n $ meanmax  : num  14 13.8 13.6 13.2 13.2 ...\n\nhead(frogs)\n\n  pres.abs northing easting altitude distance NoOfPools NoOfSites   avrain\n2        1      115    1047     1500      500       232         3 155.0000\n3        1      110    1042     1520      250        66         5 157.6667\n4        1      112    1040     1540      250        32         5 159.6667\n5        1      109    1033     1590      250         9         5 165.0000\n6        1      109    1032     1590      250        67         5 165.0000\n7        1      106    1018     1600      500        12         4 167.3333\n   meanmin  meanmax\n2 3.566667 14.00000\n3 3.466667 13.80000\n4 3.400000 13.60000\n5 3.200000 13.16667\n6 3.200000 13.16667\n7 3.133333 13.06667"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#mapa-de-puntos-con-presenciaausencia",
    "href": "labs_epg/lab05_epg.html#mapa-de-puntos-con-presenciaausencia",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.2 Mapa de puntos con presencia/ausencia",
    "text": "3.2 Mapa de puntos con presencia/ausencia\n\nplot(\n  northing ~ easting,\n  data = frogs,\n  pch  = c(1, 16)[frogs$pres.abs + 1],\n  xlab = \"Metros este de puntos de referencia\",\n  ylab = \"Metros norte\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nCírculos y puntos sólidos representan sitios con ausencia/presencia.\n\nEsto ayuda a ver si hay patrones espaciales (por ejemplo, la especie se concentra en ciertas zonas)."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#relación-entre-variables-explicativas",
    "href": "labs_epg/lab05_epg.html#relación-entre-variables-explicativas",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.3 Relación entre variables explicativas",
    "text": "3.3 Relación entre variables explicativas\n\npairs(frogs[, c(5:10, 4)],\n      oma = c(2, 2, 2, 2),\n      cex = 0.5)\n\n\n\n\n\n\n\n\nAquí exploramos cómo se relacionan entre sí variables ambientales como distance, NoOfPools, NoOfSites, avrain, altitude, meanmin, meanmax."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#densidades-y-posibles-transformaciones",
    "href": "labs_epg/lab05_epg.html#densidades-y-posibles-transformaciones",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.4 Densidades y posibles transformaciones",
    "text": "3.4 Densidades y posibles transformaciones\nLa idea es ver la distribución de algunas variables clave y pensar en transformaciones que las hagan más “amigables” para el modelo (por ejemplo, simétricas o menos sesgadas).\n\npar(mfrow = c(1, 3))\nfor(nam in c(\"distance\", \"NoOfPools\", \"NoOfSites\")){\n  y &lt;- frogs[, nam]\n  plot(density(y), main = \"\", xlab = nam)\n}\n\n\n\n\n\n\n\npar(mfrow = c(1, 3))\nfor(nam in c(\"distance\", \"NoOfPools\", \"NoOfSites\")){\n  y &lt;- frogs[, nam]\n  plot(density(sqrt(y)), main = \"\", xlab = paste(\"sqrt(\", nam, \")\"))\n}\n\n\n\n\n\n\n\npar(mfrow = c(1, 3))\nfor(nam in c(\"distance\", \"NoOfPools\", \"NoOfSites\")){\n  y &lt;- frogs[, nam]\n  plot(density(log(y)), main = \"\", xlab = paste(\"log(\", nam, \")\"))\n}\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nTip\n\n\n\nEn el PDF se comenta que para algunas variables conviene usar:\n\nlog(distance)\n\nlog(NoOfPools)\n\nTransformaciones sobre NoOfSites y combinaciones de temperaturas (meanmax + meanmin, meanmax - meanmin)."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#correlaciones-entre-variables-climáticas",
    "href": "labs_epg/lab05_epg.html#correlaciones-entre-variables-climáticas",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.5 Correlaciones entre variables climáticas",
    "text": "3.5 Correlaciones entre variables climáticas\n\nwith(frogs, cor(altitude, meanmax))\n\n[1] -0.996557\n\nwith(frogs, cor(cbind(\n  altitude,\n  \"meanmax+meanmin\" = meanmin + meanmax,\n  \"meanmax-meanmin\" = meanmin - meanmax\n)))\n\n                  altitude meanmax+meanmin meanmax-meanmin\naltitude         1.0000000      -0.9933266       0.9094551\nmeanmax+meanmin -0.9933266       1.0000000      -0.8730120\nmeanmax-meanmin  0.9094551      -0.8730120       1.0000000\n\n\nY un gráfico de pares con transformaciones:\n\nwith(frogs,\n     pairs(\n       cbind(\n         log(distance), log(NoOfPools), NoOfSites,\n         avrain, altitude, meanmax + meanmin, meanmax - meanmin\n       ),\n       col    = \"gray\",\n       labels = c(\"log(distance)\", \"log(NoOfPools)\", \"NoOfSites\",\n                  \"Av. rainfall\", \"altitude\",\n                  \"meanmax+meanmin\", \"meanmax-meanmin\"),\n       panel  = panel.smooth\n     )\n)"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#modelo-logit-especificación-y-ajuste",
    "href": "labs_epg/lab05_epg.html#modelo-logit-especificación-y-ajuste",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.6 Modelo logit: especificación y ajuste",
    "text": "3.6 Modelo logit: especificación y ajuste\nRecordemos que un modelo logit asume:\n\\[\n\\Pr(\\text{pres.abs} = 1 \\mid X) = \\frac{1}{1 + e^{-(X\\beta)}},\n\\]\ny que el logit de la probabilidad es lineal en las X:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right) = X\\beta.\n\\]\n\n3.6.1 Modelo logit inicial (frogs.glm0)\n\nfrogs.glm0 &lt;- glm(\n  pres.abs ~ log(distance) + log(NoOfPools) + NoOfSites +\n    avrain + I(meanmin + meanmax) + I(meanmin - meanmax),\n  family = binomial,\n  data   = frogs\n)\n\nsummary(frogs.glm0)\n\n\nCall:\nglm(formula = pres.abs ~ log(distance) + log(NoOfPools) + NoOfSites + \n    avrain + I(meanmin + meanmax) + I(meanmin - meanmax), family = binomial, \n    data = frogs)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          18.2688999 16.1381912   1.132  0.25762    \nlog(distance)        -0.7583198  0.2558117  -2.964  0.00303 ** \nlog(NoOfPools)        0.5708953  0.2153335   2.651  0.00802 ** \nNoOfSites            -0.0036201  0.1061469  -0.034  0.97279    \navrain                0.0007003  0.0411710   0.017  0.98643    \nI(meanmin + meanmax)  1.4958055  0.3153152   4.744  2.1e-06 ***\nI(meanmin - meanmax)  3.8582668  1.2783921   3.018  0.00254 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 279.99  on 211  degrees of freedom\nResidual deviance: 197.65  on 205  degrees of freedom\nAIC: 211.65\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n3.6.2 Modelo logit reducido (frogs.glm1)\nQuitamos algunas variables para ver si un modelo más simple puede funcionar bien:\n\nfrogs.glm1 &lt;- glm(\n  pres.abs ~ log(distance) + log(NoOfPools) +\n    I(meanmin + meanmax) + I(meanmin - meanmax),\n  family = binomial,\n  data   = frogs\n)\n\nsummary(frogs.glm1)\n\n\nCall:\nglm(formula = pres.abs ~ log(distance) + log(NoOfPools) + I(meanmin + \n    meanmax) + I(meanmin - meanmax), family = binomial, data = frogs)\n\nCoefficients:\n                     Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           18.5268     5.2673   3.517 0.000436 ***\nlog(distance)         -0.7547     0.2261  -3.338 0.000844 ***\nlog(NoOfPools)         0.5707     0.2152   2.652 0.007999 ** \nI(meanmin + meanmax)   1.4985     0.3088   4.853 1.22e-06 ***\nI(meanmin - meanmax)   3.8806     0.9002   4.311 1.63e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 279.99  on 211  degrees of freedom\nResidual deviance: 197.66  on 207  degrees of freedom\nAIC: 207.66\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSigno del coeficiente: indica si la variable aumenta o reduce la probabilidad de presencia.\n\nMagnitud: se interpreta mejor usando la exponencial (odds ratios).\n\np-value: indica si la variable aporta significativamente al modelo logit."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#tipos-de-predicción",
    "href": "labs_epg/lab05_epg.html#tipos-de-predicción",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.7 Tipos de predicción",
    "text": "3.7 Tipos de predicción\n\n# Probabilidades ajustadas\nhead(fitted(frogs.glm1))\n\n        2         3         4         5         6         7 \n0.9416691 0.9259228 0.9029415 0.8119619 0.9314070 0.7278038 \n\n# Probabilidades con predict(type = \"response\")\nhead(predict(frogs.glm1, type = \"response\"))\n\n        2         3         4         5         6         7 \n0.9416691 0.9259228 0.9029415 0.8119619 0.9314070 0.7278038 \n\n# Escala lineal del predictor (logit)\nhead(predict(frogs.glm1, type = \"link\"))\n\n        2         3         4         5         6         7 \n2.7815212 2.5256832 2.2303441 1.4628085 2.6085055 0.9835086 \n\n# Valores ajustados en la escala lineal con errores estándar\npred_link &lt;- predict(frogs.glm1, type = \"link\", se.fit = TRUE)\nstr(pred_link)\n\nList of 3\n $ fit           : Named num [1:212] 2.78 2.53 2.23 1.46 2.61 ...\n  ..- attr(*, \"names\")= chr [1:212] \"2\" \"3\" \"4\" \"5\" ...\n $ se.fit        : Named num [1:212] 0.686 0.485 0.438 0.481 0.529 ...\n  ..- attr(*, \"names\")= chr [1:212] \"2\" \"3\" \"4\" \"5\" ...\n $ residual.scale: num 1"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#aporte-de-cada-variable-termplot",
    "href": "labs_epg/lab05_epg.html#aporte-de-cada-variable-termplot",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.8 Aporte de cada variable: termplot",
    "text": "3.8 Aporte de cada variable: termplot\n\npar(mfrow = c(1, 4), pty = \"s\")\n\nfrogs$maxminSum  &lt;- with(frogs, meanmax + meanmin)\nfrogs$maxminDiff &lt;- with(frogs, meanmax - meanmin)\n\nfrogs.glm &lt;- glm(\n  pres.abs ~ log(distance) + log(NoOfPools) +\n    maxminSum + maxminDiff,\n  family = binomial,\n  data   = frogs\n)\n\ntermplot(frogs.glm)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nNota\n\n\n\nCada gráfico muestra cómo se relaciona la respuesta en escala logit con una variable, manteniendo las demás fijas. Es un análogo al “efecto parcial” de cada regresor."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#validación-cruzada-del-modelo-logit",
    "href": "labs_epg/lab05_epg.html#validación-cruzada-del-modelo-logit",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.9 Validación cruzada del modelo logit",
    "text": "3.9 Validación cruzada del modelo logit\n\nCVbinary(frogs.glm0)\n\n\nFold:  3 4 5 2 9 10 1 7 6 8\nInternal estimate of accuracy = 0.778\nCross-validation estimate of accuracy = 0.778\n\nCVbinary(frogs.glm)\n\n\nFold:  7 2 10 6 5 9 3 8 4 1\nInternal estimate of accuracy = 0.778\nCross-validation estimate of accuracy = 0.778\n\n\nEstas funciones entregan estimaciones de error de clasificación usando validación cruzada, lo que ayuda a medir la capacidad predictiva del modelo."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#odds-ratios-or-e-intervalos-de-confianza",
    "href": "labs_epg/lab05_epg.html#odds-ratios-or-e-intervalos-de-confianza",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.10 Odds Ratios (OR) e intervalos de confianza",
    "text": "3.10 Odds Ratios (OR) e intervalos de confianza\n\nexp(coef(frogs.glm))\n\n   (Intercept)  log(distance) log(NoOfPools)      maxminSum     maxminDiff \n  1.112001e+08   4.701711e-01   1.769536e+00   4.474929e+00   2.063873e-02 \n\nexp(cbind(OR = coef(frogs.glm),\n          confint(frogs.glm)))\n\n                         OR        2.5 %       97.5 %\n(Intercept)    1.112001e+08 5.328174e+03 5.519123e+12\nlog(distance)  4.701711e-01 2.964833e-01 7.226771e-01\nlog(NoOfPools) 1.769536e+00 1.176801e+00 2.747499e+00\nmaxminSum      4.474929e+00 2.514265e+00 8.487274e+00\nmaxminDiff     2.063873e-02 3.247202e-03 1.122666e-01\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nUn OR &gt; 1 indica que una mayor X está asociada a mayor riesgo de presencia (o ser clasificado como 1).\n\nUn OR &lt; 1 indica un efecto protector (menor probabilidad de presencia)."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#matriz-de-confusión-y-precisión",
    "href": "labs_epg/lab05_epg.html#matriz-de-confusión-y-precisión",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.11 Matriz de confusión y precisión",
    "text": "3.11 Matriz de confusión y precisión\nPrimero calculamos las probabilidades y luego definimos una regla de corte (threshold) para clasificar 0/1:\n\nfrogs$rankP &lt;- predict(frogs.glm, newdata = frogs, type = \"response\")\nplot(frogs$pres.abs, frogs$rankP,\n     xlab = \"Presencia real (0/1)\", ylab = \"Probabilidad estimada\")\n\n\n\n\n\n\n\nfitted.results &lt;- predict(frogs.glm, newdata = frogs, type = \"response\")\nfitted.results &lt;- ifelse(fitted.results &gt; 0.399779, 1, 0)\n\nmisClasificError &lt;- mean(fitted.results != frogs$pres.abs)\nprint(paste(\"Accuracy\", 1 - misClasificError))\n\n[1] \"Accuracy 0.787735849056604\"\n\nmatrizConfusion &lt;- table(Real = frogs$pres.abs,\n                         Predicho = fitted.results)\nmatrizConfusion\n\n    Predicho\nReal   0   1\n   0 104  29\n   1  16  63\n\n\nUsando caret::confusionMatrix:\n\nCM_logit &lt;- confusionMatrix(\n  as.factor(fitted.results),\n  as.factor(frogs$pres.abs)\n)\nCM_logit\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 104  16\n         1  29  63\n                                          \n               Accuracy : 0.7877          \n                 95% CI : (0.7265, 0.8408)\n    No Information Rate : 0.6274          \n    P-Value [Acc &gt; NIR] : 3.685e-07       \n                                          \n                  Kappa : 0.5607          \n                                          \n Mcnemar's Test P-Value : 0.07364         \n                                          \n            Sensitivity : 0.7820          \n            Specificity : 0.7975          \n         Pos Pred Value : 0.8667          \n         Neg Pred Value : 0.6848          \n             Prevalence : 0.6274          \n         Detection Rate : 0.4906          \n   Detection Prevalence : 0.5660          \n      Balanced Accuracy : 0.7897          \n                                          \n       'Positive' Class : 0"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#curva-roc-y-auc-con-rocr",
    "href": "labs_epg/lab05_epg.html#curva-roc-y-auc-con-rocr",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "3.12 Curva ROC y AUC con ROCR",
    "text": "3.12 Curva ROC y AUC con ROCR\n\np  &lt;- predict(frogs.glm, newdata = frogs, type = \"response\")\npr &lt;- prediction(p, frogs$pres.abs)\nprf &lt;- performance(pr, measure = \"tpr\", x.measure = \"fpr\")\nplot(prf, main = \"Curva ROC (ROCR)\")\n\n\n\n\n\n\n\ncutoffs &lt;- data.frame(\n  cut = prf@alpha.values[[1]],\n  fpr = prf@x.values[[1]],\n  tpr = prf@y.values[[1]]\n)\n\nhead(subset(cutoffs, fpr &lt;= 0.2))\n\n        cut fpr        tpr\n1       Inf   0 0.00000000\n2 0.9416691   0 0.01265823\n3 0.9314070   0 0.02531646\n4 0.9259228   0 0.03797468\n5 0.9029415   0 0.05063291\n6 0.8648604   0 0.06329114\n\nauc &lt;- performance(pr, measure = \"auc\")\nauc &lt;- auc@y.values[[1]]\nauc\n\n[1] 0.8499096"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#caso-ucbadmissions-logit-con-categorías",
    "href": "labs_epg/lab05_epg.html#caso-ucbadmissions-logit-con-categorías",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "4.1 Caso UCBAdmissions (logit con categorías)",
    "text": "4.1 Caso UCBAdmissions (logit con categorías)\nUCBAdmissions es una tabla 2x2x6 que contiene:\n\nAdmisión (Admitted / Rejected)\n\nGénero (Male / Female)\n\nDepartamento (A–F)\n\n\nUCBAdmissions\n\n, , Dept = A\n\n          Gender\nAdmit      Male Female\n  Admitted  512     89\n  Rejected  313     19\n\n, , Dept = B\n\n          Gender\nAdmit      Male Female\n  Admitted  353     17\n  Rejected  207      8\n\n, , Dept = C\n\n          Gender\nAdmit      Male Female\n  Admitted  120    202\n  Rejected  205    391\n\n, , Dept = D\n\n          Gender\nAdmit      Male Female\n  Admitted  138    131\n  Rejected  279    244\n\n, , Dept = E\n\n          Gender\nAdmit      Male Female\n  Admitted   53     94\n  Rejected  138    299\n\n, , Dept = F\n\n          Gender\nAdmit      Male Female\n  Admitted   22     24\n  Rejected  351    317\n\ndimnames(UCBAdmissions)\n\n$Admit\n[1] \"Admitted\" \"Rejected\"\n\n$Gender\n[1] \"Male\"   \"Female\"\n\n$Dept\n[1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\"\n\n\nConstruimos un data.frame con admitidos y rechazados:\n\nUCB &lt;- as.data.frame.table(UCBAdmissions[\"Admitted\", , ])\nnames(UCB)[3] &lt;- \"admit\"\n\nUCB$reject &lt;- as.data.frame.table(UCBAdmissions[\"Rejected\", , ])$Freq\n\nUCB$Gender &lt;- relevel(UCB$Gender, ref = \"Male\")\n\nUCB$total &lt;- UCB$admit + UCB$reject\nUCB$p     &lt;- UCB$admit / UCB$total\n\nhead(UCB)\n\n  Gender Dept admit reject total         p\n1   Male    A   512    313   825 0.6206061\n2 Female    A    89     19   108 0.8240741\n3   Male    B   353    207   560 0.6303571\n4 Female    B    17      8    25 0.6800000\n5   Male    C   120    205   325 0.3692308\n6 Female    C   202    391   593 0.3406408\n\n\n\n4.1.1 Modelo logit con interacción Dept * Gender\n\nUCB.glm &lt;- glm(\n  p ~ Dept * Gender,\n  family  = binomial,\n  data    = UCB,\n  weights = total\n)\n\nanova(UCB.glm, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: p\n\nTerms added sequentially (first to last)\n\n            Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                           11     877.06              \nDept         5   855.32         6      21.74 &lt; 2.2e-16 ***\nGender       1     1.53         5      20.20  0.215928    \nDept:Gender  5    20.20         0       0.00  0.001144 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(UCB.glm)\n\n\nCall:\nglm(formula = p ~ Dept * Gender, family = binomial, data = UCB, \n    weights = total)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         0.49212    0.07175   6.859 6.94e-12 ***\nDeptB               0.04163    0.11319   0.368  0.71304    \nDeptC              -1.02764    0.13550  -7.584 3.34e-14 ***\nDeptD              -1.19608    0.12641  -9.462  &lt; 2e-16 ***\nDeptE              -1.44908    0.17681  -8.196 2.49e-16 ***\nDeptF              -3.26187    0.23120 -14.109  &lt; 2e-16 ***\nGenderFemale        1.05208    0.26271   4.005 6.21e-05 ***\nDeptB:GenderFemale -0.83205    0.51039  -1.630  0.10306    \nDeptC:GenderFemale -1.17700    0.29956  -3.929 8.53e-05 ***\nDeptD:GenderFemale -0.97009    0.30262  -3.206  0.00135 ** \nDeptE:GenderFemale -1.25226    0.33032  -3.791  0.00015 ***\nDeptF:GenderFemale -0.86318    0.40267  -2.144  0.03206 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance:  8.7706e+02  on 11  degrees of freedom\nResidual deviance: -3.4195e-14  on  0  degrees of freedom\nAIC: 92.94\n\nNumber of Fisher Scoring iterations: 3\n\nsummary(UCB.glm)$coef\n\n                      Estimate Std. Error     z value     Pr(&gt;|z|)\n(Intercept)         0.49212143 0.07174966   6.8588682 6.940825e-12\nDeptB               0.04162783 0.11318919   0.3677721 7.130431e-01\nDeptC              -1.02763967 0.13549685  -7.5842331 3.344593e-14\nDeptD              -1.19607953 0.12640656  -9.4621632 3.016374e-21\nDeptE              -1.44908321 0.17681152  -8.1956378 2.492678e-16\nDeptF              -3.26186520 0.23119594 -14.1086615 3.358928e-45\nGenderFemale        1.05207596 0.26270810   4.0047336 6.208742e-05\nDeptB:GenderFemale -0.83205342 0.51039480  -1.6302153 1.030560e-01\nDeptC:GenderFemale -1.17699758 0.29955796  -3.9291147 8.525915e-05\nDeptD:GenderFemale -0.97008876 0.30261874  -3.2056467 1.347593e-03\nDeptE:GenderFemale -1.25226298 0.33032201  -3.7910371 1.500195e-04\nDeptF:GenderFemale -0.86318013 0.40266653  -2.1436600 3.206014e-02\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nEl modelo captura cómo la probabilidad de admisión cambia por departamento y género, incluyendo la interacción entre ambos.\n\nEl resultado ilustra el clásico ejemplo de sesgo aparente por género y cómo la estructura por departamentos altera la interpretación (paradoja de Simpson)."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#anova-de-un-factor-dataset-sugar",
    "href": "labs_epg/lab05_epg.html#anova-de-un-factor-dataset-sugar",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "4.2 ANOVA de un factor: dataset sugar",
    "text": "4.2 ANOVA de un factor: dataset sugar\nEste ejemplo se centra en un diseño de tratamientos (trt) y la variable respuesta weight (peso).\n\ndata(sugar)\nhead(sugar)\n\n  weight     trt\n1   82.0 Control\n2   97.8 Control\n3   69.9 Control\n4   58.3       A\n5   67.9       A\n6   59.3       A\n\nlibrary(lattice)\nstripplot(trt ~ weight,\n          pch  = 0,\n          xlab = \"Weight (mg)\",\n          data = sugar,\n          aspect = 0.5)\n\n\n\n\n\n\n\nlevels(sugar$trt)\n\n[1] \"Control\" \"A\"       \"B\"       \"C\"      \n\n\n\n4.2.1 Ajuste del modelo ANOVA\n\nsugar.aov &lt;- aov(weight ~ trt, data = sugar)\nmodel.matrix(sugar.aov)\n\n   (Intercept) trtA trtB trtC\n1            1    0    0    0\n2            1    0    0    0\n3            1    0    0    0\n4            1    1    0    0\n5            1    1    0    0\n6            1    1    0    0\n7            1    0    1    0\n8            1    0    1    0\n9            1    0    1    0\n10           1    0    0    1\n11           1    0    0    1\n12           1    0    0    1\nattr(,\"assign\")\n[1] 0 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$trt\n[1] \"contr.treatment\"\n\nsummary.lm(sugar.aov)\n\n\nCall:\naov(formula = weight ~ trt, data = sugar)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.3333  -2.7833  -0.6167   2.1750  14.5667 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   83.233      4.473  18.609 7.17e-08 ***\ntrtA         -21.400      6.325  -3.383 0.009597 ** \ntrtB         -15.733      6.325  -2.487 0.037680 *  \ntrtC         -34.333      6.325  -5.428 0.000625 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.747 on 8 degrees of freedom\nMultiple R-squared:  0.7915,    Adjusted R-squared:  0.7133 \nF-statistic: 10.12 on 3 and 8 DF,  p-value: 0.004248\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nEl intercepto está asociado a una categoría base (por ejemplo, Control).\n\nCada coeficiente representa la diferencia de cada tratamiento respecto al control.\n\nProbamos si hay diferencias significativas en el peso promedio entre tratamientos.\n\n\n\n\n\n4.2.2 Medias y comparaciones múltiples (Tukey)\n\npredict(sugar.aov)\n\n       1        2        3        4        5        6        7        8 \n83.23333 83.23333 83.23333 61.83333 61.83333 61.83333 67.50000 67.50000 \n       9       10       11       12 \n67.50000 48.90000 48.90000 48.90000 \n\nsem &lt;- summary.lm(sugar.aov)$sigma / sqrt(3)  # 3 observaciones por grupo\n\nboxplot(sugar$weight ~ sugar$trt,\n        xlab = \"Tratamiento\", ylab = \"Peso\",\n        main = \"Distribución de peso por tratamiento\")\n\n\n\n\n\n\n\nTukeyHSD(sugar.aov, conf.level = 0.95)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = weight ~ trt, data = sugar)\n\n$trt\n                diff       lwr        upr     p adj\nA-Control -21.400000 -41.65627  -1.143735 0.0388013\nB-Control -15.733333 -35.98960   4.522932 0.1368094\nC-Control -34.333333 -54.58960 -14.077068 0.0027770\nB-A         5.666667 -14.58960  25.922932 0.8074414\nC-A       -12.933333 -33.18960   7.322932 0.2491650\nC-B       -18.600000 -38.85627   1.656265 0.0723466\n\nplot(TukeyHSD(sugar.aov, conf.level = 0.95), las = 2)"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#anova-de-dos-factores-appletaste",
    "href": "labs_epg/lab05_epg.html#anova-de-dos-factores-appletaste",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "4.3 ANOVA de dos factores: appletaste",
    "text": "4.3 ANOVA de dos factores: appletaste\nEste dataset contiene evaluaciones de aftertaste (sabor residual) de distintos productos de manzana por distintos panelistas.\n\ndata(appletaste)\nhead(appletaste)\n\n  aftertaste panelist product\n1         89        a     937\n2         98        a     298\n3        108        a     493\n4         13        b     937\n5         55        b     298\n6        104        b     493\n\n# Eliminamos un panelista en particular (k)\nappletaste1 &lt;- appletaste[appletaste$panelist != \"k\", ]\n\ntable(appletaste1$product, appletaste1$panelist)\n\n     \n      a b c d e f g h i j k l m n o p q r s t\n  298 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n  493 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1\n  649 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n  937 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\n\nsapply(appletaste1, is.factor)\n\naftertaste   panelist    product \n     FALSE       TRUE       TRUE \n\n\n\n4.3.1 ANOVA con panelista y producto\n\nappletaste.aov &lt;- aov(aftertaste ~ panelist + product,\n                      data = appletaste1)\n\nsummary(appletaste.aov)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \npanelist    18  25396    1411   1.913   0.0492 *  \nproduct      3  35073   11691  15.851 1.12e-06 ***\nResiduals   35  25815     738                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nboxplot(appletaste1$aftertaste ~ appletaste1$product,\n        main = \"Aftertaste por producto\")\n\n\n\n\n\n\n\nboxplot(appletaste1$aftertaste ~ appletaste1$panelist,\n        main = \"Aftertaste por panelista\")\n\n\n\n\n\n\n\nTukeyHSD(appletaste.aov, conf.level = 0.95)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = aftertaste ~ panelist + product, data = appletaste1)\n\n$panelist\n           diff        lwr        upr     p adj\nb-a -41.0000000 -125.08231  43.082307 0.9239145\nc-a   5.0000000  -79.08231  89.082307 1.0000000\nd-a -25.0000000 -109.08231  59.082307 0.9995641\ne-a -26.3333333 -110.41564  57.748974 0.9991587\nf-a -34.6666667 -118.74897  49.415641 0.9822057\ng-a -60.3333333 -144.41564  23.748974 0.4246450\nh-a -43.0000000 -127.08231  41.082307 0.8920491\ni-a -12.0000000  -96.08231  72.082307 1.0000000\nj-a  -7.0000000  -91.08231  77.082307 1.0000000\nl-a -59.3333333 -143.41564  24.748974 0.4530346\nm-a -30.6666667 -114.74897  53.415641 0.9949812\nn-a -40.0000000 -124.08231  44.082307 0.9372358\no-a -61.3333333 -145.41564  22.748974 0.3970457\np-a -32.3333333 -116.41564  51.748974 0.9911582\nq-a -47.6666667 -131.74897  36.415641 0.7913417\nr-a -30.3333333 -114.41564  53.748974 0.9955513\ns-a -45.0000000 -129.08231  39.082307 0.8532101\nt-a -77.3333333 -161.41564   6.748974 0.1012762\nc-b  46.0000000  -38.08231 130.082307 0.8312840\nd-b  16.0000000  -68.08231 100.082307 0.9999993\ne-b  14.6666667  -69.41564  98.748974 0.9999998\nf-b   6.3333333  -77.74897  90.415641 1.0000000\ng-b -19.3333333 -103.41564  64.748974 0.9999875\nh-b  -2.0000000  -86.08231  82.082307 1.0000000\ni-b  29.0000000  -55.08231 113.082307 0.9973249\nj-b  34.0000000  -50.08231 118.082307 0.9852771\nl-b -18.3333333 -102.41564  65.748974 0.9999943\nm-b  10.3333333  -73.74897  94.415641 1.0000000\nn-b   1.0000000  -83.08231  85.082307 1.0000000\no-b -20.3333333 -104.41564  63.748974 0.9999740\np-b   8.6666667  -75.41564  92.748974 1.0000000\nq-b  -6.6666667  -90.74897  77.415641 1.0000000\nr-b  10.6666667  -73.41564  94.748974 1.0000000\ns-b  -4.0000000  -88.08231  80.082307 1.0000000\nt-b -36.3333333 -120.41564  47.748974 0.9723614\nd-c -30.0000000 -114.08231  54.082307 0.9960668\ne-c -31.3333333 -115.41564  52.748974 0.9936600\nf-c -39.6666667 -123.74897  44.415641 0.9412994\ng-c -65.3333333 -149.41564  18.748974 0.2963345\nh-c -48.0000000 -132.08231  36.082307 0.7828845\ni-c -17.0000000 -101.08231  67.082307 0.9999982\nj-c -12.0000000  -96.08231  72.082307 1.0000000\nl-c -64.3333333 -148.41564  19.748974 0.3199219\nm-c -35.6666667 -119.74897  48.415641 0.9766966\nn-c -45.0000000 -129.08231  39.082307 0.8532101\no-c -66.3333333 -150.41564  17.748974 0.2738830\np-c -37.3333333 -121.41564  46.748974 0.9647639\nq-c -52.6666667 -136.74897  31.415641 0.6522222\nr-c -35.3333333 -119.41564  48.748974 0.9786603\ns-c -50.0000000 -134.08231  34.082307 0.7293259\nt-c -82.3333333 -166.41564   1.748974 0.0603829\ne-d  -1.3333333  -85.41564  82.748974 1.0000000\nf-d  -9.6666667  -93.74897  74.415641 1.0000000\ng-d -35.3333333 -119.41564  48.748974 0.9786603\nh-d -18.0000000 -102.08231  66.082307 0.9999957\ni-d  13.0000000  -71.08231  97.082307 1.0000000\nj-d  18.0000000  -66.08231 102.082307 0.9999957\nl-d -34.3333333 -118.41564  49.748974 0.9837980\nm-d  -5.6666667  -89.74897  78.415641 1.0000000\nn-d -15.0000000  -99.08231  69.082307 0.9999997\no-d -36.3333333 -120.41564  47.748974 0.9723614\np-d  -7.3333333  -91.41564  76.748974 1.0000000\nq-d -22.6666667 -106.74897  61.415641 0.9998811\nr-d  -5.3333333  -89.41564  78.748974 1.0000000\ns-d -20.0000000 -104.08231  64.082307 0.9999796\nt-d -52.3333333 -136.41564  31.748974 0.6621111\nf-e  -8.3333333  -92.41564  75.748974 1.0000000\ng-e -34.0000000 -118.08231  50.082307 0.9852771\nh-e -16.6666667 -100.74897  67.415641 0.9999987\ni-e  14.3333333  -69.74897  98.415641 0.9999999\nj-e  19.3333333  -64.74897 103.415641 0.9999875\nl-e -33.0000000 -117.08231  51.082307 0.9890877\nm-e  -4.3333333  -88.41564  79.748974 1.0000000\nn-e -13.6666667  -97.74897  70.415641 0.9999999\no-e -35.0000000 -119.08231  49.082307 0.9804949\np-e  -6.0000000  -90.08231  78.082307 1.0000000\nq-e -21.3333333 -105.41564  62.748974 0.9999487\nr-e  -4.0000000  -88.08231  80.082307 1.0000000\ns-e -18.6666667 -102.74897  65.415641 0.9999926\nt-e -51.0000000 -135.08231  33.082307 0.7010209\ng-f -25.6666667 -109.74897  58.415641 0.9993900\nh-f  -8.3333333  -92.41564  75.748974 1.0000000\ni-f  22.6666667  -61.41564 106.748974 0.9998811\nj-f  27.6666667  -56.41564 111.748974 0.9984622\nl-f -24.6666667 -108.74897  59.415641 0.9996335\nm-f   4.0000000  -80.08231  88.082307 1.0000000\nn-f  -5.3333333  -89.41564  78.748974 1.0000000\no-f -26.6666667 -110.74897  57.415641 0.9990169\np-f   2.3333333  -81.74897  86.415641 1.0000000\nq-f -13.0000000  -97.08231  71.082307 1.0000000\nr-f   4.3333333  -79.74897  88.415641 1.0000000\ns-f -10.3333333  -94.41564  73.748974 1.0000000\nt-f -42.6666667 -126.74897  41.415641 0.8978483\nh-g  17.3333333  -66.74897 101.415641 0.9999976\ni-g  48.3333333  -35.74897 132.415641 0.7742833\nj-g  53.3333333  -30.74897 137.415641 0.6323007\nl-g   1.0000000  -83.08231  85.082307 1.0000000\nm-g  29.6666667  -54.41564 113.748974 0.9965317\nn-g  20.3333333  -63.74897 104.415641 0.9999740\no-g  -1.0000000  -85.08231  83.082307 1.0000000\np-g  28.0000000  -56.08231 112.082307 0.9982261\nq-g  12.6666667  -71.41564  96.748974 1.0000000\nr-g  30.0000000  -54.08231 114.082307 0.9960668\ns-g  15.3333333  -68.74897  99.415641 0.9999996\nt-g -17.0000000 -101.08231  67.082307 0.9999982\ni-h  31.0000000  -53.08231 115.082307 0.9943522\nj-h  36.0000000  -48.08231 120.082307 0.9745987\nl-h -16.3333333 -100.41564  67.748974 0.9999990\nm-h  12.3333333  -71.74897  96.415641 1.0000000\nn-h   3.0000000  -81.08231  87.082307 1.0000000\no-h -18.3333333 -102.41564  65.748974 0.9999943\np-h  10.6666667  -73.41564  94.748974 1.0000000\nq-h  -4.6666667  -88.74897  79.415641 1.0000000\nr-h  12.6666667  -71.41564  96.748974 1.0000000\ns-h  -2.0000000  -86.08231  82.082307 1.0000000\nt-h -34.3333333 -118.41564  49.748974 0.9837980\nj-i   5.0000000  -79.08231  89.082307 1.0000000\nl-i -47.3333333 -131.41564  36.748974 0.7996494\nm-i -18.6666667 -102.74897  65.415641 0.9999926\nn-i -28.0000000 -112.08231  56.082307 0.9982261\no-i -49.3333333 -133.41564  34.748974 0.7476743\np-i -20.3333333 -104.41564  63.748974 0.9999740\nq-i -35.6666667 -119.74897  48.415641 0.9766966\nr-i -18.3333333 -102.41564  65.748974 0.9999943\ns-i -33.0000000 -117.08231  51.082307 0.9890877\nt-i -65.3333333 -149.41564  18.748974 0.2963345\nl-j -52.3333333 -136.41564  31.748974 0.6621111\nm-j -23.6666667 -107.74897  60.415641 0.9997873\nn-j -33.0000000 -117.08231  51.082307 0.9890877\no-j -54.3333333 -138.41564  29.748974 0.6021671\np-j -25.3333333 -109.41564  58.748974 0.9994834\nq-j -40.6666667 -124.74897  43.415641 0.9285454\nr-j -23.3333333 -107.41564  60.748974 0.9998240\ns-j -38.0000000 -122.08231  46.082307 0.9589140\nt-j -70.3333333 -154.41564  13.748974 0.1957341\nm-l  28.6666667  -55.41564 112.748974 0.9976605\nn-l  19.3333333  -64.74897 103.415641 0.9999875\no-l  -2.0000000  -86.08231  82.082307 1.0000000\np-l  27.0000000  -57.08231 111.082307 0.9988552\nq-l  11.6666667  -72.41564  95.748974 1.0000000\nr-l  29.0000000  -55.08231 113.082307 0.9973249\ns-l  14.3333333  -69.74897  98.415641 0.9999999\nt-l -18.0000000 -102.08231  66.082307 0.9999957\nn-m  -9.3333333  -93.41564  74.748974 1.0000000\no-m -30.6666667 -114.74897  53.415641 0.9949812\np-m  -1.6666667  -85.74897  82.415641 1.0000000\nq-m -17.0000000 -101.08231  67.082307 0.9999982\nr-m   0.3333333  -83.74897  84.415641 1.0000000\ns-m -14.3333333  -98.41564  69.748974 0.9999999\nt-m -46.6666667 -130.74897  37.415641 0.8157955\no-n -21.3333333 -105.41564  62.748974 0.9999487\np-n   7.6666667  -76.41564  91.748974 1.0000000\nq-n  -7.6666667  -91.74897  76.415641 1.0000000\nr-n   9.6666667  -74.41564  93.748974 1.0000000\ns-n  -5.0000000  -89.08231  79.082307 1.0000000\nt-n -37.3333333 -121.41564  46.748974 0.9647639\np-o  29.0000000  -55.08231 113.082307 0.9973249\nq-o  13.6666667  -70.41564  97.748974 0.9999999\nr-o  31.0000000  -53.08231 115.082307 0.9943522\ns-o  16.3333333  -67.74897 100.415641 0.9999990\nt-o -16.0000000 -100.08231  68.082307 0.9999993\nq-p -15.3333333  -99.41564  68.748974 0.9999996\nr-p   2.0000000  -82.08231  86.082307 1.0000000\ns-p -12.6666667  -96.74897  71.415641 1.0000000\nt-p -45.0000000 -129.08231  39.082307 0.8532101\nr-q  17.3333333  -66.74897 101.415641 0.9999976\ns-q   2.6666667  -81.41564  86.748974 1.0000000\nt-q -29.6666667 -113.74897  54.415641 0.9965317\ns-r -14.6666667  -98.74897  69.415641 0.9999998\nt-r -47.0000000 -131.08231  37.082307 0.8078023\nt-s -32.3333333 -116.41564  51.748974 0.9911582\n\n$product\n             diff       lwr        upr     p adj\n493-298  17.84286  -9.37496  45.060674 0.3054791\n649-298 -12.52381 -40.20692  15.159303 0.6185367\n937-298 -46.04762 -73.73073 -18.364507 0.0004190\n649-493 -30.36667 -57.58448  -3.148850 0.0238482\n937-493 -63.89048 -91.10829 -36.672659 0.0000017\n937-649 -33.52381 -61.20692  -5.840697 0.0124799\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nEl ANOVA permite separar el efecto del producto del efecto del panelista.\n\nEn la práctica, nos interesa si el producto tiene un efecto significativo en la evaluación, más allá de la variabilidad entre panelistas."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#generar-el-dataset",
    "href": "labs_epg/lab05_epg.html#generar-el-dataset",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.1 Generar el dataset",
    "text": "5.1 Generar el dataset\n\npesos &lt;- c(\n  18.15, 16.51, 0.24, 19.15, 19.49, 0.16, 18.68,\n  19.50, 0.32, 18.35, 19.81, 0.17, 19.54, 19.84,\n  0.20, 20.58, 19.44, 0.22, 21.27, 23.30, 0.33,\n  18.87, 22.00, 0.25, 19.57, 22.30, 0.45, 20.66,\n  21.08, 0.20, 20.15, 18.95, 0.35, 21.56, 20.34,\n  0.20, 20.74, 16.69, 0.31, 20.22, 19.00, 0.18,\n  20.02, 19.26, 0.41, 18.38, 17.92, 0.30, 17.20,\n  15.90, 0.28, 20.85, 19.90, 0.17\n)\n\ny1 &lt;- pesos[c(TRUE, FALSE, FALSE)]\ny2 &lt;- pesos[c(FALSE, TRUE, FALSE)]\ny3 &lt;- pesos[c(FALSE, FALSE, TRUE)]\n\ntemp &lt;- factor(c(rep(4, 6), rep(20, 6), rep(34, 6)))\nsex  &lt;- factor(rep(c(rep(\"M\", 3), rep(\"H\", 3)), 3))\n\nratas &lt;- data.frame(y1, y2, y3, temp, sex)\nhead(ratas)\n\n     y1    y2   y3 temp sex\n1 18.15 16.51 0.24    4   M\n2 19.15 19.49 0.16    4   M\n3 18.68 19.50 0.32    4   M\n4 18.35 19.81 0.17    4   H\n5 19.54 19.84 0.20    4   H\n6 20.58 19.44 0.22    4   H"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#boxplots-exploratorios",
    "href": "labs_epg/lab05_epg.html#boxplots-exploratorios",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.2 Boxplots exploratorios",
    "text": "5.2 Boxplots exploratorios\n\nggboxplot(ratas, x = \"sex\", y = c(\"y1\", \"y2\"),\n          merge = TRUE, palette = \"jco\")\n\n\n\n\n\n\n\nggboxplot(ratas, x = \"temp\", y = c(\"y1\", \"y2\"),\n          merge = TRUE, palette = \"jco\")"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#estadísticos-agrupados-media-n-sd",
    "href": "labs_epg/lab05_epg.html#estadísticos-agrupados-media-n-sd",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.3 Estadísticos agrupados (media, n, sd)",
    "text": "5.3 Estadísticos agrupados (media, n, sd)\n\naggregate(ratas[, 1:3], list(sex = ratas$sex, temp = ratas$temp), mean)\n\n  sex temp       y1       y2        y3\n1   H    4 19.49000 19.69667 0.1966667\n2   M    4 18.66000 18.50000 0.2400000\n3   H   20 20.79000 20.12333 0.2500000\n4   M   20 19.90333 22.53333 0.3433333\n5   H   34 18.81000 17.90667 0.2500000\n6   M   34 20.32667 18.31667 0.3000000\n\naggregate(ratas[, 1:3], list(sex = ratas$sex, temp = ratas$temp), length)\n\n  sex temp y1 y2 y3\n1   H    4  3  3  3\n2   M    4  3  3  3\n3   H   20  3  3  3\n4   M   20  3  3  3\n5   H   34  3  3  3\n6   M   34  3  3  3\n\naggregate(ratas[, 1:3], list(sex = ratas$sex, temp = ratas$temp), sd)\n\n  sex temp        y1        y2         y3\n1   H    4 1.1158405 0.2227854 0.02516611\n2   M    4 0.5002999 1.7233978 0.08000000\n3   H   20 0.7139328 1.0814034 0.08660254\n4   M   20 1.2342339 0.6806859 0.10066446\n5   H   34 1.8626057 2.0000333 0.07000000\n6   M   34 0.3716629 1.4147202 0.11532563"
  },
  {
    "objectID": "labs_epg/lab05_epg.html#normalidad-univariada-por-grupo",
    "href": "labs_epg/lab05_epg.html#normalidad-univariada-por-grupo",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.4 Normalidad univariada por grupo",
    "text": "5.4 Normalidad univariada por grupo\nDefinimos una función que calcula el p-value del test de Shapiro–Wilk:\n\nnormal &lt;- function(vec){\n  shapiro.test(vec)$p.value\n}\n\naggregate(ratas[, 1:3], list(sex = ratas$sex, temp = ratas$temp), normal)\n\n  sex temp        y1          y2        y3\n1   H    4 0.9258674 0.128686974 0.7804408\n2   M    4 0.9338670 0.005540978 1.0000000\n3   H   20 0.6975632 0.666926507 0.0000000\n4   M   20 0.5491264 0.424350926 0.7804408\n5   H   34 0.6155710 0.988973545 0.2737737\n6   M   34 0.5202800 0.175746733 0.8564460\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nP-values grandes sugieren que no podemos rechazar normalidad para esa combinación de grupo y variable.\n\nEsto es un requisito para aplicar ANOVA/MANOVA de forma estricta."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#modelos-manova",
    "href": "labs_epg/lab05_epg.html#modelos-manova",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.5 Modelos MANOVA",
    "text": "5.5 Modelos MANOVA\nPlanteamos distintos modelos multivariantes:\n\nmod1   &lt;- manova(cbind(y1, y2, y3) ~ sex + temp, data = ratas)\nsummary(mod1)\n\n          Df  Pillai approx F num Df den Df  Pr(&gt;F)  \nsex        1 0.21483   1.0945      3     12 0.38905  \ntemp       2 0.80234   2.9030      6     26 0.02656 *\nResiduals 14                                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod1.1 &lt;- manova(cbind(y1, y2, y3) ~ temp, data = ratas)\nsummary(mod1.1)\n\n          Df  Pillai approx F num Df den Df  Pr(&gt;F)  \ntemp       2 0.76682   2.9018      6     28 0.02503 *\nResiduals 15                                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod2   &lt;- manova(cbind(y1, y2, y3) ~ sex * temp, data = ratas)\nsummary(mod2)\n\n          Df  Pillai approx F num Df den Df  Pr(&gt;F)  \nsex        1 0.27510   1.2650      3     10 0.33838  \ntemp       2 0.97019   3.4544      6     22 0.01475 *\nsex:temp   2 0.75271   2.2128      6     22 0.08041 .\nResiduals 12                                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nMANOVA evalúa si los factores (sexo, temperatura, e interacción) tienen efectos conjuntos sobre el vector \\((y1, y2, y3)\\).\n\nSi hay significancia, se justifica mirar luego análisis univariados para cada variable por separado."
  },
  {
    "objectID": "labs_epg/lab05_epg.html#anova-univariados-asociados",
    "href": "labs_epg/lab05_epg.html#anova-univariados-asociados",
    "title": "Capitulo_5 _Logit_y_otros _analisis",
    "section": "5.6 ANOVA univariados asociados",
    "text": "5.6 ANOVA univariados asociados\n\nm1 &lt;- aov(y1 ~ temp,        data = ratas)\nm2 &lt;- aov(y2 ~ temp,        data = ratas)\nm3 &lt;- aov(y3 ~ temp,        data = ratas)\nm4 &lt;- aov(y1 ~ temp * sex,  data = ratas)\nm5 &lt;- aov(y2 ~ temp * sex,  data = ratas)\nm6 &lt;- aov(y3 ~ temp * sex,  data = ratas)\n\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ntemp         2  4.933   2.466   1.856   0.19\nResiduals   15 19.935   1.329               \n\nsummary(m2)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ntemp         2  32.59  16.293   7.538 0.00542 **\nResiduals   15  32.42   2.161                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m3)\n\n            Df  Sum Sq  Mean Sq F value Pr(&gt;F)\ntemp         2 0.01963 0.009817   1.398  0.278\nResiduals   15 0.10537 0.007024               \n\nsummary(m4)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ntemp         2  4.933   2.466   2.074  0.168\nsex          1  0.020   0.020   0.017  0.899\ntemp:sex     2  5.643   2.821   2.372  0.135\nResiduals   12 14.272   1.189               \n\nsummary(m5)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ntemp         2  32.59  16.293   9.176 0.00382 **\nsex          1   1.32   1.318   0.742 0.40590   \ntemp:sex     2   9.79   4.897   2.758 0.10339   \nResiduals   12  21.31   1.776                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m6)\n\n            Df  Sum Sq  Mean Sq F value Pr(&gt;F)\ntemp         2 0.01963 0.009817   1.374  0.290\nsex          1 0.01742 0.017422   2.439  0.144\ntemp:sex     2 0.00221 0.001106   0.155  0.858\nResiduals   12 0.08573 0.007144               \n\n\n\n5.6.1 Tamaño de efecto (eta cuadrado)\n\netaSquared(m2)\n\n        eta.sq eta.sq.part\ntemp 0.5012788   0.5012788\n\netaSquared(m5)\n\n             eta.sq eta.sq.part\ntemp     0.50127879  0.60463503\nsex      0.02026862  0.05823481\ntemp:sex 0.15067126  0.31491368\n\n\n\n\n\n\n\n\nNota\n\n\n\nRegla de interpretación de eta² (aproximada):\n\n0.01 → efecto pequeño.\n\n0.06 → efecto mediano.\n\n\n0.14 → efecto grande.\n\n\nEsto ayuda a complementar la significancia estadística con una medida de magnitud del efecto.\n\n\n\n\n5.6.2 Comparaciones múltiples (Tukey) para una de las ANOVA\n\npost &lt;- TukeyHSD(m2)\npost\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = y2 ~ temp, data = ratas)\n\n$temp\n            diff         lwr       upr     p adj\n20-4   2.2300000  0.02527797  4.434722 0.0472590\n34-4  -0.9866667 -3.19138869  1.218055 0.4924782\n34-20 -3.2166667 -5.42138869 -1.011945 0.0047632\n\nplot(post)"
  },
  {
    "objectID": "labs_epg/lab03_epg_nopred.html",
    "href": "labs_epg/lab03_epg_nopred.html",
    "title": "Capitulo_3_Regresion_Multiple",
    "section": "",
    "text": "1 1. Material descargable\nDescargar PDF de contenidos teóricos\nEl documento incluye:\n\nMatriz de correlación y multicolinealidad.\n\nSupuestos del modelo clásico de regresión múltiple.\n\nDerivación de estimadores OLS \\((X'X)^{-1}X'Y\\).\n\nVarianza del error y matriz de covarianza del estimador.\n\n\\(R^2\\), \\(R^2\\) ajustado y prueba F global.\n\nInferencia individual sobre coeficientes (\\(t\\)-tests).\n\nIntervalos de confianza.\n\nPruebas de autocorrelación y heterocedasticidad.\n\n\n\n2 Configuración inicial\n\nlibrary(openxlsx)\nlibrary(corrplot)\nlibrary(lmtest)\n\nDefinimos tu ruta de datos:\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\"    \n\n\n\n\n3 Lectura de datos\n\narchivo &lt;- file.path(ruta_datos, \"costos.xlsx\")\ndatos &lt;- read.xlsx(archivo, sheet=\"Hoja1\", colNames=TRUE)\nhead(datos)\n\n  Costos_generales Horas_mano_de_obra Horas_maquina Numero_preparaciones\n1           155000                985          1060                  200\n2           160000               1068          1080                  225\n3           170000               1095          1100                  250\n4           165000               1105          1200                  202\n5           185000               1200          1600                  210\n6           135000               1160          1100                  150\n\n\nLos datos contienen:\n\nCostos_generales (variable dependiente).\n\nHoras_maquina y Numero_preparaciones (variables explicativas).\n\n\n\n4 Matriz de correlación\nLa matriz de correlación nos permite:\n\nDetectar relaciones lineales entre pares de variables.\n\nIdentificar multicolinealidad entre regresores.\n\n\nr &lt;- cor(datos)\nr\n\n                     Costos_generales Horas_mano_de_obra Horas_maquina\nCostos_generales            1.0000000         0.53462157     0.8775005\nHoras_mano_de_obra          0.5346216         1.00000000     0.7680722\nHoras_maquina               0.8775005         0.76807222     1.0000000\nNumero_preparaciones        0.6274762        -0.04731148     0.2507478\n                     Numero_preparaciones\nCostos_generales               0.62747618\nHoras_mano_de_obra            -0.04731148\nHoras_maquina                  0.25074784\nNumero_preparaciones           1.00000000\n\n\n\n4.0.1 Gráficos de exploración\n\npairs(datos)\n\n\n\n\n\n\n\ncorrplot(r, method=\"circle\", type=\"lower\", diag=FALSE,\n         tl.col=\"black\", tl.cex=1, tl.srt=45)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n🔍 Interpretación pedagógica:\n- Valores altos en la correlación entre regresores → multicolinealidad.\n- Esto puede inflar varianzas de los estimadores y hacer inestables los coeficientes.\n- La matriz y el corrplot permiten detectar problemas antes de ajustar el modelo.\n\n\n\n\n\n5 Modelo de regresión múltiple\nAjustamos el modelo:\n\\[\n\\text{Costos} = \\beta_0 + \\beta_1(\\text{Horas\\_maquina}) + \\beta_2(\\text{Numero\\_preparaciones}) + \\varepsilon\n\\]\n\nmodelo &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones, data=datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones, \n    data = datos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -7157  -2827    768   1449   9407 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          19796.44   12787.83   1.548 0.156013    \nHoras_maquina           65.44       6.74   9.709 4.57e-06 ***\nNumero_preparaciones   322.21      58.66   5.493 0.000384 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4951 on 9 degrees of freedom\nMultiple R-squared:  0.9472,    Adjusted R-squared:  0.9354 \nF-statistic: 80.66 on 2 and 9 DF,  p-value: 1.792e-06\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nPrueba individual (t test): evalúa si cada (_j) es distinto de 0.\n\nPrueba global (F test): evalúa si el modelo en conjunto explica la variable dependiente.\n\n**Signo de (_j):** indica dirección del efecto.\n\nMagnitud: indica cuánto cambia Y ante un cambio unitario en el regresor.\n\np-values pequeños: evidencia estadística de relación significativa.\n\n\n\n\n\n6 Residuos del modelo\n\nepsilon &lt;- modelo$residuals\nhist(epsilon)\n\n\n\n\n\n\n\nplot(density(epsilon))\n\n\n\n\n\n\n\nmean(epsilon)\n\n[1] 1.705303e-13\n\n\n\n6.0.1 Normalidad de los residuos\n\nshapiro.test(epsilon)\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95577, p-value = 0.7222\n\n\n\n\n6.0.2 Autocorrelación (Durbin–Watson)\n\ndwtest(modelo, alternative=\"two.sided\", iterations=1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0815, p-value = 0.7416\nalternative hypothesis: true autocorrelation is not 0\n\n\nInterpretación: - DW ≈ 2 → no autocorrelación\n- DW &lt; 2 → autocorrelación positiva\n- DW &gt; 2 → autocorrelación negativa\n\n\n6.0.3 Heterocedasticidad (Breusch–Pagan)\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 1.0153, df = 2, p-value = 0.6019\n\n\n\n\n\n7 Estadístico F calculado a mano\n\nR2 &lt;- 0.9472\nF &lt;- (R2/2)/((1-R2)/(12-3))\nF\n\n[1] 80.72727\n\nqf(0.05, 2, 9, lower.tail=FALSE)\n\n[1] 4.256495\n\n\nInterpretación: si F calculado &gt; F crítico → el modelo aporta información significativa.\n\n\n8 Desviación estándar del error\n\ns &lt;- sqrt(sum(epsilon^2)/(12-2-1))\ns\n\n[1] 4951.106\n\n\n\n\n9 Intervalos de confianza de los coeficientes\n\nconfint(modelo)\n\n                           2.5 %     97.5 %\n(Intercept)          -9131.64046 48724.5095\nHoras_maquina           50.18894    80.6827\nNumero_preparaciones   189.50994   454.9046\n\n\n\n9.0.1 Cálculo manual del intervalo\n\nse &lt;- sqrt(diag(vcov(modelo)))\nt &lt;- -1*qt(0.025, 12-2-1, lower.tail=FALSE)\n\nBHM &lt;- 65.44\nsbhm &lt;- 6.74\n\nlimitsupBHM &lt;- BHM + t*sbhm\nlimitinfBHM &lt;- BHM - t*sbhm\nlimitsupBHM; limitinfBHM\n\n[1] 50.19306\n\n\n[1] 80.68694\n\n\n\n\n\n10 Intervalo para la varianza del error\n\ngamma1 &lt;- qchisq(0.025, 12-2-1)\ngamma2 &lt;- qchisq(0.975, 12-2-1)\n\ns2_LI &lt;- (12-2-1) * s^2 / gamma2\ns2_LS &lt;- (12-2-1) * s^2 / gamma1\n\ns2_LI; s2_LS\n\n[1] 11597739\n\n\n[1] 81699732\n\n\n\n\n11 Predicción puntual\n\nnuevo &lt;- data.frame(Horas_maquina=2000, Numero_preparaciones=220)\n\nvalor_predicho &lt;- predict(modelo, newdata=nuevo)\nvalor_predicho\n\n       1 \n221553.7 \n\n\n\n\n12 Intervalo de confianza con predict\n\nvalor_predicho2 &lt;- predict(modelo, newdata=nuevo, interval=\"confidence\")\nvalor_predicho2\n\n       fit      lwr      upr\n1 221553.7 210265.6 232841.8\n\n\n\n\n13 Predicción manual paso a paso\nConstruimos la matriz (X):\n\nX &lt;- cbind(1, datos$Horas_maquina, datos$Numero_preparaciones)\nM &lt;- solve(t(X) %*% X)\nbeta &lt;- M %*% t(X) %*% datos$Costos_generales\n\nx0 &lt;- c(1, 2000, 220)\nh0 &lt;- t(x0) %*% M %*% x0\n\ny0 &lt;- t(beta) %*% x0\ny0\n\n         [,1]\n[1,] 221553.7\n\n\n\n13.0.1 Intervalo manual\n\ny_limsup &lt;- y0 + s*sqrt(1+h0)*qt(0.975, 12-2-1, lower.tail=FALSE)\ny_liminf &lt;- y0 - s*sqrt(1+h0)*qt(0.975, 12-2-1, lower.tail=FALSE)\n\ny_liminf; y_limsup\n\n         [,1]\n[1,] 237455.4\n\n\n         [,1]\n[1,] 205651.9\n\n\n\n\n\n14 Gráfico Y real vs Y predicho\n\nplot(modelo$fitted.values, datos$Costos_generales,\n     main=\"Revisión Valor Real vs Valor Predicho\")\nlines(c(140000,200000), c(140000,200000))\n\n\n\n\n\n\n\n\n\n\n15 Modelo sin constante\n\nmodelo2 &lt;- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones - 1, data=datos)\nsummary(modelo2)\n\n\nCall:\nlm(formula = Costos_generales ~ Horas_maquina + Numero_preparaciones - \n    1, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9042.2 -3486.9   739.7  3467.0  9300.3 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \nHoras_maquina          69.994      6.472  10.814 7.72e-07 ***\nNumero_preparaciones  390.723     41.098   9.507 2.52e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5286 on 10 degrees of freedom\nMultiple R-squared:  0.9992,    Adjusted R-squared:  0.999 \nF-statistic:  6095 on 2 and 10 DF,  p-value: 3.699e-16\n\n\n\n15.0.1 Análisis de residuos modelo sin constante\n\nepsilon &lt;- modelo2$residuals\nhist(epsilon)\n\n\n\n\n\n\n\nplot(density(epsilon))\n\n\n\n\n\n\n\nshapiro.test(epsilon)\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.97973, p-value = 0.9825\n\ndwtest(modelo2,alternative=\"two.sided\",iterations=1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo2\nDW = 2.1284, p-value = 0.9776\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo2\nBP = 0.33027, df = 1, p-value = 0.5655"
  },
  {
    "objectID": "labs_epg/lab01_epg.html",
    "href": "labs_epg/lab01_epg.html",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos\nEl PDF “Capitulo 1 Introduccion_y_Estadistica_Descriptiva” desarrolla los siguientes temas principales (a modo de índice):\n\n1.1 Introducción\n\nDefinición y términos básicos de la estadística.\n\nDiferencia entre estadística descriptiva e inferencial.\n\nImportancia de la variabilidad.\n\n1.2 Elementos Fundamentales de Estadística\n\nPoblación, muestra, unidad experimental.\n\nVariable, parámetros poblacionales y estimadores muestrales.\n\nEjemplos de problemas descriptivos y de inferencia.\n\n1.3 Tipos de Datos\n\nDatos cuantitativos.\n\nDatos cualitativos (nominales y ordinales).\n\nPor qué el tipo de dato determina qué herramientas estadísticas usar.\n\n1.4 Estadística Descriptiva\n\nMétodos gráficos y numéricos para describir datos cualitativos.\n\nMétodos gráficos para describir datos cuantitativos.\n\nMétodos numéricos para describir datos cuantitativos.\n\nMedidas de tendencia central (media, mediana, moda).\n\nMedidas de variación (rango, varianza, desviación estándar).\n\nMedidas de posición relativa (percentiles, cuartiles, z-scores).\nMedidas de asimetría (skewness).\n\nMedidas de concentración de datos (kurtosis).\n\n\nEn este laboratorio, llevaremos varios de estos conceptos a la práctica usando R."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#carga-de-librerías",
    "href": "labs_epg/lab01_epg.html#carga-de-librerías",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.1 Carga de librerías",
    "text": "2.1 Carga de librerías\n\n# Cargamos las librerías necesarias para el laboratorio\nlibrary(openxlsx)  # leer archivos Excel (.xlsx)\nlibrary(qcc)       # diagrama de Pareto\nlibrary(modeest)   # moda (mfv = most frequent value)\nlibrary(psych)     # funciones de estadística descriptiva (útil en otros labs)\nlibrary(moments)   # skewness y kurtosis\n\n\n\n\n\n\n\nTip\n\n\n\nSi alguna librería no está instalada, puedes hacerlo con:\ninstall.packages(\"nombre_del_paquete\")\nPor ejemplo: install.packages(\"openxlsx\")."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#definir-la-ruta-de-trabajo",
    "href": "labs_epg/lab01_epg.html#definir-la-ruta-de-trabajo",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.2 Definir la ruta de trabajo",
    "text": "2.2 Definir la ruta de trabajo\nVamos a guardar la ruta donde están los datos en un objeto llamado ruta_datos.\nEsto hace que el código sea más fácil de mantener si cambiamos de carpeta en el futuro.\n\n# Definimos la ruta donde están los archivos de datos del laboratorio.\n# IMPORTANTE: Ajusta esta ruta si tu carpeta tiene otro nombre o ubicación.\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\n# Podemos verificar el contenido de la carpeta (opcional)\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\"    \n\n\n\n\n\n\n\n\nNota\n\n\n\nEn R es recomendable usar / (slash) en lugar de **** en las rutas de Windows.\nPor eso escribimos \"C:/Users/manue/Desktop/...\" en lugar de \"C:Users...\".\n\n\n\n2.2.1 Ejemplo 1: Accidentes y métodos gráficos para datos cualitativos\nEn este ejemplo trabajamos con datos cualitativos (categorías de accidentes) y sus frecuencias.\nLa idea es:\n\nLeer una tabla de frecuencias desde Excel.\n\nCalcular las frecuencias relativas.\n\nRepresentar los datos con:\n\nGráfico de barras.\n\nGráfico de torta (pie).\n\nDiagrama de Pareto.\n\n\nCargar los datos del Ejemplo 1\n\n# Construimos la ruta completa al archivo Excel del Ejemplo 1\narchivo_ejemplo1 &lt;- file.path(ruta_datos, \"Ejemplo1.xlsx\")\n\n# Leemos el archivo Excel\ndatos1 &lt;- read.xlsx(\n  archivo_ejemplo1,\n  sheet    = \"Hoja1\",\n  colNames = TRUE\n)\n\n# Vemos las primeras filas para entender la estructura\nhead(datos1)\n\n                  Categoria Frecuencia Acumulado\n1          Explosion de Gas         28        28\n2 Colapso de mina de carbon          7        35\n3             Falla Represa          4        39\n4      Incendio Combustible          4        43\n5        Descarga electrica          1        44\n6           Reactor Nuclear          1        45\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn este archivo esperamos tener al menos estas columnas:\n\nCategoria: tipo de accidente.\n\nFrecuencia: cuántas veces se observó cada tipo de accidente.\n\n\n\n\n\n2.2.2 Cálculo de frecuencias relativas\nLa frecuencia relativa se define como:\n\\[\\text{frecuencia relativa} = \\frac{\\text{frecuencia de la categoría}}{\\text{total de observaciones}}. \\]\n\n# Total de accidentes (suma de las frecuencias)\ntotal &lt;- sum(datos1$Frecuencia)\n\n# Creamos una nueva columna con la frecuencia relativa\ndatos1$relativa &lt;- datos1$Frecuencia / total\n\n# Revisamos la tabla con frecuencia absoluta y relativa\ndatos1\n\n                  Categoria Frecuencia Acumulado   relativa\n1          Explosion de Gas         28        28 0.62222222\n2 Colapso de mina de carbon          7        35 0.15555556\n3             Falla Represa          4        39 0.08888889\n4      Incendio Combustible          4        43 0.08888889\n5        Descarga electrica          1        44 0.02222222\n6           Reactor Nuclear          1        45 0.02222222\n\n\nAhora queremos una versión “lista para graficar” de las frecuencias relativas:\n\n# Convertimos la columna relativa en un vector fila\nrelativo &lt;- t(as.data.frame(datos1$relativa))\n\n# Asignamos como nombres de columnas las categorías\ncolnames(relativo) &lt;- datos1$Categoria\n\nrelativo\n\n                Explosion de Gas Colapso de mina de carbon Falla Represa\ndatos1$relativa        0.6222222                 0.1555556    0.08888889\n                Incendio Combustible Descarga electrica Reactor Nuclear\ndatos1$relativa           0.08888889         0.02222222      0.02222222\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nt() transpone la tabla (cambia filas por columnas).\n\nEsto nos deja un vector fila donde cada columna es una categoría distinta.\n\n\n\n\n\n2.2.3 Gráfico de barras\nEl gráfico de barras es una forma estándar de mostrar frecuencias (o frecuencias relativas) de variables cualitativas.\n\nbarplot(\n  relativo,\n  xlab = \"Accidentes\",\n  ylab = \"Frecuencia relativa\",\n  las  = 2  # rota las etiquetas del eje X para que se lean mejor\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nCada barra representa una categoría de accidente.\n\nLa altura de la barra representa la frecuencia relativa (proporción del total).\n\nlas = 2 rota las etiquetas del eje horizontal para evitar que se encimen.\n\n\n\n\n\n2.2.4 Gráfico de torta (pie chart)\nEl gráfico de torta muestra la proporción de cada categoría como una “porción” de un círculo.\n\npie(\n  relativo,\n  labels = datos1$Categoria,\n  main   = \"Accidentes de generación de energía\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nEl gráfico de torta es útil para resaltar la proporción de cada categoría.\n\nSin embargo, para comparar categorías muy parecidas entre sí, un gráfico de barras suele ser más claro.\n\n\n\n\n\n2.2.5 Diagrama de Pareto\nEl diagrama de Pareto ordena las categorías de mayor a menor frecuencia y muestra también la acumulación.\n\n# Creamos un vector nombrado: cada elemento es la frecuencia relativa,\n# y el nombre es la categoría\nrelativo2 &lt;- datos1$relativa\nnames(relativo2) &lt;- datos1$Categoria\n\n# Ajustamos márgenes del gráfico (opcional)\npar(mar = rep(4, 4))\n\npareto.chart(relativo2)\n\n\n\n\n\n\n\n\n                           \nPareto chart analysis for relativo2\n                               Frequency    Cum.Freq.   Percentage Cum.Percent.\n  Explosion de Gas            0.62222222   0.62222222  62.22222222  62.22222222\n  Colapso de mina de carbon   0.15555556   0.77777778  15.55555556  77.77777778\n  Falla Represa               0.08888889   0.86666667   8.88888889  86.66666667\n  Incendio Combustible        0.08888889   0.95555556   8.88888889  95.55555556\n  Descarga electrica          0.02222222   0.97777778   2.22222222  97.77777778\n  Reactor Nuclear             0.02222222   1.00000000   2.22222222 100.00000000\n\n\n\n\n\n\n\n\nNota\n\n\n\nEl diagrama de Pareto permite:\n\nIdentificar cuáles son las categorías más frecuentes (las más importantes).\n\nVisualizar la acumulación: por ejemplo, ver qué porcentaje del total representan las primeras 2 o 3 categorías.\n\nEsto es muy útil en gestión para aplicar el principio de 80/20:\nuna pequeña cantidad de causas suele explicar gran parte de los efectos.\n\n\n\n\n2.2.6 Ejemplo 2: Rendimiento de vehículos y estadística descriptiva\nEn este ejemplo trabajaremos con datos cuantitativos: rendimiento de vehículos medido por la EPA (Environmental Protection Agency).\nPasos principales:\n\nConvertir las unidades de rendimiento de millas/galón a km/litro.\n\nExplorar los datos con:\n\nGráfico simple.\n\nHistograma.\n\nDensidad estimada y comparación con la normal.\n\nBoxplot.\n\n\nCalcular medidas descriptivas:\n\nMedia, mediana, moda, rango, desviación estándar, coeficiente de variación.\n\n\nEvaluar la normalidad:\n\nPrueba de Shapiro-Wilk.\n\nPrueba de Kolmogorov-Smirnov.\n\nGráfico QQ.\n\nSkewness y kurtosis.\n\n\n\n\n2.2.7 Cargar los datos del Ejemplo 2\n\narchivo_ejemplo2 &lt;- file.path(ruta_datos, \"Ejemplo2.xlsx\")\n\ndatos2 &lt;- read.xlsx(\n  archivo_ejemplo2,\n  sheet    = \"Hoja1\",\n  colNames = TRUE\n)\n\nhead(datos2)\n\n  EPA_Mileage_Ratings_milla_galon\n1                            36.3\n2                            32.7\n3                            40.5\n4                            36.2\n5                            38.5\n6                            36.3\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn este archivo esperamos tener una columna llamada, por ejemplo:\n\nEPA_Mileage_Ratings_milla_galon: rendimiento en millas por galón.\n\n\n\n\n\n2.2.8 Conversión de unidades: de millas/galón a km/litro\nRecordemos las equivalencias:\n\n1 milla ≈ 1.6093 kilómetros.\n\n1 galón ≈ 3.78 litros.\n\nEntonces, el factor de conversión es:\n\\[\\text{factor} = \\frac{1.6093}{3.78}.\\]\n\nmilla &lt;- 1.6093\ngalon &lt;- 3.78\n\nfactorconversion &lt;- milla / galon\nfactorconversion\n\n[1] 0.4257407\n\n\nAplicamos este factor a la columna de rendimiento:\n\ndatos2$EPA_Mileage_Ratings_km_l &lt;- factorconversion * datos2$EPA_Mileage_Ratings_milla_galon\n\n# Resumen de la nueva variable\nsummary(datos2$EPA_Mileage_Ratings_km_l)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.77   15.19   15.75   15.75   16.32   19.12 \n\n\n\n\n\n\n\n\nTip\n\n\n\nCrear una nueva columna (en lugar de sobrescribir la original) permite:\n\nConservar las unidades originales.\n\nComparar resultados y evitar errores de interpretación.\n\n\n\n\n\n2.2.9 Gráfico simple de la serie\n\nplot(\n  datos2$EPA_Mileage_Ratings_km_l,\n  main = \"Rendimiento EPA en km/l\",\n  xlab = \"Observación\",\n  ylab = \"Rendimiento (km/l)\"\n)\n\n\n\n\n\n\n\n\nEste gráfico muestra cómo varía el rendimiento (en km/l) a lo largo de las observaciones."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#histograma-y-densidad",
    "href": "labs_epg/lab01_epg.html#histograma-y-densidad",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.3 Histograma y densidad",
    "text": "2.3 Histograma y densidad\n\n2.3.1 Histograma de frecuencias (escala de densidad)\n\nhist(\n  datos2$EPA_Mileage_Ratings_km_l,\n  main = \"Histograma de frecuencias EPA\",\n  xlab = \"Rendimiento (km/l)\",\n  freq = FALSE  # FALSE =&gt; el eje Y representa densidad, no conteos\n)\n\n\n\n\n\n\n\n\n\n\n2.3.2 Densidad estimada y comparación con la normal\n\n# Estimación de la densidad empírica\nplot(\n  density(datos2$EPA_Mileage_Ratings_km_l),\n  main = \"Densidad de frecuencias EPA\",\n  xlab = \"Rendimiento (km/l)\"\n)\n\n# Añadimos la curva de una Normal con misma media y desviación estándar\ncurve(\n  dnorm(\n    x,\n    mean = mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE),\n    sd   = sd(datos2$EPA_Mileage_Ratings_km_l,   na.rm = TRUE)\n  ),\n  add = TRUE,\n  col = \"red\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nLa curva negra representa la densidad empírica estimada a partir de los datos.\n\nLa curva roja representa una distribución normal teórica con la misma media y desviación estándar que la muestra.\n\nComparar ambas curvas nos da una idea visual de qué tan “normal” parece la distribución.\n\n\n\n\n\n2.3.3 Boxplot (gráfico de cajas)\nEl boxplot resume:\n\nMediana.\n\nCuartiles (Q1 y Q3).\n\nRango intercuartílico.\n\nPosibles valores atípicos (outliers).\n\n\nboxplot(\n  datos2$EPA_Mileage_Ratings_km_l,\n  main    = \"Gráfico de cajas 1\",\n  ylab    = \"Rendimiento (km/l)\",\n  outline = TRUE  # muestra los posibles outliers\n)\n\n\n\n\n\n\n\n\n\n\n2.3.4 Medidas descriptivas: centro y dispersión\nCalculamos:\n\nMedia.\n\nMediana.\n\nModa (usando mfv).\n\nRango.\n\nDesviación estándar.\n\nCoeficiente de variación.\n\n\nmedia   &lt;- mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\nmediana &lt;- median(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\nmoda    &lt;- mfv(datos2$EPA_Mileage_Ratings_km_l)  # most frequent value\nrango   &lt;- range(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\ndesv    &lt;- sd(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\n\ncoeficiente_variacion &lt;- desv / media\n\nmedia\n\n[1] 15.74985\n\nmediana\n\n[1] 15.75241\n\nmoda\n\n[1] 15.75241\n\nrango\n\n[1] 12.77222 19.11576\n\ndesv\n\n[1] 1.029397\n\ncoeficiente_variacion\n\n[1] 0.06535917\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nLa media es el promedio aritmético.\n\nLa mediana es el valor central de los datos ordenados.\n\nLa moda es el valor que más se repite.\n\nEl coeficiente de variación es adimensional y se interpreta como:\n\n\\[CV = \\frac{\\text{desviación estándar}}{\\text{media}}. \\]\nEs útil para comparar la variabilidad relativa entre diferentes variables."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#pruebas-de-normalidad",
    "href": "labs_epg/lab01_epg.html#pruebas-de-normalidad",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.4 Pruebas de normalidad",
    "text": "2.4 Pruebas de normalidad\nAplicamos dos pruebas clásicas de normalidad:\n\n2.4.1 Prueba de Shapiro-Wilk\n\nshapiro.test(datos2$EPA_Mileage_Ratings_km_l)\n\n\n    Shapiro-Wilk normality test\n\ndata:  datos2$EPA_Mileage_Ratings_km_l\nW = 0.98814, p-value = 0.5185\n\n\n\nH0: los datos provienen de una distribución normal.\n\nH1: los datos NO provienen de una distribución normal.\n\nSi el p-valor es menor a 0.05, rechazamos H0 y concluimos que los datos no son normales.\n\n\n2.4.2 Prueba de Kolmogorov-Smirnov\n\nks.test(\n  datos2$EPA_Mileage_Ratings_km_l,\n  pnorm,\n  mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE),\n  sd(datos2$EPA_Mileage_Ratings_km_l,   na.rm = TRUE)\n)\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  datos2$EPA_Mileage_Ratings_km_l\nD = 0.067046, p-value = 0.7597\nalternative hypothesis: two-sided\n\n\nAquí comparamos la distribución muestral con una normal teórica con:\n\nmedia = media muestral\n\ndesviación estándar = desviación estándar muestral"
  },
  {
    "objectID": "labs_epg/lab01_epg.html#simulación-de-una-distribución-normal-comparable",
    "href": "labs_epg/lab01_epg.html#simulación-de-una-distribución-normal-comparable",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.5 Simulación de una distribución normal comparable",
    "text": "2.5 Simulación de una distribución normal comparable\nGeneramos datos simulados desde una distribución normal con la misma media y desviación estándar que los datos reales, y comparamos los histogramas.\n\nset.seed(123)  # para reproducibilidad\n\ndatos_simulados &lt;- rnorm(\n  1000,\n  mean = mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE),\n  sd   = sd(datos2$EPA_Mileage_Ratings_km_l,   na.rm = TRUE)\n)\n\n# Histograma de los datos simulados\nhist(\n  datos_simulados,\n  main = \"Histograma de datos simulados (Normal)\",\n  xlab = \"Rendimiento (km/l)\"\n)\n\n\n\n\n\n\n\n# Histograma de los datos reales con curva normal\nhist(\n  datos2$EPA_Mileage_Ratings_km_l,\n  freq = FALSE,\n  main = \"Datos EPA con curva normal teórica\",\n  xlab = \"Rendimiento (km/l)\"\n)\n\ncurve(\n  dnorm(\n    x,\n    mean = mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE),\n    sd   = sd(datos2$EPA_Mileage_Ratings_km_l,   na.rm = TRUE)\n  ),\n  add = TRUE,\n  col = \"red\"\n)"
  },
  {
    "objectID": "labs_epg/lab01_epg.html#cuantiles-y-valores-teóricos",
    "href": "labs_epg/lab01_epg.html#cuantiles-y-valores-teóricos",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.6 Cuantiles y valores teóricos",
    "text": "2.6 Cuantiles y valores teóricos\nCalculamos los cuantiles (percentiles) y luego los valores teóricos de una normal para los percentiles 25% y 75% usando qnorm.\n\n# Cuantiles 0%, 25%, 50%, 75% y 100%\nquantile(\n  datos2$EPA_Mileage_Ratings_km_l,\n  prob = c(0, 0.25, 0.5, 0.75, 1),\n  na.rm = TRUE\n)\n\n      0%      25%      50%      75%     100% \n12.77222 15.18830 15.75241 16.31651 19.11576 \n\n\nAhora calculamos los valores que corresponderían al 25% y 75% bajo una distribución normal con la misma media y desviación estándar:\n\nz_0.75 &lt;- mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE) +\n  qnorm(0.75) * sd(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\n\nz_0.25 &lt;- mean(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE) +\n  qnorm(0.25) * sd(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\n\nz_0.75\n\n[1] 16.44417\n\nz_0.25\n\n[1] 15.05554"
  },
  {
    "objectID": "labs_epg/lab01_epg.html#gráfico-qq-quantile-quantile",
    "href": "labs_epg/lab01_epg.html#gráfico-qq-quantile-quantile",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.7 Gráfico QQ (quantile-quantile)",
    "text": "2.7 Gráfico QQ (quantile-quantile)\nEl gráfico QQ compara los cuantiles de los datos con los cuantiles de una normal teórica.\n\nqqnorm(datos2$EPA_Mileage_Ratings_km_l)\nqqline(datos2$EPA_Mileage_Ratings_km_l, col = \"red\")\n\n\n\n\n\n\n\n\n\nSi los puntos siguen aproximadamente la línea roja, la distribución de los datos es cercana a la normal.\n\nDesviaciones sistemáticas indican diferencias respecto a la normalidad (colas más pesadas, asimetría, etc.)."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#asimetría-skewness-y-curtosis-kurtosis",
    "href": "labs_epg/lab01_epg.html#asimetría-skewness-y-curtosis-kurtosis",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.8 Asimetría (skewness) y curtosis (kurtosis)",
    "text": "2.8 Asimetría (skewness) y curtosis (kurtosis)\nFinalmente, medimos la forma de la distribución mediante:\n\nSkewness: mide la asimetría.\n\nKurtosis: mide el “apuntamiento” o peso de las colas comparado con una normal.\n\n\nskewness(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\n\n[1] 0.05014194\n\nkurtosis(datos2$EPA_Mileage_Ratings_km_l, na.rm = TRUE)\n\n[1] 3.672556\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi skewness &gt; 0: asimetría hacia la derecha (cola más larga a la derecha).\n\nSi skewness &lt; 0: asimetría hacia la izquierda.\nPara la curtosis (definición clásica):\n\nUna distribución normal tiene kurtosis ≈ 3.\n\nSi kurtosis &gt; 3: colas más pesadas (leptocúrtica).\n\nSi kurtosis &lt; 3: colas más ligeras (platicúrtica)."
  },
  {
    "objectID": "labs_epg/lab01_epg.html#resumen-final-del-ejemplo-2",
    "href": "labs_epg/lab01_epg.html#resumen-final-del-ejemplo-2",
    "title": "Capitulo 1 Introduccion_y_Estadistica_Descriptiva",
    "section": "2.9 Resumen final del Ejemplo 2",
    "text": "2.9 Resumen final del Ejemplo 2\nEn este ejemplo aprendimos a:\n\nConvertir unidades (millas/galón → km/l).\n\nExplorar datos cuantitativos con gráficos:\n\nPlot simple, histograma, densidad, boxplot y QQ-plot.\n\n\nCalcular medidas descriptivas:\n\nMedia, mediana, moda, rango, desviación estándar, coeficiente de variación.\n\n\nEvaluar la normalidad de una variable usando:\n\nPruebas de hipótesis (Shapiro-Wilk, Kolmogorov-Smirnov).\n\nComparación visual con una distribución normal.\n\nSkewness y kurtosis.\n\n\nEstos pasos son la base para análisis más avanzados en econometría, donde suponemos frecuentemente normalidad en los errores o en ciertas variables."
  },
  {
    "objectID": "eco_eco.html",
    "href": "eco_eco.html",
    "title": "Econometría - Mención Economía",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML y PDF.\n\nIntroducción a R y pasos básicos de limpieza de datos\n\nHTML PDF\n\nRegresión lineal simple\n\nHTML PDF\n\nRegresión bivariada y transformaciones\n\nHTML PDF\n\nRegresión lineal múltiple\n\nHTML PDF\n\nSesgo por variable omitida y multicolinealidad\n\nHTML PDF\n\nVariables dummy y modelo de probabilidad lineal (MPL)\n\nHTML PDF\n\nPruebas de hipótesis individuales sobre parámetros\n\nHTML PDF\n\nPruebas conjuntas de hipótesis\n\nHTML PDF\n\nHeterocedasticidad e inferencia robusta\n\nHTML PDF"
  },
  {
    "objectID": "eco_eco.html#laboratorios",
    "href": "eco_eco.html#laboratorios",
    "title": "Econometría - Mención Economía",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML y PDF.\n\nIntroducción a R y pasos básicos de limpieza de datos\n\nHTML PDF\n\nRegresión lineal simple\n\nHTML PDF\n\nRegresión bivariada y transformaciones\n\nHTML PDF\n\nRegresión lineal múltiple\n\nHTML PDF\n\nSesgo por variable omitida y multicolinealidad\n\nHTML PDF\n\nVariables dummy y modelo de probabilidad lineal (MPL)\n\nHTML PDF\n\nPruebas de hipótesis individuales sobre parámetros\n\nHTML PDF\n\nPruebas conjuntas de hipótesis\n\nHTML PDF\n\nHeterocedasticidad e inferencia robusta\n\nHTML PDF"
  },
  {
    "objectID": "data_secundaria.html",
    "href": "data_secundaria.html",
    "title": "Datos Administrativos",
    "section": "",
    "text": "Las bases de datos agrupadas en esta sección corresponden a fuentes estadísticas complementarias que, si bien contienen una menor cantidad de variables, ofrecen información clave para desarrollar análisis econométricos enfocados y temáticamente específicos.\nIncluyen registros provenientes de distintas instituciones nacionales e internacionales —como el Banco Central de Chile, el Ministerio de Economía, el Banco Mundial, el Banco Interamericano de Desarrollo (BID) y otros organismos del Estado— que proporcionan indicadores macroeconómicos, series de precios, productividad, informalidad laboral, microemprendimiento, turismo y diversos aspectos del desarrollo económico y social.\nSi bien estas bases no tienen la amplitud de variables de las grandes encuestas sociales, su profundidad temática permite construir modelos de regresión y análisis descriptivos centrados en temas concretos, como la evolución del empleo formal e informal, la estructura de costos laborales, el comportamiento del sector agrícola o los determinantes de la actividad turística.\nPor su naturaleza más técnica, la manipulación de estas bases puede requerir un manejo intermedio o avanzado en RStudio y Excel, especialmente cuando se busca complementar distintas fuentes o realizar integraciones de series temporales. No obstante, su correcta utilización brinda la oportunidad de generar análisis aplicados y resultados interpretables que fortalecen el aprendizaje práctico de la econometría y la gestión de datos económicos.\nCada sección de datos cuenta con el mismo formato de presentacion, conteniendo las siguientes variables:"
  },
  {
    "objectID": "data_secundaria.html#buscador",
    "href": "data_secundaria.html#buscador",
    "title": "Datos Administrativos",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (“search”) que facilita la exploración, que funciona a nivel de palabras claves, por ejemplo, si se escribe “economía”, el sistema buscará esa palabra en todas las columnas de la tabla (años, siglas, nombre, enlace y descripción). Esto permite filtrar de manera rápida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "proyectos.html",
    "href": "proyectos.html",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES"
  },
  {
    "objectID": "proyectos.html#section",
    "href": "proyectos.html#section",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES"
  },
  {
    "objectID": "datos.html",
    "href": "datos.html",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\nInstituto Nacional de Estadistica, a través de su sistema INE-DATOS.\n\nse proyecta integrar información de ODEPAen el caso de queerer realizar un proyecto orientado al sector agricola y otros organismos públicos vinculados al ámbito económico, social y producitivo."
  },
  {
    "objectID": "datos.html#section",
    "href": "datos.html#section",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\nInstituto Nacional de Estadistica, a través de su sistema INE-DATOS.\n\nse proyecta integrar información de ODEPAen el caso de queerer realizar un proyecto orientado al sector agricola y otros organismos públicos vinculados al ámbito económico, social y producitivo."
  },
  {
    "objectID": "datos.html#tabla-de-bases-de-datos",
    "href": "datos.html#tabla-de-bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Tabla de bases de datos",
    "text": "Tabla de bases de datos\nDebajo encontrarás dos pestañas interactiva que contiene la siguiente información:\n\nEncuestas: Se recomienda que quienes realizan por primera vez trabajos de econometría, sin experiencia previa en RStudio y con un manejo intermedio de Excel, utilicen bases de datos provenientes de encuestas o que ya contengan múltiples variables integradas. Esto permite evitar el proceso de combinar distintas fuentes de información, lo cual podría generar errores en la manipulación y pérdida de consistencia en los datos si no se aplican las precauciones adecuadas.\nDatos Administrativos: Estos datos son útiles para desarrollar trabajos de econometría y pueden conducir a resultados interesantes; sin embargo, su manipulación presenta mayor complejidad, ya que suelen requerir la integración con otras bases de datos. Por ello, es recomendable contar con un nivel intermedio de manejo en RStudio y Excel. Si decides trabajar con información de esta sección, se sugiere consultar a los docentes del curso para asegurar una correcta gestión y procesamiento de los datos."
  },
  {
    "objectID": "datos.html#bases-de-datos",
    "href": "datos.html#bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Bases de Datos",
    "text": "Bases de Datos\n\n\nEncuestas\n\nVer Datos\n\n\nDatos Administrativos\n\nVer Datos"
  },
  {
    "objectID": "index.html#descripción-del-sitio-web",
    "href": "index.html#descripción-del-sitio-web",
    "title": "",
    "section": "Descripción del Sitio Web",
    "text": "Descripción del Sitio Web\nEste sitio web es una iniciativa conjunta de los profesores Fernando Crespo y Rocío Valdebenito, docentes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado (UAH). Está dirigido a los estudiantes de la carrera de Ingeniería Comercial, con mención en Economía y Administración de Empresas, que cursan las asignaturas de Econometría.\nEl objetivo principal de esta página es que los estudiantes se familiaricen con el uso de bases de datos y aprendan a utilizar el software R y Rstudio como herramienta para analizar y responder preguntas de investigación. Como parte fundamental del aprendizaje, los estudiantes desarrollan un proyecto aplicado, el cual es presentado en formato de póster y expuesto frente a la comunidad académica.\nPara acompañar este proceso, el sitio web se organiza en tres secciones principales:\n\nDatos:\n\n\nMaterial de Estudio:\n\n\nProyectos:\nEn conjunto, este sitio busca convertirse en un centro de recursos para la formación en econometría, promoviendo el uso de datos y herramientas de análisis como competencias clave para la futura labor profesional de los estudiantes de Ingeniería Comercial de la UAH."
  },
  {
    "objectID": "index.html#docentes-y-ayudante",
    "href": "index.html#docentes-y-ayudante",
    "title": "",
    "section": "Docentes y Ayudante",
    "text": "Docentes y Ayudante\n\nRocío Valdebenito: Docente e Investigadora\nLa Dra. Rocío Valdebenito es académica con formación y afiliación en Ingeniera Comercial y Máster en Management de la Universidad Adolfo Ibáñez (UAI) y Doctorado (Ph.D.) en Economía Aplicada de la University of Illinois at Urbana-Champaign (EE. UU., 2024). Actualmente es Profesora en la Facultad de Economía y Negocios (FEN) de la Universidad Alberto Hurtado (UAH).\n\nAmador Marin Torres: Ayudante Econometría mención Economía\nEs un estudiante de Ingeniería Comercial con Mención en Economía de la Universidad Alberto Hurtado (UAH). desempeñándose como Ayudante de Cátedra de multiples cursos a lo largo de su carrera universitaria.\n\n\n\nFernando Crespo: Docente e Investigador\nEl profesor Fernando Crespo es un experto en Ciencia de Datos, Machine Learning y Modelos Matemáticos Aplicados. Es Doctor en Ciencias de la Ingeniería por la Pontificia Universidad Católica de Chile y actualmente se desempeña como Profesor en la Universidad Alberto Hurtado.\n\nManuel Labraña Rojas: Ayudante\nManuel Labraña Rojas es un estudiante de Ingeniería Comercial con Mención en Economía de la Universidad Alberto Hurtado (UAH). desempeñándose como Ayudante de Cátedra. Además, colabora en el área de investigación como Ayudante del proyecto “Repositorio de Econometría”, contribuyendo a su funcionamiento y desarrollo web."
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Material de Estudio",
    "section": "",
    "text": "Bienvenido al Repositorio de Laboratorios y Materiales Prácticos de los cursos de Econometría FEN-UAH.\nEn este espacio encontrarás guías paso a paso desarrolladas en RStudio/Quarto, acompañadas de fundamentos teóricos y explicaciones conceptuales que facilitan el aprendizaje aplicado de la econometría, abarcando desde la regresión lineal simple hasta modelos econométricos más avanzados.\nEl material se organiza ahora en dos secciones específicas, según la mención del curso:\nCada laboratorio puede abrirse directamente en formato HTML renderizado, permitiendo revisar el código, los resultados y la interpretación de forma integrada."
  },
  {
    "objectID": "codigos.html#cursos",
    "href": "codigos.html#cursos",
    "title": "Material de Estudio",
    "section": "Cursos",
    "text": "Cursos\n\n\nEconometría Mención Economía\n\nVer Curso\n\n\nEconometría para la Gestión Mención Administración\n\nVer Curso"
  },
  {
    "objectID": "data_principal.html",
    "href": "data_principal.html",
    "title": "Encuestas",
    "section": "",
    "text": "Las bases de datos de encuestas incluidas en este repositorio reúnen información oficial y representativa de distintos ámbitos sociales y económicos de Chile, provenientes de instituciones como el Instituto Nacional de Estadísticas (INE) y el Ministerio de Desarrollo Social y Familia. Estas encuestas abarcan temas como salud, empleo, ingresos, gasto de los hogares y uso del tiempo, entre otros, permitiendo realizar análisis econométricos con un alto nivel de profundidad.\nEntre las principales se encuentran la Encuesta de Presupuestos Familiares, la Encuesta Nacional de Salud, la Encuesta de Uso del Tiempo y la Encuesta de Mercado Laboral, todas con una amplia cobertura de variables demográficas, laborales y socioeconómicas.\nEstas fuentes resultan especialmente valiosas para el desarrollo de modelos de regresión, estudios de determinantes sociales y económicos, y comparaciones entre grupos de población. Además, su estructura multidimensional permite combinar distintas áreas de análisis —como ingreso, género, educación y bienestar— fomentando una comprensión integral de la realidad económica y social del país.\nEn conjunto, estas encuestas constituyen una base sólida para el aprendizaje aplicado de la econometría, ofreciendo datos confiables y actualizados para desarrollar ejercicios, informes y proyectos con rigor estadístico.\nCada sección de datos cuenta con el mismo formato de presentacion, conteniendo las siguientes variables:"
  },
  {
    "objectID": "data_principal.html#buscador",
    "href": "data_principal.html#buscador",
    "title": "Encuestas",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (“search”) que facilita la exploración, que funciona a nivel de palabras claves, por ejemplo, si se escribe “economía”, el sistema buscará esa palabra en todas las columnas de la tabla (años, siglas, nombre, enlace y descripción). Esto permite filtrar de manera rápida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "eco_epg.html",
    "href": "eco_epg.html",
    "title": "Econometría para la Gestión",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML y PDF.\n\nCapítulo 1 – Introducción y estadística descriptiva\nHTML PDF\nCapítulo 2 – Correlación y regresión lineal simple\nHTML PDF\nCapítulo 3 – Regresión múltiple\nHTML PDF\nCapítulo 4 – Uso avanzado de la regresión múltiple\nHTML PDF\nCapítulo 5 – Logit y otros análisis\nHTML PDF\nCapítulo 6 – Componentes principales\nHTML PDF\nCapítulo 7 – Análisis factorial (PCA ampliado)\nHTML PDF"
  },
  {
    "objectID": "eco_epg.html#laboratorios",
    "href": "eco_epg.html#laboratorios",
    "title": "Econometría para la Gestión",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML y PDF.\n\nCapítulo 1 – Introducción y estadística descriptiva\nHTML PDF\nCapítulo 2 – Correlación y regresión lineal simple\nHTML PDF\nCapítulo 3 – Regresión múltiple\nHTML PDF\nCapítulo 4 – Uso avanzado de la regresión múltiple\nHTML PDF\nCapítulo 5 – Logit y otros análisis\nHTML PDF\nCapítulo 6 – Componentes principales\nHTML PDF\nCapítulo 7 – Análisis factorial (PCA ampliado)\nHTML PDF"
  },
  {
    "objectID": "labs_eco/lab01_introR.html",
    "href": "labs_eco/lab01_introR.html",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "",
    "text": "El objetivo de este laboratorio presencial es familiarizarse con R y RStudio. El laboratorio se puede realizar en grupo, pero cada estudiante debe entregar su propio trabajo. Para obtener créditos, suba su script .R al lugar correspondiente en Canvas."
  },
  {
    "objectID": "labs_eco/lab01_introR.html#primeros-pasos",
    "href": "labs_eco/lab01_introR.html#primeros-pasos",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "Primeros pasos",
    "text": "Primeros pasos\n\nAbre RStudio en tu ordenador portátil\nHaz clic en Archivo &gt; Nuevo archivo &gt; Script R.\n\nVerás una sección en blanco en la parte superior izquierda de la ventana de RStudio. Aquí es donde escribirás tu primer script R.\n\nConsola\nEn la parte inferior izquierda de la pantalla hay una pestaña llamada «Consola». Básicamente, se trata de una calculadora muy sofisticada.\nPrueba la calculadora escribiendo algo como:\n\n2+2\n\nO incluso algo más sofisticado como:\n\nsqrt(pi)\n\n\n\nPaquetes\nR hace un uso extensivo de paquetes de terceros. No entraremos en detalles ahora mismo, pero para esta clase necesitarás instalar algunos de ellos. Instalar paquetes es bastante fácil. Escribe las dos líneas de código siguientes en la parte superior de tu script:\n\ninstall.packages(\"tidyverse\", repos='http://cran.us.r-project.org')\ninstall.packages(\"modelsummary\", repos='http://cran.us.r-project.org')\ninstall.packages(\"wooldridge\", repos='http://cran.us.r-project.org')\n\nAcabas de instalar tres paquetes. Básicamente, los has descargado en tu ordenador. Al igual que con cualquier otro software de tu ordenador, solo tienes que realizar la instalación una vez. Sin embargo, aún debes indicar a R que vas a utilizar los paquetes. Añade las dos líneas de código siguientes a tu script (debajo de las dos primeras líneas que has escrito). Fíjate en que esta vez no hay comillas dentro de los paréntesis.\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(wooldridge)\n\n\n\nEjecutar un script\nPara ejecutar el script, haz clic en la palabra «Fuente» en la esquina superior derecha del panel superior izquierdo de la ventana. Esto tomará lo que hay en tu script y lo enviará automáticamente a la consola (como si lo hubieras escrito directamente en la consola).\nPara guardar el script, haga clic en el icono del disco situado en la parte superior del panel del script (pero no en el icono del disco situado en la parte superior de RStudio). Asigne al script el nombre «ICL1_XYZ.R», donde «XYZ» son sus iniciales.\n\n\nComentarios\nAhora, coloca un hashtag (#) delante de las dos primeras líneas de código de tu script, así:\n\n#install.packages(\"tidyverse\")\n#install.packages(\"modelsummary\")\n#install.packages(\"wooldridge\")\n\nEl hashtag es la forma de indicarle a R que no ejecute el código de tu script. Esto se conoce como «comentar» tu código.\nEn la parte superior de tu script, escribe tu nombre precedido de un hashtag.\nA partir de ahora, añade todo el código que veas a tu script."
  },
  {
    "objectID": "labs_eco/lab01_introR.html#explorar-datos",
    "href": "labs_eco/lab01_introR.html#explorar-datos",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "Explorar datos",
    "text": "Explorar datos\nAhora que ya conoces algunos conceptos básicos de R, ¡veamos algunos datos!\n\nCarga de datos\nVamos a cargar un conjunto de datos del paquete wooldridge. El conjunto de datos se llama wage1.\n\ndf &lt;- as_tibble(wage1)\n\nLo que hicimos allí fue convertirlo a un «tibble», que es un formato muy útil para conjuntos de datos (véase el capítulo 10 de @r4ds). Llamamos al tibble convertido «df», pero puedes llamarlo como quieras: «mydata», «data123», lo que sea.\n\n\nNavegación\nSi vuelve a ejecutar el script (haciendo clic en «Fuente»… o mejor aún, haciendo clic en la pequeña flecha situada junto a «Fuente», que abre un menú en el que puede hacer clic en «Fuente con eco»), verá algo nuevo en la ventana «Entorno» (arriba a la derecha). Dice «df» bajo el encabezado «Datos».\nHaga doble clic en «df» en la ventana Entorno. Esto le mostrará sus datos en un formato similar a una hoja de cálculo de Excel. Puede utilizar esto para examinar fácilmente los datos y asegurarse de que todo parece razonable.\n\n\nEstadísticas resumidas\nVeamos las estadísticas resumidas de una de nuestras variables. Supongamos que queremos saber: ¿Cuál es el promedio de años de educación en nuestra muestra?\n\ndatasummary_skim(df)#then look at 'educ' column\n\nEn tu script, escribe el valor de la media de «educ», precedido por un comentario (el símbolo de almohadilla).\n¿Qué fracción de la muestra está compuesta por mujeres?\n\nmean(df$female)\n# or\ndatasummary_skim(df) #then look at 'female' column\n\n\n\nVisualización\nSupongamos que desea visualizar toda la distribución de la educación. Utilizaría el siguiente código:\n\nggplot(df, aes(educ)) + geom_histogram(binwidth=1)+theme_classic()\n\nEn un comentario, escribe el valor más común de la educación (la moda de la distribución) debajo del código en tu script.\nRepite los dos fragmentos de código anteriores, pero esta vez utiliza la variable wage en lugar de la variable educ.\n\n\nCreación de una nueva variable\nSupongamos que desea añadir una nueva variable a df. Por ejemplo, la variable salario se expresa en dólares de 1976 y desea saber cuál sería el salario en dólares actuales. (Nota: el IPC implica que 1 dólar de 1976 equivale a 4,53 dólares actuales).\n\ndf &lt;- df %&gt;% mutate(realwage=wage*4.53)\nsummary(df$realwage)\ndatasummary_skim(\n  df,\n  fun_numeric = list(\n    `Unique`        = NUnique,\n    `Missing Pct.`  = PercentMissing,\n    `Mean`          = Mean,\n    `SD`            = SD,\n    `Min`           = Min,\n    `Median`        = Median,\n    `Max`           = Max\n    # NOTA: aquí NO ponemos \"Histogram\"\n  )\n)\n# then look at realwage column\n\nPuede verificar que «realwage» se ha añadido a «df» haciendo clic en la vista previa de «df» y desplazándose completamente hacia la derecha.\nPara obtener más información sobre «mutate()», consulte la sección 5.5 de @r4ds. También puede eliminar una variable escribiendo «df &lt;- df %&gt;% mutate(realwage=NULL)».\n\n\nEliminar observaciones\nSupongamos que queremos eliminar a todos los hombres de nuestros datos. (Por ejemplo, tal vez estemos investigando sobre la participación de las mujeres en la población activa). Para ello, utilizamos la función filter().\nPara utilizar filter(), debe proporcionar las condiciones para mantener una observación específica. Añada lo siguiente a su script:\n\nsummary(df$female)\ndf &lt;- df %&gt;% filter(female==1)\nsummary(df$female)\n\nLe dijimos a R que conservara las observaciones en las que «female» era igual a 1. Se puede observar que, antes de la instrucción «filter()», las mujeres representaban el 48 % de los datos. Ahora, representan el 100 %. Por lo tanto, podemos verificar que «filter()» hizo lo que le pedimos.\n\n\nValores perdidos\nUna situación habitual en los datos observacionales transversales es la pérdida de valores. Por ejemplo, alguien deja en blanco una pregunta en una encuesta. O el salario de alguien que está desempleado no está definido. En R, los valores perdidos se almacenan como «NA» (que significa «no aplicable»). Para eliminar las observaciones «NA», utilice la función «drop_na()»:\n\nsummary(df$wage)\ndf &lt;- df %&gt;% drop_na(wage)\nsummary(df$wage)"
  },
  {
    "objectID": "labs_epg/lab02_epg.html",
    "href": "labs_epg/lab02_epg.html",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos\nEl PDF “Capitulo_2_Correlacion_regresion_simple” desarrolla los siguientes temas principales (a modo de índice):\n\nCovarianza y correlación.\n\nDiagramas de dispersión.\n\nPrueba de hipótesis para la correlación.\n\nEcuaciones lineales y modelo lineal simple.\n\nMétodo de mínimos cuadrados.\n\nResiduos y error estándar de la estimación.\n\nPredicción e intervalos de confianza.\n\nCoeficiente de determinación simple (R^2).\n\nPrueba de hipótesis sobre el parámetro de pendiente (_1).\n\nEn este laboratorio llevaremos varios de estos conceptos a la práctica con R."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#carga-de-librerías",
    "href": "labs_epg/lab02_epg.html#carga-de-librerías",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "2.1 Carga de librerías",
    "text": "2.1 Carga de librerías\n\n# Cargamos las librerías necesarias para el laboratorio\nlibrary(openxlsx)  # leer archivos Excel (.xlsx)\n\n\n\n\n\n\n\nTip\n\n\n\nSi alguna librería no está instalada, puedes hacerlo con:\ninstall.packages(\"openxlsx\")"
  },
  {
    "objectID": "labs_epg/lab02_epg.html#definir-la-ruta-de-trabajo",
    "href": "labs_epg/lab02_epg.html#definir-la-ruta-de-trabajo",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "2.2 Definir la ruta de trabajo",
    "text": "2.2 Definir la ruta de trabajo\nVamos a guardar la ruta donde están los datos en un objeto llamado ruta_datos.\nAsí solo modificamos una línea si cambiamos la carpeta en el futuro.\n\n# Definimos la ruta donde están los archivos de datos del laboratorio.\n# IMPORTANTE: Ajusta esta ruta si tu carpeta tiene otro nombre o ubicación.\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\n# Podemos verificar el contenido de la carpeta (opcional)\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\"    \n\n\n\n\n\n\n\n\nNota\n\n\n\nEn R es recomendable usar / (slash) en lugar de **** en las rutas de Windows.\nPor eso escribimos \"C:/Users/manue/Desktop/...\" en lugar de \"C:Users...\"."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#lectura-de-los-datos-de-autos",
    "href": "labs_epg/lab02_epg.html#lectura-de-los-datos-de-autos",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "3.1 Lectura de los datos de autos",
    "text": "3.1 Lectura de los datos de autos\n\narchivo_autos &lt;- file.path(ruta_datos, \"auto_peso_consumo.xlsx\")\n\ndatos &lt;- read.xlsx(\n  archivo_autos,\n  sheet    = \"Hoja1\",\n  colNames = TRUE\n)\n\n# Vemos las primeras filas\nhead(datos)\n\n  Auto Peso_Libras Consumo_Millas_por_galon\n1    1        2743                     21.4\n2    2        3518                     15.2\n3    3        1855                     38.9\n4    4        5214                     12.7\n5    5        4341                     17.8\n\n\nEsperamos que el archivo contenga, al menos, las columnas:\n\nPeso_Libras\n\nConsumo_Millas_por_galon"
  },
  {
    "objectID": "labs_epg/lab02_epg.html#diagrama-de-dispersión",
    "href": "labs_epg/lab02_epg.html#diagrama-de-dispersión",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "3.2 Diagrama de dispersión",
    "text": "3.2 Diagrama de dispersión\nEl diagrama de dispersión nos permite ver visualmente si existe una relación lineal entre las variables.\n\nplot(\n  datos$Peso_Libras,\n  datos$Consumo_Millas_por_galon,\n  xlab = \"Peso (libras)\",\n  ylab = \"Consumo (millas por galón)\",\n  main = \"Relación entre peso del auto y consumo\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi al aumentar el peso el consumo (millas por galón) disminuye, la nube de puntos tendrá una forma descendente → correlación negativa.\n\nSi al aumentar el peso el consumo aumentara, veríamos una nube ascendente → correlación positiva.\n\nSi no hay patrón claro, la correlación podría ser cercana a cero."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#cálculo-de-la-correlación",
    "href": "labs_epg/lab02_epg.html#cálculo-de-la-correlación",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "3.3 Cálculo de la correlación",
    "text": "3.3 Cálculo de la correlación\nEl coeficiente de correlación de Pearson mide la intensidad y dirección de la relación lineal entre dos variables numéricas.\n\nr &lt;- cor(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\nr\n\n[1] -0.8549912\n\n\n\n\\(r\\) está entre -1 y 1.\n\n(r &lt; 0): relación negativa.\n\n(r &gt; 0): relación positiva.\n\n(|r|) cercano a 1 → relación lineal fuerte.\n\n(|r|) cercano a 0 → relación lineal débil."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#prueba-de-hipótesis-para-la-correlación-cálculo-manual",
    "href": "labs_epg/lab02_epg.html#prueba-de-hipótesis-para-la-correlación-cálculo-manual",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "3.4 Prueba de hipótesis para la correlación (cálculo manual)",
    "text": "3.4 Prueba de hipótesis para la correlación (cálculo manual)\nEn la teoría se plantea la prueba:\n\\[\nH_0: \\rho = 0 \\quad \\text{vs} \\quad H_1: \\rho \\neq 0\n\\]\nLa idea es ver si la correlación poblacional () podría ser cero o no.\nEn el script se calcula el error estándar del coeficiente de correlación y luego el estadístico t:\n\n# Cálculo manual basado en la fórmula del error estándar de r\nsr &lt;- sqrt((1 - r) / 3)   # comentario original: n número de datos menos 2\n\nt &lt;- r / sr               # estadístico t aproximado\n\nt\n\n[1] -1.087305\n\n\nLuego se calcula el valor crítico y el p-valor usando la distribución t de Student:\n\nc &lt;- qt(0.025, 3, lower.tail = FALSE)  # valor crítico (cola superior)\nc\n\n[1] 3.182446\n\n# p-valor aproximado\npt(-t, 3, lower.tail = FALSE)\n\n[1] 0.1782267\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi el p-valor es pequeño (por ejemplo, menor que 0.05), rechazamos (H_0) y concluimos que la correlación es significativamente distinta de cero.\n\nSi el p-valor es grande, no tenemos evidencia suficiente para afirmar que exista correlación lineal distinta de cero."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#prueba-de-hipótesis-para-la-correlación-con-cor.test",
    "href": "labs_epg/lab02_epg.html#prueba-de-hipótesis-para-la-correlación-con-cor.test",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "3.5 Prueba de hipótesis para la correlación con cor.test",
    "text": "3.5 Prueba de hipótesis para la correlación con cor.test\nEn lugar de hacer todos los cálculos “a mano”, R nos ofrece la función cor.test, que:\n\nCalcula el coeficiente de correlación.\n\nRealiza la prueba de hipótesis.\n\nEntrega el p-valor y un intervalo de confianza para ().\n\n\ncor.test(datos$Peso_Libras, datos$Consumo_Millas_por_galon)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos$Peso_Libras and datos$Consumo_Millas_por_galon\nt = -2.8553, df = 3, p-value = 0.06483\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9902684  0.1110238\nsample estimates:\n       cor \n-0.8549912 \n\n\n\n\n\n\n\n\nTip\n\n\n\nSiempre que sea posible, conviene verificar los resultados manuales con funciones integradas como cor.test, ya que éstas manejan bien detalles como el tamaño de muestra, grados de libertad y supuestos."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#lectura-de-los-datos-de-mantenimiento",
    "href": "labs_epg/lab02_epg.html#lectura-de-los-datos-de-mantenimiento",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.1 Lectura de los datos de mantenimiento",
    "text": "4.1 Lectura de los datos de mantenimiento\n\narchivo_mant &lt;- file.path(ruta_datos, \"annos_mantenimiento.xlsx\")\n\ndatos2 &lt;- read.xlsx(\n  archivo_mant,\n  sheet    = \"Hoja1\",\n  colNames = TRUE\n)\n\nhead(datos2)\n\n  Bus Costo_Mantenimiento Tiempo_operacion\n1   1                 859                8\n2   2                 682                5\n3   3                 471                3\n4   4                 708                9\n5   5                1094               11\n6   6                 224                2\n\n\nEsperamos las columnas:\n\nTiempo_operacion\n\nCosto_Mantenimiento"
  },
  {
    "objectID": "labs_epg/lab02_epg.html#diagrama-de-dispersión-1",
    "href": "labs_epg/lab02_epg.html#diagrama-de-dispersión-1",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.2 Diagrama de dispersión",
    "text": "4.2 Diagrama de dispersión\n\nplot(\n  datos2$Tiempo_operacion,\n  datos2$Costo_Mantenimiento,\n  xlab = \"Tiempo de operación (años)\",\n  ylab = \"Costo de mantenimiento (unidades monetarias)\",\n  main = \"Relación entre tiempo de operación y costo de mantenimiento\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEste gráfico permite ver si al aumentar los años de operación los costos de mantenimiento tienden a subir.\nSi la nube de puntos sugiere una recta ascendente, tiene sentido ajustar un modelo lineal."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#cálculo-de-la-correlación-y-prueba-de-hipótesis",
    "href": "labs_epg/lab02_epg.html#cálculo-de-la-correlación-y-prueba-de-hipótesis",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.3 Cálculo de la correlación y prueba de hipótesis",
    "text": "4.3 Cálculo de la correlación y prueba de hipótesis\n\nr &lt;- cor(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\nr\n\n[1] 0.9376733\n\n\nNuevamente, calculamos el error estándar y el estadístico t de forma manual (siguiendo la lógica del script original):\n\nsr &lt;- sqrt((1 - r) / 7)  # comentario original: aquí se usa 7 como \"n - 2\"\n\nt &lt;- r / sr\nt\n\n[1] 9.937184\n\n\nSe podría obtener un valor crítico (aunque en el script se reutiliza un valor con 3 grados de libertad), y luego:\n\ncor.test(datos2$Tiempo_operacion, datos2$Costo_Mantenimiento)\n\n\n    Pearson's product-moment correlation\n\ndata:  datos2$Tiempo_operacion and datos2$Costo_Mantenimiento\nt = 7.1388, df = 7, p-value = 0.0001872\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7250800 0.9870994\nsample estimates:\n      cor \n0.9376733 \n\n\n\n\n\n\n\n\nTip\n\n\n\ncor.test es la forma recomendada de hacer la prueba de hipótesis para la correlación, ya que usa la fórmula teórica correcta y ajusta automáticamente los grados de libertad."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#ajuste-del-modelo-de-regresión-lineal-simple",
    "href": "labs_epg/lab02_epg.html#ajuste-del-modelo-de-regresión-lineal-simple",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.4 Ajuste del modelo de regresión lineal simple",
    "text": "4.4 Ajuste del modelo de regresión lineal simple\nPlanteamos el modelo:\n\\[\\text{Costo\\_Mantenimiento} = \\beta_0 + \\beta_1 \\cdot \\text{Tiempo\\_operacion} + \\varepsilon\\]\nLo estimamos con lm:\n\nmodelo &lt;- lm(Costo_Mantenimiento ~ Tiempo_operacion, data = datos2)\n\nsummary(modelo)\n\n\nCall:\nlm(formula = Costo_Mantenimiento ~ Tiempo_operacion, data = datos2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-138.47 -124.55   40.88   83.45  119.21 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       208.203     75.002   2.776 0.027457 *  \nTiempo_operacion   70.918      9.934   7.139 0.000187 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 111.6 on 7 degrees of freedom\nMultiple R-squared:  0.8792,    Adjusted R-squared:  0.862 \nF-statistic: 50.96 on 1 and 7 DF,  p-value: 0.0001872\n\n\nEl output de summary(modelo) incluye:\n\nEstimaciones de (_0) (intercepto) y (_1) (pendiente).\n\nError estándar de cada coeficiente.\n\nEstadístico t y p-valor para probar si los coeficientes son distintos de cero.\n\n(R^2): porcentaje de variabilidad en el costo explicado por el tiempo de operación.\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi el p-valor asociado a la pendiente (_1) es pequeño (ej. &lt; 0.05), concluimos que el tiempo de operación es un buen predictor del costo de mantenimiento.\n\nUn (R^2) alto indica que el modelo lineal explica gran parte de la variabilidad del costo."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#predicción-para-5-años-de-operación",
    "href": "labs_epg/lab02_epg.html#predicción-para-5-años-de-operación",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.5 Predicción para 5 años de operación",
    "text": "4.5 Predicción para 5 años de operación\nSupongamos que queremos predecir el costo de mantenimiento para un bus con 5 años de operación.\n\nnuevo &lt;- data.frame(Tiempo_operacion = c(5))  # valor donde evaluamos el modelo\n\nvalor_predicho &lt;- predict(object = modelo, newdata = nuevo)\n\nvalor_predicho\n\n      1 \n562.794 \n\n\nEste es el valor esperado de costo de mantenimiento según el modelo lineal."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#análisis-de-residuos",
    "href": "labs_epg/lab02_epg.html#análisis-de-residuos",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.6 Análisis de residuos",
    "text": "4.6 Análisis de residuos\nLos residuos son las diferencias entre los valores observados y los valores ajustados por el modelo:\n\\[ \\hat{\\varepsilon}_i = y_i - \\hat{y}_i \\]\n\n# Vector de residuos\nmodelo$residuals\n\n         1          2          3          4          5          6          7 \n  83.45158  119.20599   50.04225 -138.46655  105.69718 -126.03961   40.87852 \n         8          9 \n-124.54842  -10.22095 \n\n# Histograma de residuos\nhist(\n  modelo$residuals,\n  main = \"Histograma de residuos\",\n  xlab = \"Residuo\"\n)\n\n\n\n\n\n\n\n# Densidad de los residuos\nplot(\n  density(modelo$residuals),\n  main = \"Densidad de residuos\",\n  xlab = \"Residuo\"\n)\n\n\n\n\n\n\n\n# Media de los residuos\nmean(modelo$residuals)\n\n[1] -2.368187e-15\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nEn un buen modelo lineal, los residuos deberían:\n\nTener media cercana a cero.\n\nNo mostrar patrones sistemáticos.\n\nAproximarse a una distribución normal (especialmente importante para los intervalos de confianza).\n\n\nEl histograma y la densidad ayudan a evaluar visualmente estas propiedades."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#cálculo-del-error-estándar-de-la-estimación-s_yx",
    "href": "labs_epg/lab02_epg.html#cálculo-del-error-estándar-de-la-estimación-s_yx",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.7 Cálculo del error estándar de la estimación (s_{y,x})",
    "text": "4.7 Cálculo del error estándar de la estimación (s_{y,x})\nEl script calcula manualmente el error estándar de la estimación a partir de los residuos:\n\\[ s_{y,x} = \\sqrt{\\frac{\\sum \\hat{\\varepsilon}_i^2}{n - 2}} \\]\n\ns_yx &lt;- sqrt(sum(modelo$residuals^2) / 7)  # aquí se usa 7 como \"n - 2\"\ns_yx\n\n[1] 111.6097\n\n\nEste valor mide la dispersión típica de los puntos alrededor de la recta de regresión."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#intervalo-de-predicción-para-un-valor-individual-x_0-5",
    "href": "labs_epg/lab02_epg.html#intervalo-de-predicción-para-un-valor-individual-x_0-5",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.8 Intervalo de predicción para un valor individual (x_0 = 5)",
    "text": "4.8 Intervalo de predicción para un valor individual (x_0 = 5)\nPara un valor específico (x_0 = 5), el error estándar de la predicción se calcula (según la teoría) como:\n\\[ s_{\\hat{y}x} = s_{y,x}\n\\sqrt{1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}}\n\\]\nEl script implementa esto en varios pasos.\n\nraiz &lt;- sqrt(\n  1 +\n    1 / 9 +\n    (5 - mean(datos2$Tiempo_operacion))^2 /\n      sum((datos2$Tiempo_operacion - mean(datos2$Tiempo_operacion))^2)\n)\n\ns_hatyx &lt;- s_yx * raiz\ns_hatyx\n\n[1] 118.6576\n\n\nLuego se obtiene el valor crítico t y se calculan los límites del intervalo de predicción:\n\nt_crit &lt;- qt(0.025, 7, lower.tail = FALSE)  # valor crítico t para 95%\n\nlim_sup &lt;- valor_predicho + t_crit * s_hatyx\nlim_inf &lt;- valor_predicho - t_crit * s_hatyx\n\nlim_inf\n\n       1 \n282.2134 \n\nlim_sup\n\n       1 \n843.3746 \n\n\n\n\n\n\n\n\nNota\n\n\n\n\nEste intervalo responde a la pregunta:\n&gt; “¿En qué rango esperamos que caiga un nuevo costo de mantenimiento individual para un bus con 5 años de operación, con un 95% de confianza?”\n\nEs más ancho que el intervalo para la media porque incluye la variabilidad individual."
  },
  {
    "objectID": "labs_epg/lab02_epg.html#intervalo-de-confianza-para-la-media-del-costo-cuando-x_0-5",
    "href": "labs_epg/lab02_epg.html#intervalo-de-confianza-para-la-media-del-costo-cuando-x_0-5",
    "title": "Capitulo 2 Correlación y Regresión Simple",
    "section": "4.9 Intervalo de confianza para la media del costo cuando (x_0 = 5)",
    "text": "4.9 Intervalo de confianza para la media del costo cuando (x_0 = 5)\nSi en lugar de un valor individual queremos estimar la media poblacional del costo para buses con 5 años de operación, el error estándar es:\n\\[ s_{\\hat{\\mu}x} = s_{y,x}\n\\sqrt{\\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}} \\] En el script:\n\nraiz1 &lt;- sqrt(\n  1 / 9 +\n    (5 - mean(datos2$Tiempo_operacion))^2 /\n      sum((datos2$Tiempo_operacion - mean(datos2$Tiempo_operacion))^2)\n)\n\ns_hatmux &lt;- s_yx * raiz1\ns_hatmux\n\n[1] 40.28504\n\n\nSin embargo, una forma más directa es usar predict con interval = \"confidence\":\n\nvalor_predicho_conf &lt;- predict(\n  object = modelo,\n  newdata = nuevo,\n  interval = \"confidence\"  # intervalo de confianza para la media\n)\n\nvalor_predicho_conf\n\n      fit     lwr     upr\n1 562.794 467.535 658.053\n\n\n\n\n\n\n\n\nTip\n\n\n\n\ninterval = \"confidence\": intervalo de confianza para la media del costo en (x_0).\n\ninterval = \"prediction\": intervalo de predicción para un nuevo valor individual."
  },
  {
    "objectID": "labs_epg/lab04_epg.html",
    "href": "labs_epg/lab04_epg.html",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#carga-de-librerías",
    "href": "labs_epg/lab04_epg.html#carga-de-librerías",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "2.1 Carga de librerías",
    "text": "2.1 Carga de librerías\n\nlibrary(openxlsx)\nlibrary(MASS)      # funciones adicionales para modelos lineales\nlibrary(corrplot)  # correlaciones gráficas\nlibrary(lmtest)    # pruebas como Durbin-Watson, Breusch-Pagan\nlibrary(ggplot2)   # gráficos avanzados"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#definir-ruta-de-trabajo",
    "href": "labs_epg/lab04_epg.html#definir-ruta-de-trabajo",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "2.2 Definir ruta de trabajo",
    "text": "2.2 Definir ruta de trabajo\nEn tu proyecto utilizaremos la ruta:\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\n# Verificamos que la carpeta exista y revisamos algunos archivos\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\"    \n\n\n\n\n\n\n\n\nTip\n\n\n\nSi copias este laboratorio a otro computador, solo deberás cambiar la ruta de ruta_datos para que apunte a la nueva carpeta donde estén millaje.txt y otros archivos de datos."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#crear-el-conjunto-de-datos",
    "href": "labs_epg/lab04_epg.html#crear-el-conjunto-de-datos",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.1 Crear el conjunto de datos",
    "text": "3.1 Crear el conjunto de datos\nEl script genera los vectores directamente en R y luego los combina en un data.frame:\n\ntv &lt;- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7,\n         23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2,\n         228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6,\n         95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1,\n         175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9,\n         7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5,\n         139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5,\n         5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3,\n         109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7,\n         135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4,\n         225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3,\n         18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2,\n         8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5,\n         104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3,\n         187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2,\n         234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9,\n         248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0,\n         139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2,\n         177.0, 283.6, 232.1)\n\nradio &lt;- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0,\n           35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9,\n           12.6, 3.5, 29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1,\n           43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5,\n           15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5,\n           2.0, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3,\n           33.0, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5,\n           43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14.0, 31.6,\n           3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11.0, 0.3,\n           0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3, 0.8, 36.9, 16.0,\n           26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0, 39.6, 2.9,\n           27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2, 5.7,\n           14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6,\n           43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2,\n           23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0,\n           2.6, 5.4, 5.7, 43.0, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8,\n           4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6)\n\nperiodico &lt;- c(69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2,\n               4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5,\n               49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0,\n               0.3, 7.4, 8.5, 5.0, 45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3,\n               31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0,\n               41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2,\n               11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4,\n               23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2, 73.4, 51.4,\n               9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8,\n               100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2,\n               2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6,\n               12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6,\n               8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9.0, 8.7,\n               44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3,\n               45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6,\n               6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6,\n               8.3, 27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0,\n               31.6, 3.6, 6.0, 13.8, 8.1, 6.4, 66.2, 8.7)\n\nventas &lt;- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4,\n            9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5,\n            9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8,\n            25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2,\n            14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4,\n            8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4,\n            8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6,\n            21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9,\n            11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7,\n            5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6,\n            15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7,\n            5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4,\n            11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6,\n            3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0,\n            12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8,\n            12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8,\n            9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4)\n\ndatos &lt;- data.frame(tv, radio, periodico, ventas)\nhead(datos)\n\n     tv radio periodico ventas\n1 230.1  37.8      69.2   22.1\n2  44.5  39.3      45.1   10.4\n3  17.2  45.9      69.3    9.3\n4 151.5  41.3      58.5   18.5\n5 180.8  10.8      58.4   12.9\n6   8.7  48.9      75.0    7.2"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#correlaciones-y-multicolinealidad",
    "href": "labs_epg/lab04_epg.html#correlaciones-y-multicolinealidad",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.2 Correlaciones y multicolinealidad",
    "text": "3.2 Correlaciones y multicolinealidad\nPrimero, miramos las correlaciones entre variables:\n\npairs(datos)\n\n\n\n\n\n\n\nr &lt;- cor(datos)\nr\n\n                  tv      radio  periodico    ventas\ntv        1.00000000 0.05480866 0.05664787 0.7822244\nradio     0.05480866 1.00000000 0.35410375 0.5762226\nperiodico 0.05664787 0.35410375 1.00000000 0.2282990\nventas    0.78222442 0.57622257 0.22829903 1.0000000\n\ncorrplot(r, method=\"circle\", type=\"lower\", diag=FALSE,\n         tl.col=\"black\", tl.cex=0.8, tl.srt=45)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nInterpretación:\n\nLa columna ventas te muestra cómo se relaciona la variable respuesta con cada medio.\n\nSi dos regresores (por ejemplo, tv y radio) tienen correlación muy alta, podría haber multicolinealidad.\n\nEl corrplot ayuda a ver estas relaciones de forma más clara que solo con la matriz numérica."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelo-con-las-tres-variables",
    "href": "labs_epg/lab04_epg.html#modelo-con-las-tres-variables",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.3 Modelo con las tres variables",
    "text": "3.3 Modelo con las tres variables\nAjustamos el modelo completo:\n\\[\n\\text{ventas} = \\beta_0 + \\beta_1 \\text{tv} + \\beta_2 \\text{radio} + \\beta_3 \\text{periodico} + \\varepsilon\n\\]\n\nmodelo_full &lt;- lm(ventas ~ tv + radio + periodico, data = datos)\nsummary(modelo_full)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + periodico, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\ntv           0.045765   0.001395  32.809   &lt;2e-16 ***\nradio        0.188530   0.008611  21.893   &lt;2e-16 ***\nperiodico   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNota\n\n\n\nMira especialmente:\n\nEl p-value de cada coeficiente → te indica si esa variable es significativa.\n\nEl p-value de la prueba F → si el modelo completo explica significativamente a ventas.\n\nEl R^2 y R^2 ajustado → qué porcentaje de la variación se explica por los regresores."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelo-sin-variable-no-significativa",
    "href": "labs_epg/lab04_epg.html#modelo-sin-variable-no-significativa",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.4 Modelo sin variable no significativa",
    "text": "3.4 Modelo sin variable no significativa\nSi el coeficiente de periodico no es significativo, podemos intentar un modelo más parsimonioso:\n\nmodelo &lt;- lm(ventas ~ tv + radio, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7977 -0.8752  0.2422  1.1708  2.8328 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\ntv           0.04575    0.00139  32.909   &lt;2e-16 ***\nradio        0.18799    0.00804  23.382   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.681 on 197 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 \nF-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nTip\n\n\n\nEliminar variables no significativas:\n\nSimplifica la interpretación.\n\nPuede mejorar la capacidad predictiva fuera de muestra.\n\nSiempre es recomendable comparar modelos (por ejemplo, con ANOVA o criterios de información)."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#superficie-de-regresión-en-3d",
    "href": "labs_epg/lab04_epg.html#superficie-de-regresión-en-3d",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.5 Superficie de regresión en 3D",
    "text": "3.5 Superficie de regresión en 3D\nComo ahora el modelo solo depende de tv y radio, podemos visualizar la “superficie de regresión” y cómo se ubican los datos alrededor de ella.\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\n\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2],\n                            length.out = 20)\n\npredicciones &lt;- outer(\n  X = nuevos_valores_tv,\n  Y = nuevos_valores_radio, \n  FUN = function(tv, radio) {\n    predict(object = modelo, newdata = data.frame(tv, radio))\n  }\n)\n\nsuperficie &lt;- persp(\n  x = nuevos_valores_tv,\n  y = nuevos_valores_radio,\n  z = predicciones,\n  theta = 18, phi = 20,\n  col = \"lightblue\", shade = 0.1,\n  xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n  ticktype = \"detailed\",\n  main = \"Predicción ventas ~ tv + radio\"\n)\n\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo), superficie)\n\npoints(observaciones, col = \"red\", pch = 16)\nsegments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nLos puntos rojos son las observaciones reales.\n\nLas líneas verticales muestran la distancia entre la superficie de predicción y los datos → son los errores del modelo.\n\nSi las líneas son pequeñas, el ajuste es bueno."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#análisis-de-residuos-del-modelo-reducido",
    "href": "labs_epg/lab04_epg.html#análisis-de-residuos-del-modelo-reducido",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.6 Análisis de residuos del modelo reducido",
    "text": "3.6 Análisis de residuos del modelo reducido\n\nshapiro.test(modelo$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo$residuals\nW = 0.91804, p-value = 4.19e-09\n\nhist(modelo$residuals, main=\"Histograma de residuos\", xlab=\"Residuo\")\n\n\n\n\n\n\n\nplot(density(modelo$residuals), main=\"Densidad de residuos\", xlab=\"Residuo\")\n\n\n\n\n\n\n\n\nPruebas de autocorrelación y heterocedasticidad:\n\ndwtest(modelo, alternative =\"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0808, p-value = 0.5656\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 4.8093, df = 2, p-value = 0.0903\n\n\nGráfico de valores reales vs estimados:\n\nplot(modelo$fitted.values, datos$ventas,\n     xlab = \"Ventas estimadas\", ylab = \"Ventas reales\",\n     main = \"Ventas reales vs estimadas (modelo sin periodico)\")\nlines(c(0, 25), c(0, 25), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi los puntos se alinean alrededor de la diagonal roja → el modelo predice razonablemente bien.\n\nDesviaciones sistemáticas o patrones curvos indicarían que falta estructura (no linealidad, interacciones, etc.)."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#incorporar-una-interacción-tv-radio",
    "href": "labs_epg/lab04_epg.html#incorporar-una-interacción-tv-radio",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.7 Incorporar una interacción tv * radio",
    "text": "3.7 Incorporar una interacción tv * radio\nAhora probamos un modelo donde el efecto de la TV depende del nivel de radio (y viceversa).\n\ntv_radio &lt;- tv * radio\n\nmodelo_interaccion &lt;- lm(ventas ~ tv + radio + tv:radio, data = datos)\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + tv:radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***\ntv          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \ntv:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\n\nAnalizamos los residuos del nuevo modelo:\n\nshapiro.test(modelo_interaccion$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion$residuals\nW = 0.8469, p-value = 3.047e-13\n\nhist(modelo_interaccion$residuals, main=\"Histograma residuos modelo interacción\")\n\n\n\n\n\n\n\nplot(density(modelo_interaccion$residuals),\n     main=\"Densidad residuos modelo interacción\", xlab=\"Residuo\")\n\n\n\n\n\n\n\ndwtest(modelo_interaccion, alternative =\"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion\nDW = 2.2236, p-value = 0.1103\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo_interaccion)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion\nBP = 14.324, df = 3, p-value = 0.002495\n\n\nVentas reales vs estimadas con interacción:\n\nplot(modelo_interaccion$fitted.values, datos$ventas,\n     xlab = \"Ventas estimadas\",\n     ylab = \"Ventas reales\",\n     main = \"Ventas reales vs estimadas (modelo con interacción)\")\nlines(c(0, 25), c(0, 25), col = \"red\", lwd = 2)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#superficie-del-modelo-con-interacción",
    "href": "labs_epg/lab04_epg.html#superficie-del-modelo-con-interacción",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.8 Superficie del modelo con interacción",
    "text": "3.8 Superficie del modelo con interacción\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\n\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(\n  X = nuevos_valores_tv,\n  Y = nuevos_valores_radio, \n  FUN = function(tv, radio) {\n    predict(object = modelo_interaccion,\n            newdata = data.frame(tv, radio))\n  }\n)\n\nsuperficie &lt;- persp(\n  x = nuevos_valores_tv,\n  y = nuevos_valores_radio,\n  z = predicciones,\n  theta = 18, phi = 20,\n  col = \"lightblue\", shade = 0.1,\n  xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n  ticktype = \"detailed\",\n  main = \"Predicción ventas ~ tv + radio + tv:radio\"\n)\n\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo_interaccion), superficie)\n\npoints(observaciones, col = \"red\", pch = 16)\nsegments(observaciones$x, observaciones$y, error$x, error$y)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#comparación-de-modelos-con-anova",
    "href": "labs_epg/lab04_epg.html#comparación-de-modelos-con-anova",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.9 Comparación de modelos con ANOVA",
    "text": "3.9 Comparación de modelos con ANOVA\nComparamos el modelo sin interacción y el modelo con interacción:\n\nanova(modelo, modelo_interaccion)\n\nAnalysis of Variance Table\n\nModel 1: ventas ~ tv + radio\nModel 2: ventas ~ tv + radio + tv:radio\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    197 556.91                                  \n2    196 174.48  1    382.43 429.59 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi la prueba ANOVA da un p-value pequeño, la interacción aporta información estadísticamente significativa.\n\nAdemás de la significancia, es importante revisar residuos y lógica económica del modelo."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelo-con-interacción-y-término-cuadrático-en-tv",
    "href": "labs_epg/lab04_epg.html#modelo-con-interacción-y-término-cuadrático-en-tv",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "3.10 Modelo con interacción y término cuadrático en tv",
    "text": "3.10 Modelo con interacción y término cuadrático en tv\nProbamos un modelo más flexible:\n\\[\n\\text{ventas} = \\beta_0 + \\beta_1 \\text{tv} + \\beta_2 \\text{radio} + \\beta_3 \\text{tv}^2 + \\beta_4 (\\text{tv}\\cdot\\text{radio}) + \\varepsilon\n\\]\n\nmodelo_interaccion_1 &lt;- lm(ventas ~ tv + radio + I(tv^2) + tv:radio, data = datos)\nsummary(modelo_interaccion_1)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + I(tv^2) + tv:radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9949 -0.2969 -0.0066  0.3798  1.1686 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.137e+00  1.927e-01  26.663  &lt; 2e-16 ***\ntv           5.092e-02  2.232e-03  22.810  &lt; 2e-16 ***\nradio        3.516e-02  5.901e-03   5.959 1.17e-08 ***\nI(tv^2)     -1.097e-04  6.893e-06 -15.920  &lt; 2e-16 ***\ntv:radio     1.077e-03  3.466e-05  31.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6238 on 195 degrees of freedom\nMultiple R-squared:  0.986, Adjusted R-squared:  0.9857 \nF-statistic:  3432 on 4 and 195 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_interaccion_1$fitted.values, datos$ventas,\n     xlab = \"Ventas estimadas\", ylab = \"Ventas reales\",\n     main = \"Ventas reales vs estimadas (modelo con tv^2 e interacción)\")\nlines(c(0, 27), c(0, 27), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nhist(modelo_interaccion_1$residuals, main=\"Histograma residuos modelo_interaccion_1\")\n\n\n\n\n\n\n\nplot(density(modelo_interaccion_1$residuals),\n     main=\"Densidad residuos modelo_interaccion_1\")\n\n\n\n\n\n\n\nshapiro.test(modelo_interaccion_1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion_1$residuals\nW = 0.80888, p-value = 6.359e-15\n\ndwtest(modelo_interaccion_1, alternative =\"two.sided\", iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion_1\nDW = 2.204, p-value = 0.1432\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo_interaccion_1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion_1\nBP = 19.986, df = 4, p-value = 0.0005027"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#cargar-los-datos-de-millaje",
    "href": "labs_epg/lab04_epg.html#cargar-los-datos-de-millaje",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.1 Cargar los datos de millaje",
    "text": "4.1 Cargar los datos de millaje\n\narchivo_millaje &lt;- file.path(ruta_datos, \"millaje.txt\")\n\nmillaje &lt;- read.table(file = archivo_millaje, header = TRUE)\nhead(millaje)\n\n   mpg  sp   wt vol hp\n1 65.4  96 17.5  89 49\n2 56.0  97 20.0  92 55\n3 55.9  97 20.0  92 55\n4 49.0 105 20.0  92 70\n5 46.5  96 20.0  92 53\n6 46.2 105 20.0  89 70"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#correlaciones-y-gráficos",
    "href": "labs_epg/lab04_epg.html#correlaciones-y-gráficos",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.2 Correlaciones y gráficos",
    "text": "4.2 Correlaciones y gráficos\n\nr_auto &lt;- cor(millaje)\nr_auto\n\n           mpg          sp         wt         vol          hp\nmpg  1.0000000 -0.68844623 -0.9050849 -0.36861368 -0.78985635\nsp  -0.6884462  1.00000000  0.6785339 -0.04306242  0.96654517\nwt  -0.9050849  0.67853388  1.0000000  0.38495423  0.83222021\nvol -0.3686137 -0.04306242  0.3849542  1.00000000  0.07647905\nhp  -0.7898564  0.96654517  0.8322202  0.07647905  1.00000000\n\npairs(millaje)\n\n\n\n\n\n\n\ncorrplot(r_auto, method=\"circle\", type=\"lower\", diag=FALSE,\n         tl.col=\"black\", tl.cex=0.8, tl.srt=45)\n\n\n\n\n\n\n\n\nGráfico simple de mpg vs hp:\n\nplot(\n  x = millaje$hp,\n  y = millaje$mpg,\n  main = \"Consumo vs potencia motor\",\n  xlab = \"hp (potencia)\",\n  ylab = \"mpg (millas por galón)\",\n  pch = 20,\n  col = \"grey\"\n)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelo-lineal-simple-en-hp-y-vol",
    "href": "labs_epg/lab04_epg.html#modelo-lineal-simple-en-hp-y-vol",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.3 Modelo lineal simple en hp y vol",
    "text": "4.3 Modelo lineal simple en hp y vol\n\nmodelo_lineal &lt;- lm(mpg ~ hp + vol, data = millaje)\nsummary(modelo_lineal)\n\n\nCall:\nlm(formula = mpg ~ hp + vol, data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.556  -3.411  -0.687   2.736  21.058 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 63.40255    2.91066  21.783  &lt; 2e-16 ***\nhp          -0.13485    0.01052 -12.818  &lt; 2e-16 ***\nvol         -0.13993    0.02698  -5.187 1.61e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.366 on 79 degrees of freedom\nMultiple R-squared:  0.7194,    Adjusted R-squared:  0.7123 \nF-statistic: 101.3 on 2 and 79 DF,  p-value: &lt; 2.2e-16\n\n\nVisualizamos la recta de regresión en función de hp (manteniendo fijo vol en el promedio, de manera implícita):\n\nplot(\n  x = millaje$hp,\n  y = millaje$mpg,\n  main = \"Consumo vs potencia motor (modelo lineal)\",\n  xlab = \"hp\",\n  ylab = \"mpg\",\n  pch  = 20,\n  col  = \"grey\"\n)\nabline(modelo_lineal, lwd = 3, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEste gráfico es más ilustrativo que riguroso (porque el modelo usa también vol), pero sirve para visualizar la tendencia lineal negativa: a mayor hp, menor mpg."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelo-polinomial-cuadrático",
    "href": "labs_epg/lab04_epg.html#modelo-polinomial-cuadrático",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.4 Modelo polinomial cuadrático",
    "text": "4.4 Modelo polinomial cuadrático\nAhora permitimos una relación no lineal entre hp y mpg:\n\nmodelo_pol2 &lt;- lm(mpg ~ vol + hp + I(hp^2), data = millaje)\nsummary(modelo_pol2)\n\n\nCall:\nlm(formula = mpg ~ vol + hp + I(hp^2), data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4677 -2.9686 -0.6293  2.3102 15.0791 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 73.3557314  2.8205235  26.008  &lt; 2e-16 ***\nvol         -0.0546235  0.0255711  -2.136   0.0358 *  \nhp          -0.4115233  0.0436316  -9.432 1.57e-14 ***\nI(hp^2)      0.0008294  0.0001283   6.466 8.01e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.357 on 78 degrees of freedom\nMultiple R-squared:  0.8173,    Adjusted R-squared:  0.8103 \nF-statistic: 116.3 on 3 and 78 DF,  p-value: &lt; 2.2e-16\n\nmodelo_cuadratico &lt;- lm(mpg ~ poly(hp, 2), data = millaje)\nsummary(modelo_cuadratico)\n\n\nCall:\nlm(formula = mpg ~ poly(hp, 2), data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.2059 -3.3067 -0.4611  2.4724 14.3716 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   33.7817     0.4919  68.674  &lt; 2e-16 ***\npoly(hp, 2)1 -71.1198     4.4545 -15.966  &lt; 2e-16 ***\npoly(hp, 2)2  38.4953     4.4545   8.642 4.87e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.454 on 79 degrees of freedom\nMultiple R-squared:  0.8067,    Adjusted R-squared:  0.8018 \nF-statistic: 164.8 on 2 and 79 DF,  p-value: &lt; 2.2e-16\n\n\nComparación gráfico predicho vs real:\n\nplot(modelo_pol2$fitted.values, millaje$mpg,\n     xlab = \"mpg estimado\", ylab = \"mpg real\",\n     main = \"Ajuste modelo polinomial (grado 2)\")\nlines(c(10, 60), c(10, 60), col = \"red\", lwd = 2)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#análisis-de-residuos-del-modelo-polinomial",
    "href": "labs_epg/lab04_epg.html#análisis-de-residuos-del-modelo-polinomial",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.5 Análisis de residuos del modelo polinomial",
    "text": "4.5 Análisis de residuos del modelo polinomial\n\nshapiro.test(modelo_pol2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2$residuals\nW = 0.95926, p-value = 0.0107\n\nhist(modelo_pol2$residuals, main=\"Histograma residuos modelo_pol2\")\n\n\n\n\n\n\n\nplot(density(modelo_pol2$residuals),\n     main=\"Densidad residuos modelo_pol2\", xlab=\"Residuo\")\n\n\n\n\n\n\n\npar(mfrow = c(2, 2))\nplot(modelo_pol2)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\nComparación formal entre el modelo lineal y el polinomial:\n\nanova(modelo_lineal, modelo_pol2)\n\nAnalysis of Variance Table\n\nModel 1: mpg ~ hp + vol\nModel 2: mpg ~ vol + hp + I(hp^2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     79 2274.8                                  \n2     78 1480.9  1    793.86 41.813 8.009e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSi el p-valor es pequeño, el término cuadrático mejora significativamente el modelo."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#curva-predicha-del-modelo-polinomial",
    "href": "labs_epg/lab04_epg.html#curva-predicha-del-modelo-polinomial",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.6 Curva predicha del modelo polinomial",
    "text": "4.6 Curva predicha del modelo polinomial\n\nplot(\n  x = millaje$hp,\n  y = millaje$mpg,\n  main = \"Consumo vs potencia motor (modelo cuadrático)\",\n  xlab = \"hp\",\n  ylab = \"mpg\",\n  pch  = 20,\n  col  = \"grey\"\n)\n\npuntos_interpolados &lt;- seq(from = min(millaje$hp), to = max(millaje$hp), by = 1)\n\nprediccion &lt;- predict(\n  object = modelo_pol2,\n  newdata = data.frame(hp = millaje$hp, vol = millaje$vol)\n)\n\nlines(sort(millaje$hp), prediccion[order(millaje$hp)],\n      col = \"red\", lwd = 3)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#visualización-con-ggplot2",
    "href": "labs_epg/lab04_epg.html#visualización-con-ggplot2",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.7 Visualización con ggplot2",
    "text": "4.7 Visualización con ggplot2\n\nggplot(millaje, aes(x = hp, y = mpg)) +\n  geom_point(colour = \"grey\") +\n  stat_smooth(method = \"lm\", formula = y ~ hp + I(hp^2)) +\n  labs(title = \"Consumo vs potencia motor (modelo cuadrático)\") +\n  theme_bw()"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#polinomios-de-grados-más-altos",
    "href": "labs_epg/lab04_epg.html#polinomios-de-grados-más-altos",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.8 Polinomios de grados más altos",
    "text": "4.8 Polinomios de grados más altos\n\nggplot(millaje, aes(x = hp, y = mpg)) +\n  geom_point(colour = \"grey\") +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 2),  colour = \"red\",   se = FALSE) +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 5),  colour = \"blue\",  se = FALSE) +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 10), colour = \"green\", se = FALSE) +\n  labs(title = \"Polinomios de grados 2, 5 y 10\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nObserva cómo los polinomios de grados más altos se ajustan fuertemente a los datos, pero pueden sobreajustar (overfitting) y producir curvas muy oscilantes poco realistas."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#modelos-polinomiales-y-comparación",
    "href": "labs_epg/lab04_epg.html#modelos-polinomiales-y-comparación",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.9 Modelos polinomiales y comparación",
    "text": "4.9 Modelos polinomiales y comparación\n\nmodelo_5 &lt;- lm(mpg ~ poly(hp, 5), data = millaje)\nsummary(modelo_5)\n\n\nCall:\nlm(formula = mpg ~ poly(hp, 5), data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.9505 -2.5323 -0.4598  3.2027 10.9823 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   33.7817     0.4503  75.018  &lt; 2e-16 ***\npoly(hp, 5)1 -71.1198     4.0778 -17.441  &lt; 2e-16 ***\npoly(hp, 5)2  38.4953     4.0778   9.440 1.92e-14 ***\npoly(hp, 5)3 -15.3033     4.0778  -3.753  0.00034 ***\npoly(hp, 5)4   7.5552     4.0778   1.853  0.06780 .  \npoly(hp, 5)5  -3.5388     4.0778  -0.868  0.38822    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.078 on 76 degrees of freedom\nMultiple R-squared:  0.8441,    Adjusted R-squared:  0.8339 \nF-statistic: 82.31 on 5 and 76 DF,  p-value: &lt; 2.2e-16\n\nmodelo_5_correjido &lt;- lm(mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje)\nsummary(modelo_5_correjido)\n\n\nCall:\nlm(formula = mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6503 -2.6022 -0.3181  2.6926 11.4477 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.236e+01  5.361e+00  17.229  &lt; 2e-16 ***\nvol         -6.226e-02  2.345e-02  -2.655 0.009634 ** \nhp          -8.414e-01  1.135e-01  -7.410 1.38e-10 ***\nI(hp^2)      3.765e-03  7.355e-04   5.119 2.20e-06 ***\nI(hp^3)     -5.782e-06  1.430e-06  -4.044 0.000124 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.983 on 77 degrees of freedom\nMultiple R-squared:  0.8493,    Adjusted R-squared:  0.8415 \nF-statistic: 108.5 on 4 and 77 DF,  p-value: &lt; 2.2e-16\n\nanova(modelo_cuadratico, modelo_5_correjido)\n\nAnalysis of Variance Table\n\nModel 1: mpg ~ poly(hp, 2)\nModel 2: mpg ~ vol + hp + I(hp^2) + I(hp^3)\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     79 1567.5                                  \n2     77 1221.5  2    346.02 10.906 6.758e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnálisis de residuos:\n\nshapiro.test(modelo_5_correjido$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_5_correjido$residuals\nW = 0.98456, p-value = 0.4319\n\nhist(modelo_5_correjido$residuals, main = \"Histograma residuos modelo_5_correjido\")\n\n\n\n\n\n\n\nplot(density(modelo_5_correjido$residuals),\n     main = \"Densidad residuos modelo_5_correjido\")\n\n\n\n\n\n\n\nplot(modelo_5_correjido$fitted.values, millaje$mpg,\n     xlab = \"mpg estimado\", ylab = \"mpg real\",\n     main = \"Ajuste modelo_5_correjido\")\nlines(c(10, 60), c(10, 60), col = \"red\", lwd = 2)"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#transformaciones-de-la-variable-respuesta",
    "href": "labs_epg/lab04_epg.html#transformaciones-de-la-variable-respuesta",
    "title": "Capitulo_4_Uso_de_la_Regresion_Multiple",
    "section": "4.10 Transformaciones de la variable respuesta",
    "text": "4.10 Transformaciones de la variable respuesta\nBuscamos mejorar la normalidad de los residuos y la homocedasticidad usando transformaciones de mpg:\n\n4.10.1 Transformación logarítmica\n\nmodelo_pol2_trans &lt;- lm(log(1 + mpg) ~ vol + hp + I(hp^2), data = millaje)\nsummary(modelo_pol2_trans)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ vol + hp + I(hp^2), data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.31049 -0.06894 -0.02497  0.07082  0.33219 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.581e+00  7.376e-02  62.104  &lt; 2e-16 ***\nvol         -1.846e-03  6.687e-04  -2.761  0.00718 ** \nhp          -1.011e-02  1.141e-03  -8.858 2.03e-13 ***\nI(hp^2)      1.734e-05  3.354e-06   5.171 1.75e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1139 on 78 degrees of freedom\nMultiple R-squared:  0.8557,    Adjusted R-squared:  0.8501 \nF-statistic: 154.1 on 3 and 78 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_pol2_trans$residuals, modelo_pol2_trans$fitted.values,\n     main = \"Residuos vs ajustados (log(1+mpg))\")\n\n\n\n\n\n\n\nplot(log(1 + millaje$mpg), modelo_pol2_trans$fitted.values,\n     main = \"Valores reales transformados vs ajustados\")\nlines(c(2, 5), c(2, 5), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nshapiro.test(modelo_pol2_trans$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2_trans$residuals\nW = 0.98398, p-value = 0.4003\n\nhist(modelo_pol2_trans$residuals, main = \"Histograma residuos modelo_pol2_trans\")\n\n\n\n\n\n\n\nplot(density(modelo_pol2_trans$residuals),\n     main = \"Densidad residuos modelo_pol2_trans\")\n\n\n\n\n\n\n\n\n\n\n4.10.2 Transformación raíz cuadrada\n\nmodelo_pol3_trans &lt;- lm(sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)\nsummary(modelo_pol3_trans)\n\n\nCall:\nlm(formula = sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70979 -0.22004 -0.05431  0.19640  0.95714 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  9.031e+00  2.232e-01  40.459  &lt; 2e-16 ***\nvol         -5.083e-03  2.024e-03  -2.512   0.0141 *  \nhp          -3.256e-02  3.453e-03  -9.429 1.59e-14 ***\nI(hp^2)      6.117e-05  1.015e-05   6.027 5.21e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3448 on 78 degrees of freedom\nMultiple R-squared:  0.8442,    Adjusted R-squared:  0.8383 \nF-statistic: 140.9 on 3 and 78 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_pol3_trans$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol3_trans$residuals\nW = 0.97571, p-value = 0.1217\n\nplot(modelo_pol3_trans$residuals, modelo_pol3_trans$fitted.values,\n     main = \"Residuos vs ajustados (sqrt(mpg))\")\n\n\n\n\n\n\n\nplot(sqrt(millaje$mpg), modelo_pol3_trans$fitted.values,\n     main = \"sqrt(mpg) real vs ajustado\")\nlines(c(4, 8), c(4, 8), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\n4.10.3 Transformación 1/sqrt(mpg)\n\nmodelo_pol4_trans &lt;- lm(1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)\nsummary(modelo_pol4_trans)\n\n\nCall:\nlm(formula = 1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.032371 -0.007178  0.001601  0.005842  0.044607 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.354e-02  7.154e-03  11.677  &lt; 2e-16 ***\nvol          1.823e-04  6.486e-05   2.811 0.006249 ** \nhp           8.284e-04  1.107e-04   7.485 9.28e-11 ***\nI(hp^2)     -1.219e-06  3.253e-07  -3.747 0.000341 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01105 on 78 degrees of freedom\nMultiple R-squared:  0.8501,    Adjusted R-squared:  0.8444 \nF-statistic: 147.5 on 3 and 78 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_pol4_trans$residuals, modelo_pol4_trans$fitted.values,\n     main = \"Residuos vs ajustados (1/sqrt(mpg))\")\n\n\n\n\n\n\n\nplot(1/sqrt(millaje$mpg), modelo_pol4_trans$fitted.values,\n     main = \"1/sqrt(mpg) real vs ajustado\")\n\n\n\n\n\n\n\nshapiro.test(modelo_pol4_trans$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol4_trans$residuals\nW = 0.94789, p-value = 0.002249\n\n\n\n\n4.10.4 Transformaciones más complejas\n\nmodelo_pol2_tran_2 &lt;- lm(log(1 + mpg) ~ vol + hp + log(1 + hp) + I(hp^2),\n                         data = millaje)\nsummary(modelo_pol2_tran_2)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ vol + hp + log(1 + hp) + I(hp^2), \n    data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.35624 -0.06687 -0.00430  0.07828  0.29355 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.340e+00  1.236e+00   5.937 7.87e-08 ***\nvol         -2.076e-03  6.602e-04  -3.144  0.00237 ** \nhp           2.231e-03  5.630e-03   0.396  0.69297    \nlog(1 + hp) -8.215e-01  3.675e-01  -2.236  0.02827 *  \nI(hp^2)     -2.564e-06  9.486e-06  -0.270  0.78768    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1111 on 77 degrees of freedom\nMultiple R-squared:  0.8645,    Adjusted R-squared:  0.8574 \nF-statistic: 122.8 on 4 and 77 DF,  p-value: &lt; 2.2e-16\n\nplot(log(1 + millaje$mpg), modelo_pol2_tran_2$fitted.values,\n     main = \"log(1+mpg) real vs ajustado (modelo_tran_2)\")\n\n\n\n\n\n\n\nshapiro.test(modelo_pol2_tran_2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2_tran_2$residuals\nW = 0.98972, p-value = 0.7645\n\nhist(modelo_pol2_tran_2$residuals, main = \"Histograma residuos modelo_tran_2\")\n\n\n\n\n\n\n\nplot(density(modelo_pol2_tran_2$residuals),\n     main = \"Densidad residuos modelo_tran_2\")\n\n\n\n\n\n\n\nplot(modelo_pol2_tran_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOtro modelo más flexible:\n\nmodelo_pol2_tran_3 &lt;- lm(log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) +\n                           log(1 + hp) + I(hp^2),\n                         data = millaje)\nsummary(modelo_pol2_tran_3)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) + log(1 + \n    hp) + I(hp^2), data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.33860 -0.07127 -0.01969  0.07723  0.30307 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -2.034e+01  7.517e+01  -0.271    0.787\nhp          -3.355e-02  8.029e-02  -0.418    0.677\nI(1/hp)      4.093e+02  1.224e+03   0.334    0.739\nI(1/(hp^2)) -5.165e+03  1.705e+04  -0.303    0.763\nlog(1 + hp)  5.049e+00  1.558e+01   0.324    0.747\nI(hp^2)      3.600e-05  7.142e-05   0.504    0.616\n\nResidual standard error: 0.1187 on 76 degrees of freedom\nMultiple R-squared:  0.8475,    Adjusted R-squared:  0.8374 \nF-statistic: 84.45 on 5 and 76 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_pol2_tran_3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2_tran_3$residuals\nW = 0.98744, p-value = 0.6104\n\nplot(modelo_pol2_tran_3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(log(1 + millaje$mpg), modelo_pol2_tran_3$fitted.values,\n     main = \"log(1+mpg) real vs ajustado (modelo_tran_3)\")\nlines(c(3, 4.5), c(3, 4.5), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\n4.10.5 Modelos sin constante y selección\n\nmodelo_pol2_tran_4 &lt;- lm(log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) +\n                           log(1 + hp) + I(hp^2) - 1,\n                         data = millaje)\nsummary(modelo_pol2_tran_4)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) + log(1 + \n    hp) + I(hp^2) - 1, data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.34452 -0.07355 -0.01464  0.07509  0.30562 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \nhp          -1.202e-02  1.098e-02  -1.094   0.2772  \nI(1/hp)      7.934e+01  1.074e+02   0.738   0.4625  \nI(1/(hp^2)) -6.299e+02  3.147e+03  -0.200   0.8419  \nlog(1 + hp)  8.319e-01  3.658e-01   2.274   0.0258 *\nI(hp^2)      1.725e-05  1.732e-05   0.996   0.3223  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1179 on 77 degrees of freedom\nMultiple R-squared:  0.9989,    Adjusted R-squared:  0.9989 \nF-statistic: 1.459e+04 on 5 and 77 DF,  p-value: &lt; 2.2e-16\n\nplot(log(1 + millaje$mpg), modelo_pol2_tran_4$fitted.values,\n     main = \"Modelo_tran_4 (sin constante)\")\nlines(c(3, 4.5), c(3, 4.5), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nmodelo_pol2_tran_5 &lt;- lm(log(1 + mpg) ~ hp + I(1/hp) + log(1 + hp) + I(hp^2) - 1,\n                         data = millaje)\nsummary(modelo_pol2_tran_5)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ hp + I(1/hp) + log(1 + hp) + I(hp^2) - \n    1, data = millaje)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.33926 -0.07379 -0.01700  0.07535  0.30724 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \nhp          -1.410e-02  3.554e-03  -3.967 0.000161 ***\nI(1/hp)      5.795e+01  1.116e+01   5.194  1.6e-06 ***\nlog(1 + hp)  9.030e-01  8.687e-02  10.394  &lt; 2e-16 ***\nI(hp^2)      2.041e-05  7.119e-06   2.867 0.005328 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1172 on 78 degrees of freedom\nMultiple R-squared:  0.9989,    Adjusted R-squared:  0.9989 \nF-statistic: 1.846e+04 on 4 and 78 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_pol2_tran_5$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2_tran_5$residuals\nW = 0.98884, p-value = 0.7058\n\nplot(log(1 + millaje$mpg), modelo_pol2_tran_5$fitted.values,\n     main = \"Modelo_tran_5 (sin constante)\")\nlines(c(3, 4.5), c(3, 4.5), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nplot(modelo_pol2_tran_5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.10.6 Un modelo candidato “bueno”\nEl script sugiere como uno de los mejores:\n\nmodelo_pol2_tran_6 &lt;- lm(log(1 + mpg) ~ log(1 + hp) - 1, data = millaje)\nsummary(modelo_pol2_tran_6)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ log(1 + hp) - 1, data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3860 -0.3480  0.1168  0.3870  1.3059 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nlog(1 + hp)  0.73870    0.01383   53.42   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5883 on 81 degrees of freedom\nMultiple R-squared:  0.9724,    Adjusted R-squared:  0.9721 \nF-statistic:  2854 on 1 and 81 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_pol2_tran_6$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_pol2_tran_6$residuals\nW = 0.97148, p-value = 0.06443\n\nhist(modelo_pol2_tran_6$residuals,\n     main = \"Histograma residuos modelo_tran_6\")\n\n\n\n\n\n\n\nplot(density(modelo_pol2_tran_6$residuals),\n     main = \"Densidad residuos modelo_tran_6\")\n\n\n\n\n\n\n\nplot(modelo_pol2_tran_6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodelo_pol2_tran_7 &lt;- lm(log(1 + mpg) ~ vol + log(1 + hp) - 1, data = millaje)\nsummary(modelo_pol2_tran_7)\n\n\nCall:\nlm(formula = log(1 + mpg) ~ vol + log(1 + hp) - 1, data = millaje)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.3617 -0.3668  0.1028  0.4405  1.2853 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nvol         0.003047   0.002943   1.035    0.304    \nlog(1 + hp) 0.674633   0.063404  10.640   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.588 on 80 degrees of freedom\nMultiple R-squared:  0.9728,    Adjusted R-squared:  0.9721 \nF-statistic:  1429 on 2 and 80 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn la práctica, al elegir entre varios modelos transformados, debes considerar:\n\nSupuestos sobre los residuos (normalidad, homocedasticidad).\n\nInterpretabilidad económica de los coeficientes.\n\nCapacidad predictiva (idealmente evaluada fuera de muestra).\n\nParsimonia: preferir el modelo más simple que explique bien los datos."
  },
  {
    "objectID": "labs_epg/lab06_epg.html",
    "href": "labs_epg/lab06_epg.html",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "",
    "text": "Descargar PDF de contenidos teóricos\ne acuerdo al PDF teórico, el Análisis de Componentes Principales (PCA) es un método estadístico que:\n\nBusca simplificar la complejidad de un espacio de muchas variables (dimensiones) conservando la mayor parte posible de la información.\n\nSupone que tenemos \\(n\\) individuos y \\(p\\) variables \\((X_1, \\dots, X_p)\\).\n\nIntenta encontrar un número menor de factores subyacentes \\(z &lt; p\\) (las componentes principales) que expliquen aproximadamente lo mismo que las \\(p\\) variables originales.\n\nPertenece a los métodos de aprendizaje no supervisado (unsupervised learning): no hay una variable respuesta, sólo queremos entender la estructura interna de las variables explicativas.\n\nIntuitivamente, el PCA:\n\nBusca la dirección de máxima variabilidad de los datos (primera componente).\n\nLuego busca una segunda dirección ortogonal a la primera que explique la máxima varianza restante, y así sucesivamente.\n\nPermite mirar los datos tanto desde el punto de vista de los individuos (observaciones) como de las variables (cómo se relacionan entre sí).\n\n\n\nCuando las variables están en diferentes unidades, el primer paso es normalizar cada variable:\n\\[\ny_{ik} = \\frac{x_{ik} - \\bar x_k}{s_k}\n\\]\ndonde \\(\\bar x_k\\) es la media de la variable \\(X_k\\) y \\(s_k\\) su desviación estándar.\nCon los datos normalizados construimos la matriz de correlaciones \\(R\\), que en notación matricial puede escribirse como:\n[ R = Y^Y ]\nDe esta matriz calculamos sus valores propios (\\(\\lambda_i\\)) y vectores propios, que corresponden a:\n\nLos ejes preferenciales de información (direcciones en las que hay más varianza).\n\nLa proporción de varianza explicada por cada componente:\n\n\\[\n\\text{contribución}_i = \\frac{\\lambda_i}{\\sum_j \\lambda_j}\n\\]"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#normalización-y-matriz-de-correlación",
    "href": "labs_epg/lab06_epg.html#normalización-y-matriz-de-correlación",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "",
    "text": "Cuando las variables están en diferentes unidades, el primer paso es normalizar cada variable:\n\\[\ny_{ik} = \\frac{x_{ik} - \\bar x_k}{s_k}\n\\]\ndonde \\(\\bar x_k\\) es la media de la variable \\(X_k\\) y \\(s_k\\) su desviación estándar.\nCon los datos normalizados construimos la matriz de correlaciones \\(R\\), que en notación matricial puede escribirse como:\n[ R = Y^Y ]\nDe esta matriz calculamos sus valores propios (\\(\\lambda_i\\)) y vectores propios, que corresponden a:\n\nLos ejes preferenciales de información (direcciones en las que hay más varianza).\n\nLa proporción de varianza explicada por cada componente:\n\n\\[\n\\text{contribución}_i = \\frac{\\lambda_i}{\\sum_j \\lambda_j}\n\\]"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#carga-de-librerías",
    "href": "labs_epg/lab06_epg.html#carga-de-librerías",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "2.1 Carga de librerías",
    "text": "2.1 Carga de librerías\nEn este laboratorio usaremos algunas librerías para facilitar el análisis:\n\nlibrary(tidyverse)           # Manipulación de datos\nlibrary(psych)               # KMO, Bartlett, análisis psicométrico\nlibrary(corrplot)            # Gráficos de matrices de correlación\nlibrary(PerformanceAnalytics)# chart.Correlation"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#ruta-de-trabajo-opcional",
    "href": "labs_epg/lab06_epg.html#ruta-de-trabajo-opcional",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "2.2 Ruta de trabajo (opcional)",
    "text": "2.2 Ruta de trabajo (opcional)\nMantenemos la misma lógica de ruta de datos que en los laboratorios anteriores de ECO_EPG:\n\nruta_datos &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg\"\n\n# Puedes revisar el contenido de la carpeta\nlist.files(ruta_datos)\n\n [1] \"annos_mantenimiento.xlsx\" \"auto_peso_consumo.xlsx\"  \n [3] \"costos.xlsx\"              \"data_PCA_Decathlon.csv\"  \n [5] \"data_PCA_ExpertWine.csv\"  \"Ejemplo1.xlsx\"           \n [7] \"Ejemplo2.xlsx\"            \"millaje.txt\"             \n [9] \"orange.csv\"               \"tabla_ejemplo_R.xlsx\"    \n\n\nEn este laboratorio usaremos principalmente datasets incluidos en R, de manera que puedas ejecutar el código incluso si no has descargado archivos adicionales."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#selección-y-exploración-de-variables",
    "href": "labs_epg/lab06_epg.html#selección-y-exploración-de-variables",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.1 Selección y exploración de variables",
    "text": "3.1 Selección y exploración de variables\n\ndata(mtcars)\n\n# Seleccionamos algunas variables numéricas de interés\ndatos_auto &lt;- mtcars %&gt;% \n  select(mpg, hp, wt, qsec, disp, drat)\n\nsummary(datos_auto)\n\n      mpg              hp              wt             qsec      \n Min.   :10.40   Min.   : 52.0   Min.   :1.513   Min.   :14.50  \n 1st Qu.:15.43   1st Qu.: 96.5   1st Qu.:2.581   1st Qu.:16.89  \n Median :19.20   Median :123.0   Median :3.325   Median :17.71  \n Mean   :20.09   Mean   :146.7   Mean   :3.217   Mean   :17.85  \n 3rd Qu.:22.80   3rd Qu.:180.0   3rd Qu.:3.610   3rd Qu.:18.90  \n Max.   :33.90   Max.   :335.0   Max.   :5.424   Max.   :22.90  \n      disp            drat      \n Min.   : 71.1   Min.   :2.760  \n 1st Qu.:120.8   1st Qu.:3.080  \n Median :196.3   Median :3.695  \n Mean   :230.7   Mean   :3.597  \n 3rd Qu.:326.0   3rd Qu.:3.920  \n Max.   :472.0   Max.   :4.930  \n\n\n\n\n\n\n\n\nTip\n\n\n\nSiempre es importante ver el rango y la escala de las variables:\n\nmpg está en millas por galón.\n\nhp en caballos de fuerza.\n\nwt en miles de libras.\n\nqsec en segundos.\n\nSi no normalizamos, las variables con mayor escala dominarán el análisis."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#matriz-de-correlación",
    "href": "labs_epg/lab06_epg.html#matriz-de-correlación",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.2 Matriz de correlación",
    "text": "3.2 Matriz de correlación\nAntes de hacer PCA miramos la relación entre variables:\n\ncor_auto &lt;- cor(datos_auto)\nround(cor_auto, 2)\n\n       mpg    hp    wt  qsec  disp  drat\nmpg   1.00 -0.78 -0.87  0.42 -0.85  0.68\nhp   -0.78  1.00  0.66 -0.71  0.79 -0.45\nwt   -0.87  0.66  1.00 -0.17  0.89 -0.71\nqsec  0.42 -0.71 -0.17  1.00 -0.43  0.09\ndisp -0.85  0.79  0.89 -0.43  1.00 -0.71\ndrat  0.68 -0.45 -0.71  0.09 -0.71  1.00\n\ncorrplot(cor_auto,\n         type  = \"upper\",\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n\n\n\n\n\n\nchart.Correlation(datos_auto,\n                  histogram = TRUE,\n                  pch       = 19)"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#test-de-bartlett-y-kmo",
    "href": "labs_epg/lab06_epg.html#test-de-bartlett-y-kmo",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.3 Test de Bartlett y KMO",
    "text": "3.3 Test de Bartlett y KMO\nAplicamos los tests que se mencionan en el PDF teórico:\n\nBartlett: contrasta si la matriz de correlación es esférica.\n\nKMO: evalúa la adecuación del muestreo para análisis factorial/PCA.\n\n\npsych::cortest.bartlett(cor_auto, n = nrow(datos_auto))\n\n$chisq\n[1] 181.2473\n\n$p.value\n[1] 1.332068e-30\n\n$df\n[1] 15\n\nKMO(cor_auto)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cor_auto)\nOverall MSA =  0.76\nMSA for each item = \n mpg   hp   wt qsec disp drat \n0.83 0.83 0.70 0.52 0.78 0.85 \n\n\n\n\n\n\n\n\nNota\n\n\n\n\nSi el p-value de Bartlett es pequeño, la matriz de correlación es distinta de la identidad, lo que favorece el uso de PCA.\n\nUn KMO cercano a 1 indica que las variables comparten suficiente varianza común como para aplicar análisis factorial o PCA."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#normalización-de-las-variables",
    "href": "labs_epg/lab06_epg.html#normalización-de-las-variables",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.4 Normalización de las variables",
    "text": "3.4 Normalización de las variables\nNormalizamos las variables para que todas queden en escala comparable:\n\ndatos_auto_norm &lt;- scale(datos_auto)\n\nhead(datos_auto_norm)\n\n                         mpg         hp           wt       qsec        disp\nMazda RX4          0.1508848 -0.5350928 -0.610399567 -0.7771651 -0.57061982\nMazda RX4 Wag      0.1508848 -0.5350928 -0.349785269 -0.4637808 -0.57061982\nDatsun 710         0.4495434 -0.7830405 -0.917004624  0.4260068 -0.99018209\nHornet 4 Drive     0.2172534 -0.5350928 -0.002299538  0.8904872  0.22009369\nHornet Sportabout -0.2307345  0.4129422  0.227654255 -0.4637808  1.04308123\nValiant           -0.3302874 -0.6080186  0.248094592  1.3269868 -0.04616698\n                        drat\nMazda RX4          0.5675137\nMazda RX4 Wag      0.5675137\nDatsun 710         0.4739996\nHornet 4 Drive    -0.9661175\nHornet Sportabout -0.8351978\nValiant           -1.5646078"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#pca-con-prcomp",
    "href": "labs_epg/lab06_epg.html#pca-con-prcomp",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.5 PCA con prcomp",
    "text": "3.5 PCA con prcomp\nUsamos la función base prcomp, que trabaja sobre la matriz de datos:\n\npca_auto &lt;- prcomp(datos_auto,\n                   center = TRUE,  # restar la media\n                   scale. = TRUE)  # dividir por la desviación estándar\n\nsummary(pca_auto)\n\nImportance of components:\n                          PC1    PC2     PC3     PC4    PC5     PC6\nStandard deviation     2.0463 1.0715 0.57737 0.39289 0.3533 0.22799\nProportion of Variance 0.6979 0.1913 0.05556 0.02573 0.0208 0.00866\nCumulative Proportion  0.6979 0.8892 0.94481 0.97054 0.9913 1.00000\n\n\nEl summary muestra:\n\nLa desviación estándar de cada componente.\n\nLa proporción de varianza explicada por cada componente.\n\nLa varianza acumulada (muy útil para decidir cuántas componentes retener)."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#valores-propios-y-varianza-explicada",
    "href": "labs_epg/lab06_epg.html#valores-propios-y-varianza-explicada",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.6 Valores propios y varianza explicada",
    "text": "3.6 Valores propios y varianza explicada\nLos valores propios se obtienen elevando al cuadrado las desviaciones estándar de las componentes:\n\neigenvalues &lt;- pca_auto$sdev^2\neigenvalues\n\n[1] 4.18739648 1.14811212 0.33335666 0.15436054 0.12479601 0.05197818\n\nprop_var &lt;- eigenvalues / sum(eigenvalues)\nprop_var\n\n[1] 0.697899413 0.191352020 0.055559444 0.025726757 0.020799335 0.008663031\n\nacum_var &lt;- cumsum(prop_var)\nacum_var\n\n[1] 0.6978994 0.8892514 0.9448109 0.9705376 0.9913370 1.0000000\n\n\n\n3.6.1 Gráfico de sedimentación (scree plot)\n\nplot(prop_var,\n     type = \"b\",\n     xlab = \"Componente principal\",\n     ylab = \"Proporción de varianza explicada\",\n     main = \"Gráfico de sedimentación (scree plot)\")\n\nabline(h = 0.1, lty = 2, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIdeas típicas para decidir el número de componentes:\n\nMantener las componentes que explican en conjunto, por ejemplo, 70%-80% de la varianza.\n\nDetenerse cuando el scree plot muestra un “codo” evidente.\n\nMantener sólo las componentes con valor propio mayor que 1 (criterio de Kaiser) cuando se trabaja sobre matriz de correlación."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#cargas-loadings-e-interpretación",
    "href": "labs_epg/lab06_epg.html#cargas-loadings-e-interpretación",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.7 Cargas (loadings) e interpretación",
    "text": "3.7 Cargas (loadings) e interpretación\nLas cargas son las correlaciones entre las variables originales y las componentes:\n\npca_auto$rotation\n\n            PC1         PC2         PC3         PC4        PC5         PC6\nmpg  -0.4586835 -0.05867609 -0.19479235 -0.78205878  0.1111533  0.35249327\nhp    0.4258534 -0.36147576  0.14613554 -0.12301873  0.8057408  0.04771555\nwt    0.4386179  0.29953457  0.41776208 -0.10438337 -0.2301541  0.69246040\nqsec -0.2528320  0.76284877  0.34059066 -0.04268124  0.4218755 -0.24152663\ndisp  0.4660354  0.06065296  0.09688406 -0.60001871 -0.2946297 -0.56825752\ndrat -0.3670963 -0.43652537  0.80049152 -0.02259258 -0.1437714 -0.11277675\n\n\n\nValores altos (en valor absoluto) indican que la variable tiene una gran influencia en esa componente.\n\nEl signo indica dirección de la relación (positiva o negativa)."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#coordenadas-de-los-individuos-scores",
    "href": "labs_epg/lab06_epg.html#coordenadas-de-los-individuos-scores",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.8 Coordenadas de los individuos (scores)",
    "text": "3.8 Coordenadas de los individuos (scores)\n\nhead(pca_auto$x)\n\n                         PC1          PC2        PC3        PC4         PC5\nMazda RX4         -0.8425806 -0.873469391 -0.2282783  0.3742725 -0.51522641\nMazda RX4 Wag     -0.8075041 -0.556341552 -0.0126678  0.3336931 -0.44299870\nDatsun 710        -1.6850448  0.040006569 -0.1564937  0.4057157  0.03340433\nHornet 4 Drive    -0.0964443  1.294377904 -0.5702297 -0.2520788  0.04326023\nHornet Sportabout  1.2915096  0.006516693 -0.5250741 -0.4813192 -0.12822104\nValiant            0.2187309  2.005957905 -0.7258399  0.3136170  0.21465335\n                          PC6\nMazda RX4          0.05293884\nMazda RX4 Wag      0.15771326\nDatsun 710        -0.10756126\nHornet 4 Drive    -0.18173489\nHornet Sportabout -0.29051949\nValiant           -0.09145688\n\n\nCada fila corresponde a un auto, y cada columna a su coordenada en una componente principal (por ejemplo, PC1, PC2)."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#biplot-individuos-y-variables",
    "href": "labs_epg/lab06_epg.html#biplot-individuos-y-variables",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "3.9 Biplot: individuos y variables",
    "text": "3.9 Biplot: individuos y variables\n\nbiplot(pca_auto,\n       scale = 0,\n       cex   = 0.7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nLos puntos son los autos (individuos).\n\nLas flechas representan las variables originales.\n\nLa dirección y longitud de cada flecha muestran cómo cada variable contribuye a las primeras componentes."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#creación-de-datos-simulados",
    "href": "labs_epg/lab06_epg.html#creación-de-datos-simulados",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.1 Creación de datos simulados",
    "text": "4.1 Creación de datos simulados\n\nset.seed(123)\n\nn_regiones &lt;- 16\n\ndatos_regiones &lt;- tibble(\n  region      = paste(\"Region\", 1:n_regiones),\n  ingreso_pc  = round(rnorm(n_regiones, mean = 800000, sd = 150000)),\n  desempleo   = round(rnorm(n_regiones, mean = 8, sd = 2), 1),\n  escolaridad = round(rnorm(n_regiones, mean = 11, sd = 1.5), 1),\n  pobreza     = round(rnorm(n_regiones, mean = 15, sd = 5), 1),\n  gini        = round(rnorm(n_regiones, mean = 0.45, sd = 0.05), 2)\n)\n\ndatos_regiones\n\n# A tibble: 16 × 6\n   region    ingreso_pc desempleo escolaridad pobreza  gini\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Region 1      715929       9          12.3    18.9  0.4 \n 2 Region 2      765473       4.1        12.3    14.6  0.47\n 3 Region 3     1033806       9.4        12.2    16.3  0.47\n 4 Region 4      810576       7.1        12      14.9  0.45\n 5 Region 5      819393       5.9        11.8    14.8  0.5 \n 6 Region 6     1057260       7.6        10.9    21.8  0.55\n 7 Region 7      869137       5.9        10.5    13.9  0.43\n 8 Region 8      610241       6.5        10.4    22.6  0.33\n 9 Region 9      696972       6.7        10       7.3  0.5 \n10 Region 10     733151       4.6        10.7    17.9  0.41\n11 Region 11     983612       9.7         9.1    15.6  0.42\n12 Region 12     853972       8.3        14.3    16.1  0.5 \n13 Region 13     860116       5.7        12.8    16.9  0.44\n14 Region 14     816602      10.5         9.3    12.5  0.39\n15 Region 15     716624       8.9        10.4    13.3  0.46\n16 Region 16    1068037       7.4        10.3     9.9  0.44"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#exploración-inicial",
    "href": "labs_epg/lab06_epg.html#exploración-inicial",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.2 Exploración inicial",
    "text": "4.2 Exploración inicial\n\nsummary(select(datos_regiones, -region))\n\n   ingreso_pc        desempleo       escolaridad       pobreza     \n Min.   : 610241   Min.   : 4.100   Min.   : 9.10   Min.   : 7.30  \n 1st Qu.: 729019   1st Qu.: 5.900   1st Qu.:10.38   1st Qu.:13.75  \n Median : 817998   Median : 7.250   Median :10.80   Median :15.25  \n Mean   : 838181   Mean   : 7.331   Mean   :11.21   Mean   :15.46  \n 3rd Qu.: 897756   3rd Qu.: 8.925   3rd Qu.:12.22   3rd Qu.:17.15  \n Max.   :1068037   Max.   :10.500   Max.   :14.30   Max.   :22.60  \n      gini       \n Min.   :0.3300  \n 1st Qu.:0.4175  \n Median :0.4450  \n Mean   :0.4475  \n 3rd Qu.:0.4775  \n Max.   :0.5500"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#matriz-de-correlación-1",
    "href": "labs_epg/lab06_epg.html#matriz-de-correlación-1",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.3 Matriz de correlación",
    "text": "4.3 Matriz de correlación\n\nvars_reg &lt;- select(datos_regiones, -region)\ncor_reg  &lt;- cor(vars_reg)\nround(cor_reg, 2)\n\n            ingreso_pc desempleo escolaridad pobreza  gini\ningreso_pc        1.00      0.30       -0.01   -0.06  0.44\ndesempleo         0.30      1.00       -0.23   -0.06 -0.09\nescolaridad      -0.01     -0.23        1.00    0.26  0.34\npobreza          -0.06     -0.06        0.26    1.00 -0.22\ngini              0.44     -0.09        0.34   -0.22  1.00\n\ncorrplot(cor_reg,\n         type  = \"upper\",\n         order = \"hclust\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n\n\n\n\n\n\nchart.Correlation(vars_reg, histogram = TRUE, pch = 19)"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#bartlett-y-kmo",
    "href": "labs_epg/lab06_epg.html#bartlett-y-kmo",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.4 Bartlett y KMO",
    "text": "4.4 Bartlett y KMO\n\npsych::cortest.bartlett(cor_reg, n = nrow(datos_regiones))\n\n$chisq\n[1] 9.531286\n\n$p.value\n[1] 0.4825305\n\n$df\n[1] 10\n\nKMO(cor_reg)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: KMO(r = cor_reg)\nOverall MSA =  0.38\nMSA for each item = \n ingreso_pc   desempleo escolaridad     pobreza        gini \n       0.40        0.46        0.39        0.30        0.38"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#pca-sobre-indicadores-regionales",
    "href": "labs_epg/lab06_epg.html#pca-sobre-indicadores-regionales",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.5 PCA sobre indicadores regionales",
    "text": "4.5 PCA sobre indicadores regionales\n\npca_reg &lt;- prcomp(vars_reg,\n                  center = TRUE,\n                  scale. = TRUE)\n\nsummary(pca_reg)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5\nStandard deviation     1.2525 1.2071 1.0262 0.7718 0.57039\nProportion of Variance 0.3138 0.2914 0.2106 0.1191 0.06507\nCumulative Proportion  0.3138 0.6052 0.8158 0.9349 1.00000\n\n\n\n4.5.1 Varianza explicada\n\neig_reg   &lt;- pca_reg$sdev^2\nprop_reg  &lt;- eig_reg / sum(eig_reg)\nacum_reg  &lt;- cumsum(prop_reg)\n\nprop_reg\n\n[1] 0.31375635 0.29143673 0.21061115 0.11912759 0.06506818\n\nacum_reg\n\n[1] 0.3137564 0.6051931 0.8158042 0.9349318 1.0000000\n\nplot(prop_reg,\n     type = \"b\",\n     xlab = \"Componente principal\",\n     ylab = \"Proporción de varianza explicada\",\n     main = \"Scree plot - indicadores regionales\")"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#interpretación-de-las-componentes",
    "href": "labs_epg/lab06_epg.html#interpretación-de-las-componentes",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.6 Interpretación de las componentes",
    "text": "4.6 Interpretación de las componentes\n\npca_reg$rotation\n\n                   PC1        PC2        PC3          PC4        PC5\ningreso_pc   0.6287024  0.2048168  0.3221309  0.471827456 -0.4862035\ndesempleo    0.1577429  0.5621811  0.5069584 -0.605120552  0.1894515\nescolaridad  0.2260606 -0.6701855  0.1702061 -0.549672409 -0.4106557\npobreza     -0.2399983 -0.3756731  0.7540961  0.330237323  0.3515011\ngini         0.6864021 -0.2274283 -0.2039456  0.003394633  0.6599418\n\n\n\n\n\n\n\n\nNota\n\n\n\n\nUna componente con alta carga positiva en ingreso_pc y escolaridad y carga negativa en pobreza podría interpretarse como un índice de desarrollo socioeconómico.\n\nOtra componente con alta carga en desempleo y gini podría interpretarse como un patrón de inestabilidad laboral y desigualdad."
  },
  {
    "objectID": "labs_epg/lab06_epg.html#coordenadas-de-las-regiones-en-el-espacio-de-componentes",
    "href": "labs_epg/lab06_epg.html#coordenadas-de-las-regiones-en-el-espacio-de-componentes",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.7 Coordenadas de las regiones en el espacio de componentes",
    "text": "4.7 Coordenadas de las regiones en el espacio de componentes\n\nscores_reg &lt;- as_tibble(pca_reg$x) %&gt;%\n  mutate(region = datos_regiones$region)\n\nscores_reg\n\n# A tibble: 16 × 6\n       PC1    PC2    PC3     PC4      PC5 region   \n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    \n 1 -1.07   -0.335  1.15  -1.11   -0.00143 Region 1 \n 2 -0.0845 -1.63  -1.17   0.296  -0.190   Region 2 \n 3  1.47    0.260  1.22  -0.319  -0.420   Region 3 \n 4  0.0496 -0.451 -0.148 -0.381  -0.179   Region 4 \n 5  0.611  -0.909 -0.691  0.113   0.342   Region 5 \n 6  1.92   -0.497  1.39   1.33    1.19    Region 6 \n 7 -0.225   0.180 -0.638  0.718  -0.406   Region 7 \n 8 -3.21   -0.387  0.977  0.403   0.141   Region 8 \n 9  0.287   0.742 -2.44  -0.493   0.712   Region 9 \n10 -1.43   -0.812 -0.434  0.931  -0.00298 Region 10\n11  0.160   2.05   0.863  0.575   0.0168  Region 11\n12  1.30   -1.46   0.602 -1.43   -0.158   Region 12\n13  0.0352 -1.34   0.111  0.0974 -0.678   Region 13\n14 -0.705   2.38   0.227 -0.605  -0.0228  Region 14\n15 -0.261   0.835 -0.424 -0.792   0.791   Region 15\n16  1.16    1.37  -0.600  0.656  -1.14    Region 16\n\n\n\n4.7.1 Gráfico de las regiones en PC1–PC2\n\nggplot(scores_reg, aes(x = PC1, y = PC2, label = region)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"grey70\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey70\") +\n  geom_point() +\n  geom_text(vjust = -0.5, size = 3) +\n  labs(title = \"Regiones en el espacio de las dos primeras componentes\",\n       x = \"Componente principal 1\",\n       y = \"Componente principal 2\") +\n  theme_minimal()"
  },
  {
    "objectID": "labs_epg/lab06_epg.html#biplot-con-variables-e-individuos",
    "href": "labs_epg/lab06_epg.html#biplot-con-variables-e-individuos",
    "title": "Capitulo_6_Componentes_Principales",
    "section": "4.8 Biplot con variables e individuos",
    "text": "4.8 Biplot con variables e individuos\n\nbiplot(pca_reg,\n       scale = 0,\n       cex   = 0.7)"
  }
]