[
  {
    "objectID": "labs_epg/lab04_epg.html",
    "href": "labs_epg/lab04_epg.html",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#uso-de-la-regresión-múltiple",
    "href": "labs_epg/lab04_epg.html#uso-de-la-regresión-múltiple",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "1 Uso de la Regresión Múltiple",
    "text": "1 Uso de la Regresión Múltiple"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#análisis-de-correlaciones-simultáneas",
    "href": "labs_epg/lab04_epg.html#análisis-de-correlaciones-simultáneas",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "2 Análisis de Correlaciones Simultáneas",
    "text": "2 Análisis de Correlaciones Simultáneas\nEl análisis inicial en regresión múltiple se centra en la relación entre las variables explicativas. Una herramienta fundamental es la matriz de correlación.\nUna alta correlación entre las variables explicativas (\\(X_i, X_j\\)) es un indicio de multicolinealidad, lo que puede inestabilizar los coeficientes estimados.\nLa librería MASS es comúnmente utilizada en R, aunque la función cor() pertenece al paquete base.\nR\nlibrary(MASS) # Ejemplo de uso # Permite ver correlaciones simultáneas cor(Datos[, c(\"X1\", \"X2\", \"X3\")])"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#criterios-de-especificación-del-modelo",
    "href": "labs_epg/lab04_epg.html#criterios-de-especificación-del-modelo",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "3 Criterios de Especificación del Modelo",
    "text": "3 Criterios de Especificación del Modelo\n\n3.1 Eliminación de Variables Irrelevantes\nSe deben eliminar las variables del modelo que no son estadísticamente significativas (\\(\\hat{\\beta}_i\\) no es distinto de cero), siempre y cuando el modelo global mantenga su significancia. El objetivo es obtener un modelo parsimonioso (simple y explicativo).\n\n\n3.2 Inclusión de Interacciones\nSe pueden agregar interacciones (\\(X_i \\times X_j\\)) para modelar un efecto conjunto o condicional de dos variables sobre la respuesta (\\(Y\\)):\n$$X_3 = X_2 \\times X_1$$"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#regresión-polinomial",
    "href": "labs_epg/lab04_epg.html#regresión-polinomial",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "4 Regresión Polinomial",
    "text": "4 Regresión Polinomial\nLa regresión polinomial se utiliza para modelar relaciones no lineales entre \\(X\\) y \\(Y\\) manteniendo la linealidad en los parámetros (\\(\\beta\\)).\nEl modelo de regresión polinomial de grado \\(k\\) es:\n$$y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\cdots + \\beta_k x^k + \\varepsilon$$\ndonde \\(\\varepsilon\\) representa el término de perturbación aleatoria.\nNo existe una regla estricta para determinar el grado \\(k\\), pero la práctica sugiere incrementar el grado del polinomio hasta que el nuevo término deje de ser significativo. Esto se evalúa formalmente mediante una prueba ANOVA (o prueba \\(F\\)) que compara la mejora de ajuste entre el modelo de grado \\(k\\) y el modelo de grado \\(k+1\\)."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#transformación-de-variables",
    "href": "labs_epg/lab04_epg.html#transformación-de-variables",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "5 Transformación de Variables",
    "text": "5 Transformación de Variables\nTanto la variable dependiente (\\(Y\\)) como las independientes (\\(X_i\\)) pueden transformarse mediante funciones matemáticas (\\(f(\\cdot)\\)) para:\n\nEstabilizar la varianza de los residuos (resolver heterocedasticidad).\nMejorar la linealidad de la relación.\nNormalizar la distribución de los errores.\n\n$$y’ = f(y), \\qquad x’ = g(x)$$\n\n5.1 Transformación Logarítmica\nSi se utiliza el logaritmo y alguna variable toma el valor cero (\\(0\\)), se debe aplicar un desplazamiento para evitar la indeterminación, usando:\n$$\\log(1 + y) \\quad \\text{o} \\quad \\log(1 + x)$$\n\n\n5.2 Otras Transformaciones\nOtras transformaciones comunes para estabilizar la varianza incluyen la raíz cuadrada:\n$$y’ = \\sqrt{y}$$\nEl objetivo principal es encontrar la transformación que minimice la varianza de los residuos (\\(\\sigma_{\\varepsilon}^2\\)) y asegure que el modelo cumpla con los supuestos clásicos de la regresión lineal."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#conclusión",
    "href": "labs_epg/lab04_epg.html#conclusión",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "6 Conclusión",
    "text": "6 Conclusión\nLa fase de especificación del modelo, que abarca el manejo de multicolinealidad, la selección de variables, la incorporación de efectos no lineales (polinomiales) y las transformaciones adecuadas, es crucial. Estas herramientas permiten construir modelos econométricos sólidos, válidos y parsimoniosos, mejorando la interpretación, la validez estadística y la capacidad predictiva del modelo de regresión múltiple."
  },
  {
    "objectID": "labs_epg/lab04_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "href": "labs_epg/lab04_epg.html#aplicación-en-r-sobre-los-contenidos-anteriores",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "7 Aplicación en R (sobre los contenidos anteriores)",
    "text": "7 Aplicación en R (sobre los contenidos anteriores)\n\n# Ruta absoluta de datos (según tu equipo)\ndata_path &lt;- \"C:/Users/manue/Desktop/lab-econometria/labs/data_epg\"\n\nif (!file.exists(file.path(data_path, \"millaje.txt\"))) {\n  message(\"ℹ️ Aviso: 'millaje.txt' no se encontró en data_path; el bloque DAAG usa dataset interno 'carprice'.\")\n}\n\n\n# Librerías necesarias\n# install.packages(c(\"tidyverse\",\"openxlsx\",\"MASS\",\"corrplot\",\"lmtest\",\"DAAG\",\"ggplot2\"))\nlibrary(tidyverse); library(openxlsx); library(MASS); library(corrplot)\nlibrary(lmtest); library(DAAG); library(ggplot2)\n\n\n7.1 1) Ejemplo publicitario: tv, radio, periódico → ventas\n\ntv &lt;- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2, 228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6, 95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1, 175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9, 7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5, 139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5, 5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0, 139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177.0, 283.6, 232.1)\nradio &lt;- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0, 35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9, 12.6, 3.5, 29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1, 43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5, 15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5, 2.0, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3, 33.0, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5, 43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14.0, 31.6, 3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11.0, 0.3, 0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3, 0.8, 36.9, 16.0, 26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0, 39.6, 2.9, 27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2, 5.7, 14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6, 43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2, 23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0, 2.6, 5.4, 5.7, 43.0, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8, 4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6)\nperiodico &lt;- c(69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2, 4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5, 49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0, 0.3, 7.4, 8.5, 5.0, 45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3, 31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0, 41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2, 11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4, 23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2, 73.4, 51.4, 9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8, 100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2, 2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6, 12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6, 8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9.0, 8.7, 44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3, 45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6, 6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6, 8.3, 27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0, 31.6, 3.6, 6.0, 13.8, 8.1, 6.4, 66.2, 8.7)\nventas &lt;- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5, 9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4, 8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6, 21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6, 3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0, 12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4)\ndatos &lt;- data.frame(tv, radio, periodico, ventas)\n\npairs(datos)\n\n\n\n\n\n\n\nr &lt;- cor(datos)\ncorrplot(r, method=\"circle\", type=\"lower\", diag=FALSE, tl.col=\"black\", tl.cex=1, tl.offset=0.1, tl.srt=45)\n\n\n\n\n\n\n\n\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio + periodico, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + periodico, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.8277 -0.8908  0.2418  1.1893  2.8292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***\ntv           0.045765   0.001395  32.809   &lt;2e-16 ***\nradio        0.188530   0.008611  21.893   &lt;2e-16 ***\nperiodico   -0.001037   0.005871  -0.177     0.86    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 196 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 \nF-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nmodelo &lt;- lm(formula = ventas ~ tv + radio, data = datos)\nsummary(modelo)\n\n\nCall:\nlm(formula = ventas ~ tv + radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7977 -0.8752  0.2422  1.1708  2.8328 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\ntv           0.04575    0.00139  32.909   &lt;2e-16 ***\nradio        0.18799    0.00804  23.382   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.681 on 197 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 \nF-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones,\n                    theta = 18, phi = 20,\n                    col = \"lightblue\", shade = 0.1,\n                    xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\",\n                    main = \"Predicción ventas ~ TV y Radio\")\n\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo), superficie)\npoints(observaciones, col = \"red\", pch = 16)\nsegments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nshapiro.test(modelo$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo$residuals\nW = 0.91804, p-value = 4.19e-09\n\nhist(modelo$residuals); plot(density(modelo$residuals))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  modelo\nDW = 2.0808, p-value = 0.5656\nalternative hypothesis: true autocorrelation is not 0\n\nbptest(modelo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo\nBP = 4.8093, df = 2, p-value = 0.0903\n\nplot(modelo$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\ntv_radio &lt;- tv*radio\nmodelo_interaccion &lt;- lm(formula = ventas ~ tv + radio + tv*radio, data = datos)\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***\ntv          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***\nradio       2.886e-02  8.905e-03   3.241   0.0014 ** \ntv:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(modelo_interaccion$residuals); hist(modelo_interaccion$residuals); plot(density(modelo_interaccion$residuals))\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion$residuals\nW = 0.8469, p-value = 3.047e-13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndwtest(modelo_interaccion,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion\nDW = 2.2236, p-value = 0.1103\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion\nBP = 14.324, df = 3, p-value = 0.002495\n\nplot(modelo_interaccion$fitted.values, datos$ventas); lines(c(0,25), c(0,25))\n\n\n\n\n\n\n\n\n\nrango_tv &lt;- range(datos$tv)\nnuevos_valores_tv &lt;- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)\nrango_radio &lt;- range(datos$radio)\nnuevos_valores_radio &lt;- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)\n\npredicciones &lt;- outer(X = nuevos_valores_tv, Y = nuevos_valores_radio, \n                      FUN = function(tv, radio) {\n                        predict(object = modelo_interaccion, newdata = data.frame(tv, radio))\n                      })\n\nsuperficie &lt;- persp(x = nuevos_valores_tv, y = nuevos_valores_radio,\n                    z = predicciones, theta = 18, phi = 20, col = \"lightblue\",\n                    shade = 0.1, xlab = \"tv\", ylab = \"radio\", zlab = \"ventas\",\n                    ticktype = \"detailed\", main = \"Predicción ventas ~ TV y Radio (interacción)\")\nobservaciones &lt;- trans3d(datos$tv, datos$radio, datos$ventas, superficie)\nerror &lt;- trans3d(datos$tv, datos$radio, fitted(modelo_interaccion), superficie)\npoints(observaciones, col = \"red\", pch = 16); segments(observaciones$x, observaciones$y, error$x, error$y)\n\n\n\n\n\n\n\n\n\nanova(modelo, modelo_interaccion)\n\nAnalysis of Variance Table\n\nModel 1: ventas ~ tv + radio\nModel 2: ventas ~ tv + radio + tv * radio\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    197 556.91                                  \n2    196 174.48  1    382.43 429.59 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodelo_interaccion_1 &lt;- lm(formula = ventas ~ tv + radio + I(tv^2)+ tv*radio, data = datos)\nsummary(modelo_interaccion_1)\n\n\nCall:\nlm(formula = ventas ~ tv + radio + I(tv^2) + tv * radio, data = datos)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.9949 -0.2969 -0.0066  0.3798  1.1686 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.137e+00  1.927e-01  26.663  &lt; 2e-16 ***\ntv           5.092e-02  2.232e-03  22.810  &lt; 2e-16 ***\nradio        3.516e-02  5.901e-03   5.959 1.17e-08 ***\nI(tv^2)     -1.097e-04  6.893e-06 -15.920  &lt; 2e-16 ***\ntv:radio     1.077e-03  3.466e-05  31.061  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6238 on 195 degrees of freedom\nMultiple R-squared:  0.986, Adjusted R-squared:  0.9857 \nF-statistic:  3432 on 4 and 195 DF,  p-value: &lt; 2.2e-16\n\nplot(modelo_interaccion_1$fitted.values, datos$ventas); lines(c(0,27), c(0,27))\n\n\n\n\n\n\n\nhist(modelo_interaccion_1$residuals); plot(density(modelo_interaccion_1$residuals)); shapiro.test(modelo_interaccion_1$residuals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  modelo_interaccion_1$residuals\nW = 0.80888, p-value = 6.359e-15\n\ndwtest(modelo_interaccion_1,alternative =\"two.sided\",iterations = 1000); bptest(modelo_interaccion_1)\n\n\n    Durbin-Watson test\n\ndata:  modelo_interaccion_1\nDW = 2.204, p-value = 0.1432\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_interaccion_1\nBP = 19.986, df = 4, p-value = 0.0005027\n\n\n\n\n7.2 2) Ejemplo adicional: dataset carprice (DAAG)\n\ndata(carprice)\npairs(carprice[,-c(1,8,9)]); \n\n\n\n\n\n\n\ncorrplot(cor(carprice[,-c(1,8,9)]),method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n\n\n\n\n\n\n\n\n\ncarprice1.lm &lt;- lm(gpm100 ~ Type + Min.Price + Price + Max.Price + Range.Price, data=carprice)\nsummary(carprice1.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Min.Price + Price + Max.Price + \n    Range.Price, data = carprice)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.48431 -0.22731 -0.03417  0.19004  0.49651 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.2874     0.1531  21.467  &lt; 2e-16 ***\nTypeLarge     0.3235     0.1733   1.867   0.0695 .  \nTypeMidsize   0.1849     0.1660   1.114   0.2722    \nTypeSmall    -0.3895     0.1681  -2.317   0.0258 *  \nTypeSporty    0.2055     0.1747   1.176   0.2467    \nTypeVan       1.3487     0.1927   6.997 2.16e-08 ***\nMin.Price     0.6997     0.9894   0.707   0.4836    \nPrice        -1.3773     1.9829  -0.695   0.4914    \nMax.Price     0.7106     0.9943   0.715   0.4791    \nRange.Price       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3059 on 39 degrees of freedom\nMultiple R-squared:  0.8149,    Adjusted R-squared:  0.777 \nF-statistic: 21.47 on 8 and 39 DF,  p-value: 4.768e-12\n\ncarprice2.lm &lt;- lm(gpm100 ~ Type + Max.Price, data=carprice)\nsummary(carprice2.lm)\n\n\nCall:\nlm(formula = gpm100 ~ Type + Max.Price, data = carprice)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5468 -0.2379 -0.0241  0.1842  0.5311 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.298110   0.150746  21.879  &lt; 2e-16 ***\nTypeLarge    0.368524   0.165541   2.226   0.0316 *  \nTypeMidsize  0.214006   0.162030   1.321   0.1939    \nTypeSmall   -0.386042   0.162609  -2.374   0.0224 *  \nTypeSporty   0.209540   0.166663   1.257   0.2158    \nTypeVan      1.367463   0.183242   7.463 3.69e-09 ***\nMax.Price    0.029982   0.006837   4.385 7.89e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3027 on 41 degrees of freedom\nMultiple R-squared:  0.8096,    Adjusted R-squared:  0.7817 \nF-statistic: 29.05 on 6 and 41 DF,  p-value: 2.782e-13\n\n\n\nepsilon &lt;- carprice2.lm$residuals\nhist(epsilon); shapiro.test(epsilon)\n\n\n\n\n\n\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  epsilon\nW = 0.95934, p-value = 0.09497\n\ndwtest(carprice2.lm,alternative =\"two.sided\",iterations = 1000)\n\n\n    Durbin-Watson test\n\ndata:  carprice2.lm\nDW = 1.7034, p-value = 0.295\nalternative hypothesis: true autocorrelation is not 0\n\ns &lt;- sqrt(sum(epsilon^2)/(41))\nplot(carprice$gpm100, carprice2.lm$fitted.values); lines(c(2,5.5),c(2,5.5))\n\n\n\n\n\n\n\nconfint(carprice2.lm)\n\n                  2.5 %      97.5 %\n(Intercept)  2.99367329  3.60254758\nTypeLarge    0.03420650  0.70284211\nTypeMidsize -0.11322061  0.54123280\nTypeSmall   -0.71443686 -0.05764682\nTypeSporty  -0.12704297  0.54612217\nTypeVan      0.99739791  1.73752784\nMax.Price    0.01617507  0.04378964\n\nout &lt;- summary(carprice2.lm); out$coefficients[ , 1]; out$coefficients[ , 2]\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n 3.29811043  0.36852431  0.21400610 -0.38604184  0.20953960  1.36746287 \n  Max.Price \n 0.02998236 \n\n\n(Intercept)   TypeLarge TypeMidsize   TypeSmall  TypeSporty     TypeVan \n0.150745713 0.165541483 0.162030238 0.162608744 0.166662906 0.183242118 \n  Max.Price \n0.006836843 \n\nse &lt;- sqrt(diag(vcov(carprice2.lm)))\n\n\nnuevo &lt;- data.frame(Type=c(\"Van\"), Max.Price=c(11))\nvalor_predicho &lt;- predict(object=carprice2.lm, newdata=nuevo)\nvalor_predicho\n\n       1 \n4.995379 \n\n\n\n\n7.3 3) Otro ejemplo con archivo externo millaje.txt (opcional)\n\nif (file.exists(file.path(data_path, \"millaje.txt\"))) {\n  millaje &lt;- read.table(file=file.path(data_path, \"millaje.txt\"), header=TRUE)\n  r_auto &lt;- cor(millaje); pairs(millaje); \n  corrplot(r_auto,method=\"circle\",type=\"lower\",diag=FALSE,tl.col=\"black\",tl.cex=1,tl.offset=0.1,tl.srt=45)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\")\n  modelo_lineal &lt;- lm(formula = mpg ~ hp + vol, data = millaje); summary(modelo_lineal)\n  plot(x = millaje$hp, y = millaje$mpg, main = \"Consumo vs potencia motor\", pch = 20, col = \"grey\"); abline(modelo_lineal, lwd = 3, col = \"red\")\n  modelo_pol2 &lt;- lm(formula = mpg ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2)\n  modelo_cuadratico &lt;- lm(formula = mpg ~ poly(hp, 2), data = millaje); summary(modelo_cuadratico)\n  plot(modelo_pol2$fitted.values, millaje$mpg); lines(c(10,60),c(10,60))\n  shapiro.test(modelo_pol2$residuals); hist(modelo_pol2$residuals); plot(density(modelo_pol2$residuals))\n  par(mfrow=c(2,2)); plot(modelo_pol2); par(mfrow=c(1,1))\n  anova(modelo_lineal, modelo_pol2)\n  plot(x = millaje$hp, y = millaje$mpg, main=\"Consumo vs potencia motor\", pch=20, col=\"grey\")\n  prediccion &lt;- predict(object = modelo_pol2, newdata = data.frame(hp = millaje$hp, vol=millaje$vol))\n  lines(sort(millaje$hp), prediccion[order(millaje$hp)], col = \"red\", lwd = 3)\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ hp + I(hp^2)) + labs(title = \"Consumo vs potencia motor\") + theme_bw()\n  ggplot(millaje, aes(x = hp, y = mpg)) + geom_point(colour = \"grey\") + stat_smooth(method = \"lm\", formula = y ~ poly(x, 2),  colour = \"red\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 5),  colour = \"blue\", se = FALSE) + stat_smooth(method = \"lm\", formula = y ~ poly(x, 10), colour = \"green\", se = FALSE) + labs(title = \"Polinomios de grados 2, 5, 10\") + theme_bw()\n  modelo_5 &lt;- lm(formula = mpg ~ poly(hp, 5), data = millaje); summary(modelo_5)\n  modelo_5_correjido &lt;- lm(formula = mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje); summary(modelo_5_correjido)\n  anova(modelo_cuadratico, modelo_5_correjido)\n  shapiro.test(modelo_5_correjido$residuals); hist(modelo_5_correjido$residuals); plot(density(modelo_5_correjido$residuals))\n  plot(modelo_5_correjido$fitted.values, millaje$mpg)\n  modelo_pol2_trans &lt;- lm(formula = log(1+mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol2_trans)\n  plot(modelo_pol2_trans$residuals,modelo_pol2_trans$fitted.values); plot(log(1+millaje$mpg),modelo_pol2_trans$fitted.values); lines(c(2,5),c(2,5))\n  shapiro.test(modelo_pol2_trans$residuals); hist(modelo_pol2_trans$residuals); plot(density(modelo_pol2_trans$residuals))\n  modelo_pol3_trans &lt;- lm(formula = sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol3_trans); shapiro.test(modelo_pol3_trans$residuals)\n  plot(modelo_pol3_trans$residuals,modelo_pol3_trans$fitted.values); plot(sqrt(millaje$mpg),modelo_pol3_trans$fitted.values); lines(c(4,8),c(4,8))\n  modelo_pol4_trans &lt;- lm(formula = 1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje); summary(modelo_pol4_trans)\n  plot(modelo_pol4_trans$residuals,modelo_pol4_trans$fitted.values); plot(1/sqrt(millaje$mpg),modelo_pol4_trans$fitted.values); shapiro.test(modelo_pol4_trans$residuals)\n  modelo_pol2_tran_2 &lt;- lm(formula = log(1+mpg) ~ vol + hp + log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_2)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_2$fitted.values); shapiro.test(modelo_pol2_tran_2$residuals); hist(modelo_pol2_tran_2$residuals); plot(density(modelo_pol2_tran_2$residuals)); plot(modelo_pol2_tran_2)\n  modelo_pol2_tran_3 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2), data = millaje); summary(modelo_pol2_tran_3)\n  shapiro.test(modelo_pol2_tran_3$residuals); plot(modelo_pol2_tran_3); plot(log(1+millaje$mpg),modelo_pol2_tran_3$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_4 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + I(1/(hp^2))+ log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_4)\n  plot(log(1+millaje$mpg),modelo_pol2_tran_4$fitted.values); lines(c(3,4.5),c(3,4.5))\n  modelo_pol2_tran_5 &lt;- lm(formula = log(1+mpg) ~ hp + I(1/(hp)) + log(1+hp) + I(hp^2)-1, data = millaje); summary(modelo_pol2_tran_5)\n  shapiro.test(modelo_pol2_tran_5$residuals); plot(log(1+millaje$mpg),modelo_pol2_tran_5$fitted.values); lines(c(3,4.5),c(3,4.5)); plot(modelo_pol2_tran_5)\n  modelo_pol2_tran_6 &lt;- lm(formula = log(1+mpg) ~ log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_6)\n  shapiro.test(modelo_pol2_tran_6$residuals); hist(modelo_pol2_tran_6$residuals); plot(density(modelo_pol2_tran_6$residuals)); plot(modelo_pol2_tran_6)\n  modelo_pol2_tran_7 &lt;- lm(formula = log(1+mpg) ~ vol + log(1+hp) -1, data = millaje); summary(modelo_pol2_tran_7)\n}"
  },
  {
    "objectID": "labs_epg/lab04_epg.html#bibliografía",
    "href": "labs_epg/lab04_epg.html#bibliografía",
    "title": "Laboratorio 4_epg: Uso de la Regresión Múltiple",
    "section": "8 Bibliografía",
    "text": "8 Bibliografía\nCrespo, F. A. (2021). Uso de la Regresión Múltiple. Universidad Alberto Hurtado."
  },
  {
    "objectID": "labs_eco/lab01_introR.html",
    "href": "labs_eco/lab01_introR.html",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "",
    "text": "El objetivo de este laboratorio presencial es familiarizarse con R y RStudio. El laboratorio se puede realizar en grupo, pero cada estudiante debe entregar su propio trabajo. Para obtener créditos, suba su script .R al lugar correspondiente en Canvas."
  },
  {
    "objectID": "labs_eco/lab01_introR.html#primeros-pasos",
    "href": "labs_eco/lab01_introR.html#primeros-pasos",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "Primeros pasos",
    "text": "Primeros pasos\n\nAbre RStudio en tu ordenador portátil\nHaz clic en Archivo &gt; Nuevo archivo &gt; Script R.\n\nVerás una sección en blanco en la parte superior izquierda de la ventana de RStudio. Aquí es donde escribirás tu primer script R.\n\nConsola\nEn la parte inferior izquierda de la pantalla hay una pestaña llamada «Consola». Básicamente, se trata de una calculadora muy sofisticada.\nPrueba la calculadora escribiendo algo como:\n\n2+2\n\nO incluso algo más sofisticado como:\n\nsqrt(pi)\n\n\n\nPaquetes\nR hace un uso extensivo de paquetes de terceros. No entraremos en detalles ahora mismo, pero para esta clase necesitarás instalar algunos de ellos. Instalar paquetes es bastante fácil. Escribe las dos líneas de código siguientes en la parte superior de tu script:\n\ninstall.packages(\"tidyverse\", repos='http://cran.us.r-project.org')\ninstall.packages(\"modelsummary\", repos='http://cran.us.r-project.org')\ninstall.packages(\"wooldridge\", repos='http://cran.us.r-project.org')\n\nAcabas de instalar tres paquetes. Básicamente, los has descargado en tu ordenador. Al igual que con cualquier otro software de tu ordenador, solo tienes que realizar la instalación una vez. Sin embargo, aún debes indicar a R que vas a utilizar los paquetes. Añade las dos líneas de código siguientes a tu script (debajo de las dos primeras líneas que has escrito). Fíjate en que esta vez no hay comillas dentro de los paréntesis.\n\nlibrary(tidyverse)\nlibrary(modelsummary)\nlibrary(wooldridge)\n\n\n\nEjecutar un script\nPara ejecutar el script, haz clic en la palabra «Fuente» en la esquina superior derecha del panel superior izquierdo de la ventana. Esto tomará lo que hay en tu script y lo enviará automáticamente a la consola (como si lo hubieras escrito directamente en la consola).\nPara guardar el script, haga clic en el icono del disco situado en la parte superior del panel del script (pero no en el icono del disco situado en la parte superior de RStudio). Asigne al script el nombre «ICL1_XYZ.R», donde «XYZ» son sus iniciales.\n\n\nComentarios\nAhora, coloca un hashtag (#) delante de las dos primeras líneas de código de tu script, así:\n\n#install.packages(\"tidyverse\")\n#install.packages(\"modelsummary\")\n#install.packages(\"wooldridge\")\n\nEl hashtag es la forma de indicarle a R que no ejecute el código de tu script. Esto se conoce como «comentar» tu código.\nEn la parte superior de tu script, escribe tu nombre precedido de un hashtag.\nA partir de ahora, añade todo el código que veas a tu script."
  },
  {
    "objectID": "labs_eco/lab01_introR.html#explorar-datos",
    "href": "labs_eco/lab01_introR.html#explorar-datos",
    "title": "Laboratorio 1 – Introducción a R y RStudio",
    "section": "Explorar datos",
    "text": "Explorar datos\nAhora que ya conoces algunos conceptos básicos de R, ¡veamos algunos datos!\n\nCarga de datos\nVamos a cargar un conjunto de datos del paquete wooldridge. El conjunto de datos se llama wage1.\n\ndf &lt;- as_tibble(wage1)\n\nLo que hicimos allí fue convertirlo a un «tibble», que es un formato muy útil para conjuntos de datos (véase el capítulo 10 de @r4ds). Llamamos al tibble convertido «df», pero puedes llamarlo como quieras: «mydata», «data123», lo que sea.\n\n\nNavegación\nSi vuelve a ejecutar el script (haciendo clic en «Fuente»… o mejor aún, haciendo clic en la pequeña flecha situada junto a «Fuente», que abre un menú en el que puede hacer clic en «Fuente con eco»), verá algo nuevo en la ventana «Entorno» (arriba a la derecha). Dice «df» bajo el encabezado «Datos».\nHaga doble clic en «df» en la ventana Entorno. Esto le mostrará sus datos en un formato similar a una hoja de cálculo de Excel. Puede utilizar esto para examinar fácilmente los datos y asegurarse de que todo parece razonable.\n\n\nEstadísticas resumidas\nVeamos las estadísticas resumidas de una de nuestras variables. Supongamos que queremos saber: ¿Cuál es el promedio de años de educación en nuestra muestra?\n\ndatasummary_skim(df)#then look at 'educ' column\n\nEn tu script, escribe el valor de la media de «educ», precedido por un comentario (el símbolo de almohadilla).\n¿Qué fracción de la muestra está compuesta por mujeres?\n\nmean(df$female)\n# or\ndatasummary_skim(df) #then look at 'female' column\n\n\n\nVisualización\nSupongamos que desea visualizar toda la distribución de la educación. Utilizaría el siguiente código:\n\nggplot(df, aes(educ)) + geom_histogram(binwidth=1)+theme_classic()\n\nEn un comentario, escribe el valor más común de la educación (la moda de la distribución) debajo del código en tu script.\nRepite los dos fragmentos de código anteriores, pero esta vez utiliza la variable wage en lugar de la variable educ.\n\n\nCreación de una nueva variable\nSupongamos que desea añadir una nueva variable a df. Por ejemplo, la variable salario se expresa en dólares de 1976 y desea saber cuál sería el salario en dólares actuales. (Nota: el IPC implica que 1 dólar de 1976 equivale a 4,53 dólares actuales).\n\ndf &lt;- df %&gt;% mutate(realwage=wage*4.53)\nsummary(df$realwage)\ndatasummary_skim(\n  df,\n  fun_numeric = list(\n    `Unique`        = NUnique,\n    `Missing Pct.`  = PercentMissing,\n    `Mean`          = Mean,\n    `SD`            = SD,\n    `Min`           = Min,\n    `Median`        = Median,\n    `Max`           = Max\n    # NOTA: aquí NO ponemos \"Histogram\"\n  )\n)\n# then look at realwage column\n\nPuede verificar que «realwage» se ha añadido a «df» haciendo clic en la vista previa de «df» y desplazándose completamente hacia la derecha.\nPara obtener más información sobre «mutate()», consulte la sección 5.5 de @r4ds. También puede eliminar una variable escribiendo «df &lt;- df %&gt;% mutate(realwage=NULL)».\n\n\nEliminar observaciones\nSupongamos que queremos eliminar a todos los hombres de nuestros datos. (Por ejemplo, tal vez estemos investigando sobre la participación de las mujeres en la población activa). Para ello, utilizamos la función filter().\nPara utilizar filter(), debe proporcionar las condiciones para mantener una observación específica. Añada lo siguiente a su script:\n\nsummary(df$female)\ndf &lt;- df %&gt;% filter(female==1)\nsummary(df$female)\n\nLe dijimos a R que conservara las observaciones en las que «female» era igual a 1. Se puede observar que, antes de la instrucción «filter()», las mujeres representaban el 48 % de los datos. Ahora, representan el 100 %. Por lo tanto, podemos verificar que «filter()» hizo lo que le pedimos.\n\n\nValores perdidos\nUna situación habitual en los datos observacionales transversales es la pérdida de valores. Por ejemplo, alguien deja en blanco una pregunta en una encuesta. O el salario de alguien que está desempleado no está definido. En R, los valores perdidos se almacenan como «NA» (que significa «no aplicable»). Para eliminar las observaciones «NA», utilice la función «drop_na()»:\n\nsummary(df$wage)\ndf &lt;- df %&gt;% drop_na(wage)\nsummary(df$wage)"
  },
  {
    "objectID": "eco_epg.html",
    "href": "eco_epg.html",
    "title": "Econometría para la Gestión",
    "section": "",
    "text": "esta\n\n\nCapitulo 1 -\n\nVer Laboratorio\n\n\ncapitulo 2 -\n\nVer Laboratorio"
  },
  {
    "objectID": "data_principal.html",
    "href": "data_principal.html",
    "title": "Encuestas",
    "section": "",
    "text": "Las bases de datos de encuestas incluidas en este repositorio reúnen información oficial y representativa de distintos ámbitos sociales y económicos de Chile, provenientes de instituciones como el Instituto Nacional de Estadísticas (INE) y el Ministerio de Desarrollo Social y Familia. Estas encuestas abarcan temas como salud, empleo, ingresos, gasto de los hogares y uso del tiempo, entre otros, permitiendo realizar análisis econométricos con un alto nivel de profundidad.\nEntre las principales se encuentran la Encuesta de Presupuestos Familiares, la Encuesta Nacional de Salud, la Encuesta de Uso del Tiempo y la Encuesta de Mercado Laboral, todas con una amplia cobertura de variables demográficas, laborales y socioeconómicas.\nEstas fuentes resultan especialmente valiosas para el desarrollo de modelos de regresión, estudios de determinantes sociales y económicos, y comparaciones entre grupos de población. Además, su estructura multidimensional permite combinar distintas áreas de análisis —como ingreso, género, educación y bienestar— fomentando una comprensión integral de la realidad económica y social del país.\nEn conjunto, estas encuestas constituyen una base sólida para el aprendizaje aplicado de la econometría, ofreciendo datos confiables y actualizados para desarrollar ejercicios, informes y proyectos con rigor estadístico.\nCada sección de datos cuenta con el mismo formato de presentacion, conteniendo las siguientes variables:"
  },
  {
    "objectID": "data_principal.html#buscador",
    "href": "data_principal.html#buscador",
    "title": "Encuestas",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (“search”) que facilita la exploración, que funciona a nivel de palabras claves, por ejemplo, si se escribe “economía”, el sistema buscará esa palabra en todas las columnas de la tabla (años, siglas, nombre, enlace y descripción). Esto permite filtrar de manera rápida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "codigos.html",
    "href": "codigos.html",
    "title": "Material de Estudio",
    "section": "",
    "text": "Bienvenido al Repositorio de Laboratorios y Materiales Prácticos de los cursos de Econometría FEN-UAH.\nEn este espacio encontrarás guías paso a paso desarrolladas en RStudio/Quarto, acompañadas de fundamentos teóricos y explicaciones conceptuales que facilitan el aprendizaje aplicado de la econometría, abarcando desde la regresión lineal simple hasta modelos econométricos más avanzados.\nEl material se organiza ahora en dos secciones específicas, según la mención del curso:\nCada laboratorio puede abrirse directamente en formato HTML renderizado, permitiendo revisar el código, los resultados y la interpretación de forma integrada."
  },
  {
    "objectID": "codigos.html#cursos",
    "href": "codigos.html#cursos",
    "title": "Material de Estudio",
    "section": "Cursos",
    "text": "Cursos\n\n\nEconometría Mención Economía\n\nVer Curso\n\n\nEconometría para la Gestión Mención Administración\n\nVer Curso"
  },
  {
    "objectID": "index.html#descripción-del-sitio-web",
    "href": "index.html#descripción-del-sitio-web",
    "title": "",
    "section": "Descripción del Sitio Web",
    "text": "Descripción del Sitio Web\nEste sitio web es una iniciativa conjunta de los profesores Fernando Crespo y Rocío Valdebenito, docentes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado (UAH). Está dirigido a los estudiantes de la carrera de Ingeniería Comercial, con mención en Economía y Administración de Empresas, que cursan las asignaturas de Econometría.\nEl objetivo principal de esta página es que los estudiantes se familiaricen con el uso de bases de datos y aprendan a utilizar el software R y Rstudio como herramienta para analizar y responder preguntas de investigación. Como parte fundamental del aprendizaje, los estudiantes desarrollan un proyecto aplicado, el cual es presentado en formato de póster y expuesto frente a la comunidad académica.\nPara acompañar este proceso, el sitio web se organiza en tres secciones principales:\n\nDatos:\n\n\nMaterial de Estudio:\n\n\nProyectos:\nEn conjunto, este sitio busca convertirse en un centro de recursos para la formación en econometría, promoviendo el uso de datos y herramientas de análisis como competencias clave para la futura labor profesional de los estudiantes de Ingeniería Comercial de la UAH."
  },
  {
    "objectID": "index.html#docentes-y-ayudante",
    "href": "index.html#docentes-y-ayudante",
    "title": "",
    "section": "Docentes y Ayudante",
    "text": "Docentes y Ayudante\n\nRocío Valdebenito: Docente e Investigadora\nLa Dra. Rocío Valdebenito es académica con formación y afiliación en Ingeniera Comercial y Máster en Management de la Universidad Adolfo Ibáñez (UAI) y Doctorado (Ph.D.) en Economía Aplicada de la University of Illinois at Urbana-Champaign (EE. UU., 2024). Actualmente es Profesora en la Facultad de Economía y Negocios (FEN) de la Universidad Alberto Hurtado (UAH).\n\nAmador Marin Torres: Ayudante Econometría mención Economía\nEs un estudiante de Ingeniería Comercial con Mención en Economía de la Universidad Alberto Hurtado (UAH). desempeñándose como Ayudante de Cátedra de multiples cursos a lo largo de su carrera universitaria.\n\n\n\nFernando Crespo: Docente e Investigador\nEl profesor Fernando Crespo es un experto en Ciencia de Datos, Machine Learning y Modelos Matemáticos Aplicados. Es Doctor en Ciencias de la Ingeniería por la Pontificia Universidad Católica de Chile y actualmente se desempeña como Profesor en la Universidad Alberto Hurtado.\n\nManuel Labraña Rojas: Ayudante\nManuel Labraña Rojas es un estudiante de Ingeniería Comercial con Mención en Economía de la Universidad Alberto Hurtado (UAH). desempeñándose como Ayudante de Cátedra. Además, colabora en el área de investigación como Ayudante del proyecto “Repositorio de Econometría”, contribuyendo a su funcionamiento y desarrollo web."
  },
  {
    "objectID": "datos.html",
    "href": "datos.html",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\nInstituto Nacional de Estadistica, a través de su sistema INE-DATOS.\n\nse proyecta integrar información de ODEPAen el caso de queerer realizar un proyecto orientado al sector agricola y otros organismos públicos vinculados al ámbito económico, social y producitivo."
  },
  {
    "objectID": "datos.html#section",
    "href": "datos.html#section",
    "title": "Repositorio de Datos",
    "section": "",
    "text": "En este apartado se reúnen diversas fuentes de información estadística y bases de datos relevantes para el análisis económico y social de Chile y el mundo. El objetivo es que los estudiantes cuenten con un repositorio único y accesible, desde el cual puedan explorar y trabajar con información oficial y validada.\nLas bases provienen de distintas instituciones nacionales e internacionales, entre ellas:\n\nMinisterio de Desarrollo Social y Familia, a través del Observatorio Social, que incluye la Encuesta CASEN y otros levantamientos de interés.\nCentro de Microdatos de la Universidad de Chile, que publica encuestas de empleo, ingresos y otros estudios.\nDEMRE, con datos asociados a los procesos de admisión universitaria (PSU, PAES, etc.).\nMinisterio de Educación (Mineduc), mediante su portal de datos abiertos.\nBanco Mundial y Banco Interamericano de Desarrollo (BID), que ofrecen estadísticas comparables a nivel internacional.\nMinisterio de Ciencia, Tecnología, Conocimiento e Innovación, con la Encuesta Nacional de Innovación.\nPortal de Datos Abiertos del Estado de Chile (datos.gob.cl)\nMinisterio de Economía, con encuestas y bases orientadas a la actividad económica.\nBanco Central de Chile, a través de su sistema SIETE.\nInstituto Nacional de Estadistica, a través de su sistema INE-DATOS.\n\nse proyecta integrar información de ODEPAen el caso de queerer realizar un proyecto orientado al sector agricola y otros organismos públicos vinculados al ámbito económico, social y producitivo."
  },
  {
    "objectID": "datos.html#tabla-de-bases-de-datos",
    "href": "datos.html#tabla-de-bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Tabla de bases de datos",
    "text": "Tabla de bases de datos\nDebajo encontrarás dos pestañas interactiva que contiene la siguiente información:\n\nEncuestas: Se recomienda que quienes realizan por primera vez trabajos de econometría, sin experiencia previa en RStudio y con un manejo intermedio de Excel, utilicen bases de datos provenientes de encuestas o que ya contengan múltiples variables integradas. Esto permite evitar el proceso de combinar distintas fuentes de información, lo cual podría generar errores en la manipulación y pérdida de consistencia en los datos si no se aplican las precauciones adecuadas.\nDatos Administrativos: Estos datos son útiles para desarrollar trabajos de econometría y pueden conducir a resultados interesantes; sin embargo, su manipulación presenta mayor complejidad, ya que suelen requerir la integración con otras bases de datos. Por ello, es recomendable contar con un nivel intermedio de manejo en RStudio y Excel. Si decides trabajar con información de esta sección, se sugiere consultar a los docentes del curso para asegurar una correcta gestión y procesamiento de los datos."
  },
  {
    "objectID": "datos.html#bases-de-datos",
    "href": "datos.html#bases-de-datos",
    "title": "Repositorio de Datos",
    "section": "Bases de Datos",
    "text": "Bases de Datos\n\n\nEncuestas\n\nVer Datos\n\n\nDatos Administrativos\n\nVer Datos"
  },
  {
    "objectID": "proyectos.html",
    "href": "proyectos.html",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES"
  },
  {
    "objectID": "proyectos.html#section",
    "href": "proyectos.html#section",
    "title": "Proyectos",
    "section": "",
    "text": "La sección Proyectos tiene como propósito ofrecer un espacio para que los estudiantes de la Facultad de Economía y Negocios de la Universidad Alberto Hurtado puedan publicar y compartir sus trabajos e investigaciones desarrolladas en los cursos de Econometría y Econometría para la Gestión.\nEste repositorio busca fomentar un entorno de aprendizaje colaborativo e interactivo, donde tanto docentes como estudiantes puedan evaluar, comentar y retroalimentar los proyectos presentados. De esta forma, se promueve la aplicación práctica de los contenidos del curso y el fortalecimiento de las habilidades analíticas y comunicacionales de los futuros profesionales.\nAUN NO DISPONIBLE, EVALUANDO COMPATIBILIDAD CON GOOGLE FORMS U OTRAS APLICACIONES"
  },
  {
    "objectID": "data_secundaria.html",
    "href": "data_secundaria.html",
    "title": "Datos Administrativos",
    "section": "",
    "text": "Las bases de datos agrupadas en esta sección corresponden a fuentes estadísticas complementarias que, si bien contienen una menor cantidad de variables, ofrecen información clave para desarrollar análisis econométricos enfocados y temáticamente específicos.\nIncluyen registros provenientes de distintas instituciones nacionales e internacionales —como el Banco Central de Chile, el Ministerio de Economía, el Banco Mundial, el Banco Interamericano de Desarrollo (BID) y otros organismos del Estado— que proporcionan indicadores macroeconómicos, series de precios, productividad, informalidad laboral, microemprendimiento, turismo y diversos aspectos del desarrollo económico y social.\nSi bien estas bases no tienen la amplitud de variables de las grandes encuestas sociales, su profundidad temática permite construir modelos de regresión y análisis descriptivos centrados en temas concretos, como la evolución del empleo formal e informal, la estructura de costos laborales, el comportamiento del sector agrícola o los determinantes de la actividad turística.\nPor su naturaleza más técnica, la manipulación de estas bases puede requerir un manejo intermedio o avanzado en RStudio y Excel, especialmente cuando se busca complementar distintas fuentes o realizar integraciones de series temporales. No obstante, su correcta utilización brinda la oportunidad de generar análisis aplicados y resultados interpretables que fortalecen el aprendizaje práctico de la econometría y la gestión de datos económicos.\nCada sección de datos cuenta con el mismo formato de presentacion, conteniendo las siguientes variables:"
  },
  {
    "objectID": "data_secundaria.html#buscador",
    "href": "data_secundaria.html#buscador",
    "title": "Datos Administrativos",
    "section": "Buscador",
    "text": "Buscador\nLa tabla cuenta con un buscador general (“search”) que facilita la exploración, que funciona a nivel de palabras claves, por ejemplo, si se escribe “economía”, el sistema buscará esa palabra en todas las columnas de la tabla (años, siglas, nombre, enlace y descripción). Esto permite filtrar de manera rápida y flexible las opciones disponibles, sin necesidad de revisar manualmente fila por fila."
  },
  {
    "objectID": "eco_eco.html",
    "href": "eco_eco.html",
    "title": "Econometría - Mención Economía",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML, PDF y archivo fuente (R Markdown/Quarto).\n\nIntroducción a R y pasos básicos de limpieza de datos\n\nHTML PDF R Markdown\n\nRegresión lineal simple\n\nHTML PDF R Markdown\n\nRegresión bivariada y transformaciones\n\nHTML PDF R Markdown\n\nRegresión lineal múltiple\n\nHTML PDF R Markdown\n\nSesgo por variable omitida y multicolinealidad\n\nHTML PDF R Markdown\n\nVariables dummy y modelo de probabilidad lineal (MPL)\n\nHTML PDF R Markdown\n\nPruebas de hipótesis individuales sobre parámetros\n\nHTML PDF R Markdown\n\nPruebas conjuntas de hipótesis\n\nHTML PDF R Markdown\n\nHeterocedasticidad e inferencia robusta\n\nHTML PDF R Markdown"
  },
  {
    "objectID": "eco_eco.html#laboratorios",
    "href": "eco_eco.html#laboratorios",
    "title": "Econometría - Mención Economía",
    "section": "",
    "text": "Objetivos:\n\nIntroducir conceptos de programación en R/Quarto,\n\nPracticar estimadores econométricos vistos en el curso,\n\nDesarrollar intuición aplicada a partir de datos reales.\n\nA continuación se presenta un listado completo de los laboratorios, disponibles en tres formatos: HTML, PDF y archivo fuente (R Markdown/Quarto).\n\nIntroducción a R y pasos básicos de limpieza de datos\n\nHTML PDF R Markdown\n\nRegresión lineal simple\n\nHTML PDF R Markdown\n\nRegresión bivariada y transformaciones\n\nHTML PDF R Markdown\n\nRegresión lineal múltiple\n\nHTML PDF R Markdown\n\nSesgo por variable omitida y multicolinealidad\n\nHTML PDF R Markdown\n\nVariables dummy y modelo de probabilidad lineal (MPL)\n\nHTML PDF R Markdown\n\nPruebas de hipótesis individuales sobre parámetros\n\nHTML PDF R Markdown\n\nPruebas conjuntas de hipótesis\n\nHTML PDF R Markdown\n\nHeterocedasticidad e inferencia robusta\n\nHTML PDF R Markdown"
  },
  {
    "objectID": "labs_epg/lab01_epg.html",
    "href": "labs_epg/lab01_epg.html",
    "title": "01_Introducción_y_Estadística_Descriptiva",
    "section": "",
    "text": "Este laboratorio se basa en el documento “01_Introducción_y_Estadística_Descriptiva (versión imprimible)”, donde se revisan los conceptos fundamentales de la estadística descriptiva y su aplicación práctica en RStudio.\n\nDescargar documento en PDF\n\n\n\n\nIntroducción a la estadística\n\nConcepto de variable aleatoria y datos\nTipos de datos: cualitativos y cuantitativos\n\n\nMétodos gráficos para datos cualitativos y cuantitativos\n\nGráfico de barras, torta y Pareto\n\nHistogramas y densidades\n\nMedidas numéricas\n\nMedia, mediana, moda, rango, varianza, desviación estándar, coeficiente de variación\n\n\nDistribuciones y normalidad\n\nPruebas de Shapiro-Wilk y Kolmogorov-Smirnov\n\nQ-Q plot\n\n\nAsimetría y curtosis"
  },
  {
    "objectID": "labs_epg/lab01_epg.html#contenido-del-pdf",
    "href": "labs_epg/lab01_epg.html#contenido-del-pdf",
    "title": "01_Introducción_y_Estadística_Descriptiva",
    "section": "",
    "text": "Introducción a la estadística\n\nConcepto de variable aleatoria y datos\nTipos de datos: cualitativos y cuantitativos\n\n\nMétodos gráficos para datos cualitativos y cuantitativos\n\nGráfico de barras, torta y Pareto\n\nHistogramas y densidades\n\nMedidas numéricas\n\nMedia, mediana, moda, rango, varianza, desviación estándar, coeficiente de variación\n\n\nDistribuciones y normalidad\n\nPruebas de Shapiro-Wilk y Kolmogorov-Smirnov\n\nQ-Q plot\n\n\nAsimetría y curtosis"
  },
  {
    "objectID": "labs_epg/lab03_epg.html",
    "href": "labs_epg/lab03_epg.html",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "",
    "text": "Material de apoyo elaborado a partir del texto de Fernando A. Crespo R. (2021) para el curso Econometría para la Gestión — FEN-UAH."
  },
  {
    "objectID": "labs_epg/lab03_epg.html#regresión-múltiple",
    "href": "labs_epg/lab03_epg.html#regresión-múltiple",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "1 Regresión Múltiple",
    "text": "1 Regresión Múltiple\nLo primero en un modelo de regresión múltiple es estudiar la relación entre las variables.\nPara ello se utiliza la matriz de correlación, donde se despliegan los coeficientes de correlación para cada par de variables.\nMulticolinealidad: ocurre cuando dos o más variables presentan una alta correlación entre ellas.\nEsto implica que existe una relación directa entre las variables, haciendo difícil determinar cuánto aporta cada una a la explicación de la variable dependiente.\nDos variables con alta correlación no proporcionan información adicional.\nRegla general para elegir variables:\n\nNo debe haber correlación alta entre variables predictoras o explicativas (\\(x\\)).\n\nSe debe preferir incluir variables independientes entre sí."
  },
  {
    "objectID": "labs_epg/lab03_epg.html#marco-teórico-modelo-clásico-de-regresión-múltiple-lineal",
    "href": "labs_epg/lab03_epg.html#marco-teórico-modelo-clásico-de-regresión-múltiple-lineal",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "2 Marco Teórico: Modelo Clásico de Regresión Múltiple Lineal",
    "text": "2 Marco Teórico: Modelo Clásico de Regresión Múltiple Lineal\nEl modelo lineal múltiple se puede escribir de forma matricial como:\n\\[\ny = 1_n \\beta_0 + x_1 \\beta_1 + x_2 \\beta_2 + \\dots + x_k \\beta_k + \\varepsilon\n\\tag{3.1}\n\\]\no en forma compacta:\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.2}\n\\]\ndonde:\n- \\(Y\\) es el vector de observaciones dependientes (\\(n \\times 1\\)).\n- \\(X\\) es la matriz de observaciones de las variables explicativas (\\(n \\times (k+1)\\)).\n- \\(\\beta\\) es el vector de parámetros desconocidos (\\(\\beta_0, \\beta_1, \\dots, \\beta_k\\)).\n- \\(\\varepsilon\\) es el vector de errores aleatorios."
  },
  {
    "objectID": "labs_epg/lab03_epg.html#supuestos-del-modelo-clásico",
    "href": "labs_epg/lab03_epg.html#supuestos-del-modelo-clásico",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "3 Supuestos del Modelo Clásico",
    "text": "3 Supuestos del Modelo Clásico\n\n3.1 Supuesto 1\n\\[\nY = X\\beta + \\varepsilon\n\\tag{3.3}\n\\]\n\n\n3.2 Supuesto 2\n\\(X \\in \\mathbb{R}^{n \\times (k+1)}\\) tiene rango completo (condición de identificación).\n\n\n3.3 Supuesto 3\nEl error tiene esperanza condicional nula:\n\\[\nE[\\varepsilon | X] =\n\\begin{bmatrix}\nE[\\varepsilon_1|X] \\\\\nE[\\varepsilon_2|X] \\\\\n\\vdots \\\\\nE[\\varepsilon_n|X]\n\\end{bmatrix}\n= 0\n\\tag{3.4}\n\\]\nAdemás:\n\\[\n\\text{Var}[\\varepsilon_j | X] = \\sigma^2, \\quad j = 1, \\dots, n\n\\tag{3.5}\n\\]\n\\[\n\\text{Cov}[\\varepsilon_i, \\varepsilon_j | X] = 0, \\quad i \\neq j\n\\tag{3.6}\n\\]\nEsto implica homocedasticidad (varianza constante) y no autocorrelación entre los errores.\n\n\n3.4 Supuesto 4\n\\[\nE[\\varepsilon \\varepsilon'] = \\sigma^2 I_n\n\\tag{3.7}\n\\]\n\n\n3.5 Supuesto 5\n\\(X\\) es no estocástica, es decir, se asume conocida o fija en el muestreo.\n\n\n3.6 Supuesto 6\nLos errores son normales:\n\\[\n\\varepsilon | X \\sim N(0, \\sigma^2 I_n)\n\\tag{3.8}\n\\]"
  },
  {
    "objectID": "labs_epg/lab03_epg.html#estimadores-de-la-regresión",
    "href": "labs_epg/lab03_epg.html#estimadores-de-la-regresión",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "4 Estimadores de la Regresión",
    "text": "4 Estimadores de la Regresión\nLos estimadores se pueden obtener por dos vías:\n\nMáxima verosimilitud, dada la normalidad de los errores.\n\nMínimos cuadrados ordinarios (OLS).\n\nMinimizamos la suma de cuadrados de los errores:\n\\[\nS(\\beta) = (Y - X\\beta)'(Y - X\\beta)\n\\tag{3.9}\n\\]\nDesarrollando:\n\\[\nS(\\beta) = Y'Y - 2Y'X\\beta + \\beta'(X'X)\\beta\n\\tag{3.10}\n\\]\nDerivando respecto a \\(\\beta\\) e igualando a cero:\n\\[\nS'(\\beta) = -2X'Y + 2(X'X)\\beta = 0\n\\tag{3.11}\n\\]\nDe donde obtenemos el estimador:\n\\[\n\\hat{\\beta} = (X'X)^{-1}X'Y\n\\tag{3.12}\n\\]\nEl vector estimado de valores ajustados es:\n\\[\n\\hat{Y} = X\\hat{\\beta} = X(X'X)^{-1}X'Y\n\\tag{3.13}\n\\]\nY los residuos estimados:\n\\[\n\\hat{\\varepsilon} = Y - \\hat{Y} = (I - X(X'X)^{-1}X')Y\n\\tag{3.14}\n\\]\n\nPropiedades útiles:\n\\[\nX'\\hat{\\varepsilon} = 0, \\qquad \\hat{Y}'\\hat{\\varepsilon} = 0\n\\tag{3.15}\n\\]\nLa variación cuadrática de los residuos es:\n\\[\n\\hat{\\varepsilon}'\\hat{\\varepsilon} = Y'(I - X(X'X)^{-1}X')Y\n\\tag{3.16}\n\\]"
  },
  {
    "objectID": "labs_epg/lab03_epg.html#coeficiente-de-determinación-r2",
    "href": "labs_epg/lab03_epg.html#coeficiente-de-determinación-r2",
    "title": "Laboratorio 3_epg: Regresión Múltiple",
    "section": "5 Coeficiente de Determinación (\\(R^2\\))",
    "text": "5 Coeficiente de Determinación (\\(R^2\\))\nA partir de (3.16):\n\\[\nY'Y = (\\hat{Y} + \\hat{\\varepsilon})'(\\hat{Y} + \\hat{\\varepsilon}) = \\hat{Y}'\\hat{Y} + \\hat{\\varepsilon}'\\hat{\\varepsilon}\n\\tag{3.17}\n\\]\nEn términos de varianzas:\n\\[\n\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2 = \\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2 + \\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2\n\\tag{3.18}\n\\]\nPor tanto:\n\\[\nR^2 = 1 - \\frac{\\sum_{j=1}^{n}\\hat{\\varepsilon}_j^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n= \\frac{\\sum_{j=1}^{n}(\\hat{Y}_j - \\bar{Y})^2}{\\sum_{j=1}^{n}(Y_j - \\bar{Y})^2}\n\\tag{3.19}\n\\]\n\n\n5.1 Contraste F global\nHipótesis:\n\\[\nH_0: \\beta_1 = \\beta_2 = \\dots = \\beta_k = 0\n\\tag{3.20}\n\\]\nEl estadístico es:\n\\[\nF = \\frac{R^2 / k}{(1 - R^2) / (n - k - 1)} \\sim F_{k,\\, n - k - 1}\n\\tag{3.21}\n\\]\nRechazamos \\(H_0\\) si \\(P(F \\ge f) \\le \\alpha\\).\n\n\n\n5.2 Propiedades de los estimadores\n\\[\nE[\\hat{\\beta}] = \\beta, \\qquad\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X'X)^{-1}\n\\tag{3.22}\n\\]\nPara los residuos:\n\\[\nE[\\hat{\\varepsilon}] = 0, \\qquad\n\\text{Cov}(\\hat{\\varepsilon}) = \\sigma^2 [I - X(X'X)^{-1}X']\n\\tag{3.23}\n\\]\nEstimador insesgado de \\(\\sigma^2\\):\n\\[\ns^2 = \\frac{\\hat{\\varepsilon}'\\hat{\\varepsilon}}{n - k - 1}\n\\tag{3.24}\n\\]\n\n\n\n5.3 Contraste individual para \\(\\beta_j\\)\n\\[\nH_0: \\beta_j = \\beta_j^*, \\qquad H_1: \\beta_j \\neq \\beta_j^*\n\\tag{3.25}\n\\]\nEl estadístico:\n\\[\nt_j = \\frac{\\hat{\\beta}_j - \\beta_j^*}{s \\sqrt{(X'X)^{-1}_{jj}}}\n\\sim t_{n - k - 1}\n\\tag{3.26}\n\\]\nRechazamos \\(H_0\\) si \\(|t_j| &gt; t_{\\alpha/2,\\, n - k - 1}\\).\nEl p-valor se obtiene como:\n\\[\np = P(|t_j| &gt; |t_j^{obs}|)\n\\tag{3.27}\n\\]\n\n\n\n5.4 Intervalos de confianza\nPara cada \\(\\beta_j\\):\n\\[\n\\hat{\\beta}_j \\pm t_{\\alpha/2,\\, n - k - 1} \\, s \\sqrt{(X'X)^{-1}_{jj}}\n\\tag{3.28}\n\\]\nPara la varianza del error:\n\\[\n\\left[\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, 1 - \\alpha/2}},\n\\quad\n\\frac{(n - k - 1)s^2}{\\chi^2_{n - k - 1,\\, \\alpha/2}}\n\\right]\n\\tag{3.29}\n\\]\n\n\n\n5.5 Predicción\nPara un nuevo vector \\(x_0\\) (incluyendo el valor 1 si el modelo tiene constante):\n\\[\n\\hat{y}_0 = x_0' \\hat{\\beta}\n\\tag{3.30}\n\\]\nVarianza del estimador:\n\\[\nh_0 = x_0'(X'X)^{-1}x_0\n\\tag{3.31}\n\\]\nIntervalo de confianza para la predicción:\n\\[\n\\hat{y}_0 \\pm s \\sqrt{1 + h_0} \\; t_{\\alpha/2,\\, n - k - 1}\n\\tag{3.32}\n\\]\n\n\n\n5.6 Diagnósticos de supuestos\nDurbin–Watson (autocorrelación de errores):\n\\[\nD = \\frac{\\sum_{i=2}^{n} (e_i - e_{i-1})^2}{\\sum_{i=1}^{n} e_i^2}\n\\tag{3.33}\n\\]\n\nSi \\(D \\approx 2\\): no hay autocorrelación.\n\nSi \\(D \\approx 0\\): autocorrelación positiva.\n\nSi \\(D \\approx 4\\): autocorrelación negativa.\n\n\nTest de Breusch–Pagan (homocedasticidad):\n\\[\nH_0: \\text{Var}(\\varepsilon_i) = \\sigma^2 \\quad \\forall i\n\\tag{3.34}\n\\]\nSi el valor-p es mayor que 0.05, se asume que los errores tienen varianza constante.\n\n\n✅ Resumen:\nEl modelo clásico de regresión múltiple lineal supone linealidad, independencia, homocedasticidad y normalidad.\nLos estimadores OLS son BLUE (Best Linear Unbiased Estimators) bajo estos supuestos.\n\nCrespo, F. A. (2021). Regresión Múltiple. Universidad Alberto Hurtado."
  }
]