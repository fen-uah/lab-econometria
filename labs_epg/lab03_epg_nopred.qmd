---
title: "Capitulo_3_Regresion_Multiple"
author: "Econometr√≠a para la Gesti√≥n (ECO_EPG) - FEN UAH"
lang: es
format:
  html:
    toc: true
    number-sections: true
    smooth-scroll: true
    self-contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo    = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center"
)
```


# 1. Material descargable

[Descargar PDF de contenidos te√≥ricos](pdf_epg/Capitulo_3_Regresion_Multiple.pdf){download="true"}


El documento incluye:

- Matriz de correlaci√≥n y multicolinealidad.  
- Supuestos del modelo cl√°sico de regresi√≥n m√∫ltiple.  
- Derivaci√≥n de estimadores OLS $(X'X)^{-1}X'Y$.  
- Varianza del error y matriz de covarianza del estimador.  
- $R^2$, $R^2$ ajustado y prueba F global.  
- Inferencia individual sobre coeficientes ($t$-tests).  
- Intervalos de confianza.  
- Pruebas de autocorrelaci√≥n y heterocedasticidad.

# Configuraci√≥n inicial

```{r}
library(openxlsx)
library(corrplot)
library(lmtest)
```

Definimos tu ruta de datos:

```{r}
ruta_datos <- "C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg"
list.files(ruta_datos)
```

# Lectura de datos

```{r}
archivo <- file.path(ruta_datos, "costos.xlsx")
datos <- read.xlsx(archivo, sheet="Hoja1", colNames=TRUE)
head(datos)
```

Los datos contienen:

- **Costos_generales** (variable dependiente).  
- **Horas_maquina** y **Numero_preparaciones** (variables explicativas).

# Matriz de correlaci√≥n

La matriz de correlaci√≥n nos permite:

- Detectar **relaciones lineales** entre pares de variables.  
- Identificar **multicolinealidad** entre regresores.

```{r}
r <- cor(datos)
r
```

### Gr√°ficos de exploraci√≥n

```{r}
pairs(datos)
corrplot(r, method="circle", type="lower", diag=FALSE,
         tl.col="black", tl.cex=1, tl.srt=45)
```

::: {.callout-note}
üîç **Interpretaci√≥n pedag√≥gica:**  
- Valores altos en la correlaci√≥n entre regresores ‚Üí **multicolinealidad**.  
- Esto puede inflar varianzas de los estimadores y hacer inestables los coeficientes.  
- La matriz y el `corrplot` permiten detectar problemas antes de ajustar el modelo.
:::

# Modelo de regresi√≥n m√∫ltiple

Ajustamos el modelo:

$$
\text{Costos} = \beta_0 + \beta_1(\text{Horas\_maquina}) + \beta_2(\text{Numero\_preparaciones}) + \varepsilon
$$

```{r}
modelo <- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones, data=datos)
summary(modelo)
```

::: {.callout-note}
- **Prueba individual (t test):** eval√∫a si cada \(\beta_j\) es distinto de 0.  
- **Prueba global (F test):** eval√∫a si el modelo en conjunto explica la variable dependiente.  
- **Signo de \(\beta_j\):** indica direcci√≥n del efecto.  
- **Magnitud:** indica cu√°nto cambia Y ante un cambio unitario en el regresor.  
- **p-values peque√±os:** evidencia estad√≠stica de relaci√≥n significativa.
:::

# Residuos del modelo

```{r}
epsilon <- modelo$residuals
hist(epsilon)
plot(density(epsilon))
mean(epsilon)
```

### Normalidad de los residuos

```{r}
shapiro.test(epsilon)
```

### Autocorrelaci√≥n (Durbin‚ÄìWatson)

```{r}
dwtest(modelo, alternative="two.sided", iterations=1000)
```

Interpretaci√≥n:
- DW ‚âà 2 ‚Üí no autocorrelaci√≥n  
- DW < 2 ‚Üí autocorrelaci√≥n positiva  
- DW > 2 ‚Üí autocorrelaci√≥n negativa  

### Heterocedasticidad (Breusch‚ÄìPagan)

```{r}
bptest(modelo)
```

# Estad√≠stico F calculado a mano

```{r}
R2 <- 0.9472
F <- (R2/2)/((1-R2)/(12-3))
F
qf(0.05, 2, 9, lower.tail=FALSE)
```

Interpretaci√≥n: si F calculado > F cr√≠tico ‚Üí el modelo **aporta informaci√≥n significativa**.

# Desviaci√≥n est√°ndar del error

```{r}
s <- sqrt(sum(epsilon^2)/(12-2-1))
s
```

# Intervalos de confianza de los coeficientes

```{r}
confint(modelo)
```

### C√°lculo manual del intervalo

```{r}
se <- sqrt(diag(vcov(modelo)))
t <- -1*qt(0.025, 12-2-1, lower.tail=FALSE)

BHM <- 65.44
sbhm <- 6.74

limitsupBHM <- BHM + t*sbhm
limitinfBHM <- BHM - t*sbhm
limitsupBHM; limitinfBHM
```

# Intervalo para la varianza del error

```{r}
gamma1 <- qchisq(0.025, 12-2-1)
gamma2 <- qchisq(0.975, 12-2-1)

s2_LI <- (12-2-1) * s^2 / gamma2
s2_LS <- (12-2-1) * s^2 / gamma1

s2_LI; s2_LS
```

# Predicci√≥n puntual

```{r}
nuevo <- data.frame(Horas_maquina=2000, Numero_preparaciones=220)

valor_predicho <- predict(modelo, newdata=nuevo)
valor_predicho
```

# Intervalo de confianza con `predict`

```{r}
valor_predicho2 <- predict(modelo, newdata=nuevo, interval="confidence")
valor_predicho2
```

# Predicci√≥n manual paso a paso

Construimos la matriz \(X\):

```{r}
X <- cbind(1, datos$Horas_maquina, datos$Numero_preparaciones)
M <- solve(t(X) %*% X)
beta <- M %*% t(X) %*% datos$Costos_generales

x0 <- c(1, 2000, 220)
h0 <- t(x0) %*% M %*% x0

y0 <- t(beta) %*% x0
y0
```

### Intervalo manual

```{r}
y_limsup <- y0 + s*sqrt(1+h0)*qt(0.975, 12-2-1, lower.tail=FALSE)
y_liminf <- y0 - s*sqrt(1+h0)*qt(0.975, 12-2-1, lower.tail=FALSE)

y_liminf; y_limsup
```

# Gr√°fico Y real vs Y predicho

```{r}
plot(modelo$fitted.values, datos$Costos_generales,
     main="Revisi√≥n Valor Real vs Valor Predicho")
lines(c(140000,200000), c(140000,200000))
```

# Modelo sin constante

```{r}
modelo2 <- lm(Costos_generales ~ Horas_maquina + Numero_preparaciones - 1, data=datos)
summary(modelo2)
```

### An√°lisis de residuos modelo sin constante

```{r}
epsilon <- modelo2$residuals
hist(epsilon)
plot(density(epsilon))
shapiro.test(epsilon)

dwtest(modelo2,alternative="two.sided",iterations=1000)
bptest(modelo2)
```

