---
title: "Capitulo_4_Uso_de_la_Regresion_Multiple"
author: "Econometría para la Gestión (ECO_EPG) - FEN UAH"
lang: es
format:
  html:
    toc: true
  pdf:
    pdf-engine: xelatex
    toc: true
    include-in-header:
      text: |
        \usepackage[spanish,es-nodecimaldot]{babel}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo    = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center"
)
```


# 1. Material descargable

[Descargar PDF de contenidos teóricos](pdf_epg/Capitulo_4_Uso_de_la_Regresion_Multiple.pdf){download="true"}

# Configuración inicial en R

## Carga de librerías

```{r librerias}
library(openxlsx)
library(MASS)      # funciones adicionales para modelos lineales
library(corrplot)  # correlaciones gráficas
library(lmtest)    # pruebas como Durbin-Watson, Breusch-Pagan
library(ggplot2)   # gráficos avanzados
```

## Definir ruta de trabajo

En tu proyecto utilizaremos la ruta:

```{r ruta-datos}
ruta_datos <- "C:/Users/manue/Desktop/lab-econometria/labs_epg/data_epg"

# Verificamos que la carpeta exista y revisamos algunos archivos
list.files(ruta_datos)
```

::: {.callout-tip}
Si copias este laboratorio a otro computador, solo deberás **cambiar la ruta** de `ruta_datos` para que apunte a la nueva carpeta donde estén `millaje.txt` y otros archivos de datos.
:::

# Parte 1: Regresión múltiple con inversión publicitaria (tv, radio, periodico)

En esta primera parte trabajaremos con un ejemplo clásico de marketing:

- **tv**: gasto en publicidad en TV (en miles de dólares).  
- **radio**: gasto en publicidad en radio.  
- **periodico**: gasto en publicidad en periódicos.  
- **ventas**: ventas del producto (en miles de unidades).

La idea es entender **cómo se relacionan las ventas con los distintos medios publicitarios**, usando regresión múltiple.

## Crear el conjunto de datos

El script genera los vectores directamente en R y luego los combina en un `data.frame`:

```{r datos-publicidad}
tv <- c(230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7,
         23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2,
         228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6,
         95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1,
         175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9,
         7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5,
         139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5,
         5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3,
         109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7,
         135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4,
         225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3,
         18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2,
         8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5,
         104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3,
         187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2,
         234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9,
         248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0,
         139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2,
         177.0, 283.6, 232.1)

radio <- c(37.8, 39.3, 45.9, 41.3, 10.8, 48.9, 32.8, 19.6, 2.1, 2.6, 5.8, 24.0,
           35.1, 7.6, 32.9, 47.7, 36.6, 39.6, 20.5, 23.9, 27.7, 5.1, 15.9, 16.9,
           12.6, 3.5, 29.3, 16.7, 27.1, 16.0, 28.3, 17.4, 1.5, 20.0, 1.4, 4.1,
           43.8, 49.4, 26.7, 37.7, 22.3, 33.4, 27.7, 8.4, 25.7, 22.5, 9.9, 41.5,
           15.8, 11.7, 3.1, 9.6, 41.7, 46.2, 28.8, 49.4, 28.1, 19.2, 49.6, 29.5,
           2.0, 42.7, 15.5, 29.6, 42.8, 9.3, 24.6, 14.5, 27.5, 43.9, 30.6, 14.3,
           33.0, 5.7, 24.6, 43.7, 1.6, 28.5, 29.9, 7.7, 26.7, 4.1, 20.3, 44.5,
           43.0, 18.4, 27.5, 40.6, 25.5, 47.8, 4.9, 1.5, 33.5, 36.5, 14.0, 31.6,
           3.5, 21.0, 42.3, 41.7, 4.3, 36.3, 10.1, 17.2, 34.3, 46.4, 11.0, 0.3,
           0.4, 26.9, 8.2, 38.0, 15.4, 20.6, 46.8, 35.0, 14.3, 0.8, 36.9, 16.0,
           26.8, 21.7, 2.4, 34.6, 32.3, 11.8, 38.9, 0.0, 49.0, 12.0, 39.6, 2.9,
           27.2, 33.5, 38.6, 47.0, 39.0, 28.9, 25.9, 43.9, 17.0, 35.4, 33.2, 5.7,
           14.8, 1.9, 7.3, 49.0, 40.3, 25.8, 13.9, 8.4, 23.3, 39.7, 21.1, 11.6,
           43.5, 1.3, 36.9, 18.4, 18.1, 35.8, 18.1, 36.8, 14.7, 3.4, 37.6, 5.2,
           23.6, 10.6, 11.6, 20.9, 20.1, 7.1, 3.4, 48.9, 30.2, 7.8, 2.3, 10.0,
           2.6, 5.4, 5.7, 43.0, 21.3, 45.1, 2.1, 28.7, 13.9, 12.1, 41.1, 10.8,
           4.1, 42.0, 35.6, 3.7, 4.9, 9.3, 42.0, 8.6)

periodico <- c(69.2, 45.1, 69.3, 58.5, 58.4, 75.0, 23.5, 11.6, 1.0, 21.2, 24.2,
               4.0, 65.9, 7.2, 46.0, 52.9, 114.0, 55.8, 18.3, 19.1, 53.4, 23.5,
               49.6, 26.2, 18.3, 19.5, 12.6, 22.9, 22.9, 40.8, 43.2, 38.6, 30.0,
               0.3, 7.4, 8.5, 5.0, 45.7, 35.1, 32.0, 31.6, 38.7, 1.8, 26.4, 43.3,
               31.5, 35.7, 18.5, 49.9, 36.8, 34.6, 3.6, 39.6, 58.7, 15.9, 60.0,
               41.4, 16.6, 37.7, 9.3, 21.4, 54.7, 27.3, 8.4, 28.9, 0.9, 2.2, 10.2,
               11.0, 27.2, 38.7, 31.7, 19.3, 31.3, 13.1, 89.4, 20.7, 14.2, 9.4,
               23.1, 22.3, 36.9, 32.5, 35.6, 33.8, 65.7, 16.0, 63.2, 73.4, 51.4,
               9.3, 33.0, 59.0, 72.3, 10.9, 52.9, 5.9, 22.0, 51.2, 45.9, 49.8,
               100.9, 21.4, 17.9, 5.3, 59.0, 29.7, 23.2, 25.6, 5.5, 56.5, 23.2,
               2.4, 10.7, 34.5, 52.7, 25.6, 14.8, 79.2, 22.3, 46.2, 50.4, 15.6,
               12.4, 74.2, 25.9, 50.6, 9.2, 3.2, 43.1, 8.7, 43.0, 2.1, 45.1, 65.6,
               8.5, 9.3, 59.7, 20.5, 1.7, 12.9, 75.6, 37.9, 34.4, 38.9, 9.0, 8.7,
               44.3, 11.9, 20.6, 37.0, 48.7, 14.2, 37.7, 9.5, 5.7, 50.5, 24.3,
               45.2, 34.6, 30.7, 49.3, 25.6, 7.4, 5.4, 84.8, 21.6, 19.4, 57.6,
               6.4, 18.4, 47.4, 17.0, 12.8, 13.1, 41.8, 20.3, 35.2, 23.7, 17.6,
               8.3, 27.4, 29.7, 71.8, 30.0, 19.6, 26.6, 18.2, 3.7, 23.4, 5.8, 6.0,
               31.6, 3.6, 6.0, 13.8, 8.1, 6.4, 66.2, 8.7)

ventas <- c(22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4,
            9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5,
            9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8,
            25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2,
            14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4,
            8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4,
            8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6,
            21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9,
            11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7,
            5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6,
            15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7,
            5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4,
            11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6,
            3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0,
            12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8,
            12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8,
            9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4)

datos <- data.frame(tv, radio, periodico, ventas)
head(datos)
```

## Correlaciones y multicolinealidad

Primero, miramos las correlaciones entre variables:

```{r corr-publicidad}
pairs(datos)

r <- cor(datos)
r

corrplot(r, method="circle", type="lower", diag=FALSE,
         tl.col="black", tl.cex=0.8, tl.srt=45)
```

::: {.callout-note}
Interpretación:

- La columna **ventas** te muestra cómo se relaciona la variable respuesta con cada medio.  
- Si dos regresores (por ejemplo, `tv` y `radio`) tienen **correlación muy alta**, podría haber multicolinealidad.  
- El `corrplot` ayuda a ver estas relaciones de forma más clara que solo con la matriz numérica.
:::

## Modelo con las tres variables

Ajustamos el modelo completo:

$$
\text{ventas} = \beta_0 + \beta_1 \text{tv} + \beta_2 \text{radio} + \beta_3 \text{periodico} + \varepsilon
$$

```{r modelo-completo}
modelo_full <- lm(ventas ~ tv + radio + periodico, data = datos)
summary(modelo_full)
```

::: {.callout-note}
Mira especialmente:

- El **p-value** de cada coeficiente → te indica si esa variable es significativa.  
- El **p-value** de la prueba F → si el modelo completo explica significativamente a `ventas`.  
- El **R^2** y **R^2 ajustado** → qué porcentaje de la variación se explica por los regresores.
:::

## Modelo sin variable no significativa

Si el coeficiente de `periodico` no es significativo, podemos intentar un modelo más parsimonioso:

```{r modelo-reducido}
modelo <- lm(ventas ~ tv + radio, data = datos)
summary(modelo)
```

::: {.callout-tip}
Eliminar variables no significativas:

- Simplifica la interpretación.  
- Puede mejorar la capacidad predictiva fuera de muestra.  
- Siempre es recomendable comparar modelos (por ejemplo, con ANOVA o criterios de información).
:::

## Superficie de regresión en 3D

Como ahora el modelo solo depende de **tv** y **radio**, podemos visualizar la “superficie de regresión” y cómo se ubican los datos alrededor de ella.

```{r superficie-simple, message=FALSE}
rango_tv <- range(datos$tv)
nuevos_valores_tv <- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)

rango_radio <- range(datos$radio)
nuevos_valores_radio <- seq(from = rango_radio[1], to = rango_radio[2],
                            length.out = 20)

predicciones <- outer(
  X = nuevos_valores_tv,
  Y = nuevos_valores_radio, 
  FUN = function(tv, radio) {
    predict(object = modelo, newdata = data.frame(tv, radio))
  }
)

superficie <- persp(
  x = nuevos_valores_tv,
  y = nuevos_valores_radio,
  z = predicciones,
  theta = 18, phi = 20,
  col = "lightblue", shade = 0.1,
  xlab = "tv", ylab = "radio", zlab = "ventas",
  ticktype = "detailed",
  main = "Predicción ventas ~ tv + radio"
)

observaciones <- trans3d(datos$tv, datos$radio, datos$ventas, superficie)
error <- trans3d(datos$tv, datos$radio, fitted(modelo), superficie)

points(observaciones, col = "red", pch = 16)
segments(observaciones$x, observaciones$y, error$x, error$y)
```

::: {.callout-note}
- Los puntos rojos son las **observaciones reales**.  
- Las líneas verticales muestran la **distancia** entre la superficie de predicción y los datos → son los errores del modelo.  
- Si las líneas son pequeñas, el ajuste es bueno.
:::

## Análisis de residuos del modelo reducido

```{r residuos-modelo}
shapiro.test(modelo$residuals)

hist(modelo$residuals, main="Histograma de residuos", xlab="Residuo")
plot(density(modelo$residuals), main="Densidad de residuos", xlab="Residuo")
```

Pruebas de autocorrelación y heterocedasticidad:

```{r pruebas-modelo}
dwtest(modelo, alternative ="two.sided", iterations = 1000)
bptest(modelo)
```

Gráfico de valores reales vs estimados:

```{r reales-vs-ajustados}
plot(modelo$fitted.values, datos$ventas,
     xlab = "Ventas estimadas", ylab = "Ventas reales",
     main = "Ventas reales vs estimadas (modelo sin periodico)")
lines(c(0, 25), c(0, 25), col = "red", lwd = 2)
```

::: {.callout-note}
- Si los puntos se alinean alrededor de la diagonal roja → el modelo predice razonablemente bien.  
- Desviaciones sistemáticas o patrones curvos indicarían que falta estructura (no linealidad, interacciones, etc.).
:::

## Incorporar una interacción tv * radio

Ahora probamos un modelo donde el efecto de la TV **depende del nivel de radio** (y viceversa).

```{r modelo-interaccion}
tv_radio <- tv * radio

modelo_interaccion <- lm(ventas ~ tv + radio + tv:radio, data = datos)
summary(modelo_interaccion)
```

Analizamos los residuos del nuevo modelo:

```{r residuos-interaccion}
shapiro.test(modelo_interaccion$residuals)

hist(modelo_interaccion$residuals, main="Histograma residuos modelo interacción")
plot(density(modelo_interaccion$residuals),
     main="Densidad residuos modelo interacción", xlab="Residuo")

dwtest(modelo_interaccion, alternative ="two.sided", iterations = 1000)
bptest(modelo_interaccion)
```

Ventas reales vs estimadas con interacción:

```{r reales-vs-ajustados-interaccion}
plot(modelo_interaccion$fitted.values, datos$ventas,
     xlab = "Ventas estimadas",
     ylab = "Ventas reales",
     main = "Ventas reales vs estimadas (modelo con interacción)")
lines(c(0, 25), c(0, 25), col = "red", lwd = 2)
```

## Superficie del modelo con interacción

```{r superficie-interaccion, message=FALSE}
rango_tv <- range(datos$tv)
nuevos_valores_tv <- seq(from = rango_tv[1], to = rango_tv[2], length.out = 20)

rango_radio <- range(datos$radio)
nuevos_valores_radio <- seq(from = rango_radio[1], to = rango_radio[2], length.out = 20)

predicciones <- outer(
  X = nuevos_valores_tv,
  Y = nuevos_valores_radio, 
  FUN = function(tv, radio) {
    predict(object = modelo_interaccion,
            newdata = data.frame(tv, radio))
  }
)

superficie <- persp(
  x = nuevos_valores_tv,
  y = nuevos_valores_radio,
  z = predicciones,
  theta = 18, phi = 20,
  col = "lightblue", shade = 0.1,
  xlab = "tv", ylab = "radio", zlab = "ventas",
  ticktype = "detailed",
  main = "Predicción ventas ~ tv + radio + tv:radio"
)

observaciones <- trans3d(datos$tv, datos$radio, datos$ventas, superficie)
error <- trans3d(datos$tv, datos$radio, fitted(modelo_interaccion), superficie)

points(observaciones, col = "red", pch = 16)
segments(observaciones$x, observaciones$y, error$x, error$y)
```

## Comparación de modelos con ANOVA

Comparamos el modelo sin interacción y el modelo con interacción:

```{r anova-interaccion}
anova(modelo, modelo_interaccion)
```

::: {.callout-note}
- Si la prueba ANOVA da un **p-value pequeño**, la interacción aporta información estadísticamente significativa.  
- Además de la significancia, es importante revisar residuos y lógica económica del modelo.
:::

## Modelo con interacción y término cuadrático en tv

Probamos un modelo más flexible:

$$
\text{ventas} = \beta_0 + \beta_1 \text{tv} + \beta_2 \text{radio} + \beta_3 \text{tv}^2 + \beta_4 (\text{tv}\cdot\text{radio}) + \varepsilon
$$
```{r modelo-interaccion-cuadratico}
modelo_interaccion_1 <- lm(ventas ~ tv + radio + I(tv^2) + tv:radio, data = datos)
summary(modelo_interaccion_1)

plot(modelo_interaccion_1$fitted.values, datos$ventas,
     xlab = "Ventas estimadas", ylab = "Ventas reales",
     main = "Ventas reales vs estimadas (modelo con tv^2 e interacción)")
lines(c(0, 27), c(0, 27), col = "red", lwd = 2)

hist(modelo_interaccion_1$residuals, main="Histograma residuos modelo_interaccion_1")
plot(density(modelo_interaccion_1$residuals),
     main="Densidad residuos modelo_interaccion_1")

shapiro.test(modelo_interaccion_1$residuals)
dwtest(modelo_interaccion_1, alternative ="two.sided", iterations = 1000)
bptest(modelo_interaccion_1)
```

# Parte 2: Regresión polinomial y transformaciones (ejemplo de millaje)

En esta parte trabajamos con el archivo `millaje.txt`, que contiene información de autos:

- `mpg`: millas por galón (consumo).  
- `hp`: horsepower (potencia del motor).  
- `vol`: alguna medida de volumen/cilindrada del motor.

Queremos modelar el **consumo de combustible** (`mpg`) en función de la potencia (`hp`) y otras características, usando polinomios y transformaciones.

## Cargar los datos de millaje

```{r leer-millaje}
archivo_millaje <- file.path(ruta_datos, "millaje.txt")

millaje <- read.table(file = archivo_millaje, header = TRUE)
head(millaje)
```

## Correlaciones y gráficos

```{r corr-millaje}
r_auto <- cor(millaje)
r_auto

pairs(millaje)

corrplot(r_auto, method="circle", type="lower", diag=FALSE,
         tl.col="black", tl.cex=0.8, tl.srt=45)
```

Gráfico simple de `mpg` vs `hp`:

```{r scatter-hp-mpg}
plot(
  x = millaje$hp,
  y = millaje$mpg,
  main = "Consumo vs potencia motor",
  xlab = "hp (potencia)",
  ylab = "mpg (millas por galón)",
  pch = 20,
  col = "grey"
)
```

## Modelo lineal simple en hp y vol

```{r modelo-lineal-millaje}
modelo_lineal <- lm(mpg ~ hp + vol, data = millaje)
summary(modelo_lineal)
```

Visualizamos la recta de regresión en función de `hp` (manteniendo fijo `vol` en el promedio, de manera implícita):

```{r linea-simple}
plot(
  x = millaje$hp,
  y = millaje$mpg,
  main = "Consumo vs potencia motor (modelo lineal)",
  xlab = "hp",
  ylab = "mpg",
  pch  = 20,
  col  = "grey"
)
abline(modelo_lineal, lwd = 3, col = "red")
```

::: {.callout-note}
Este gráfico es más ilustrativo que riguroso (porque el modelo usa también `vol`), pero sirve para visualizar la tendencia lineal negativa: a mayor `hp`, menor `mpg`.
:::

## Modelo polinomial cuadrático

Ahora permitimos una relación **no lineal** entre `hp` y `mpg`:

```{r modelo-pol2}
modelo_pol2 <- lm(mpg ~ vol + hp + I(hp^2), data = millaje)
summary(modelo_pol2)

modelo_cuadratico <- lm(mpg ~ poly(hp, 2), data = millaje)
summary(modelo_cuadratico)
```

Comparación gráfico predicho vs real:

```{r ajuste-pol2}
plot(modelo_pol2$fitted.values, millaje$mpg,
     xlab = "mpg estimado", ylab = "mpg real",
     main = "Ajuste modelo polinomial (grado 2)")
lines(c(10, 60), c(10, 60), col = "red", lwd = 2)
```

## Análisis de residuos del modelo polinomial

```{r residuos-pol2}
shapiro.test(modelo_pol2$residuals)

hist(modelo_pol2$residuals, main="Histograma residuos modelo_pol2")
plot(density(modelo_pol2$residuals),
     main="Densidad residuos modelo_pol2", xlab="Residuo")

par(mfrow = c(2, 2))
plot(modelo_pol2)
par(mfrow = c(1, 1))
```

Comparación formal entre el modelo lineal y el polinomial:

```{r anova-pol2}
anova(modelo_lineal, modelo_pol2)
```

Si el p-valor es pequeño, el término cuadrático mejora significativamente el modelo.

## Curva predicha del modelo polinomial

```{r curva-pol2}
plot(
  x = millaje$hp,
  y = millaje$mpg,
  main = "Consumo vs potencia motor (modelo cuadrático)",
  xlab = "hp",
  ylab = "mpg",
  pch  = 20,
  col  = "grey"
)

puntos_interpolados <- seq(from = min(millaje$hp), to = max(millaje$hp), by = 1)

prediccion <- predict(
  object = modelo_pol2,
  newdata = data.frame(hp = millaje$hp, vol = millaje$vol)
)

lines(sort(millaje$hp), prediccion[order(millaje$hp)],
      col = "red", lwd = 3)
```

## Visualización con ggplot2

```{r ggplot-pol2}
ggplot(millaje, aes(x = hp, y = mpg)) +
  geom_point(colour = "grey") +
  stat_smooth(method = "lm", formula = y ~ hp + I(hp^2)) +
  labs(title = "Consumo vs potencia motor (modelo cuadrático)") +
  theme_bw()
```

## Polinomios de grados más altos

```{r ggplot-polinomios}
ggplot(millaje, aes(x = hp, y = mpg)) +
  geom_point(colour = "grey") +
  stat_smooth(method = "lm", formula = y ~ poly(x, 2),  colour = "red",   se = FALSE) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 5),  colour = "blue",  se = FALSE) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 10), colour = "green", se = FALSE) +
  labs(title = "Polinomios de grados 2, 5 y 10") +
  theme_bw()
```

::: {.callout-note}
Observa cómo los polinomios de grados más altos se ajustan fuertemente a los datos, pero pueden **sobreajustar** (overfitting) y producir curvas muy oscilantes poco realistas.
:::

## Modelos polinomiales y comparación

```{r modelos-altos}
modelo_5 <- lm(mpg ~ poly(hp, 5), data = millaje)
summary(modelo_5)

modelo_5_correjido <- lm(mpg ~ vol + hp + I(hp^2) + I(hp^3), data = millaje)
summary(modelo_5_correjido)

anova(modelo_cuadratico, modelo_5_correjido)
```

Análisis de residuos:

```{r residuos-5corr}
shapiro.test(modelo_5_correjido$residuals)

hist(modelo_5_correjido$residuals, main = "Histograma residuos modelo_5_correjido")
plot(density(modelo_5_correjido$residuals),
     main = "Densidad residuos modelo_5_correjido")

plot(modelo_5_correjido$fitted.values, millaje$mpg,
     xlab = "mpg estimado", ylab = "mpg real",
     main = "Ajuste modelo_5_correjido")
lines(c(10, 60), c(10, 60), col = "red", lwd = 2)
```

## Transformaciones de la variable respuesta

Buscamos mejorar la normalidad de los residuos y la homocedasticidad usando transformaciones de `mpg`:

### Transformación logarítmica

```{r modelo-log}
modelo_pol2_trans <- lm(log(1 + mpg) ~ vol + hp + I(hp^2), data = millaje)
summary(modelo_pol2_trans)

plot(modelo_pol2_trans$residuals, modelo_pol2_trans$fitted.values,
     main = "Residuos vs ajustados (log(1+mpg))")

plot(log(1 + millaje$mpg), modelo_pol2_trans$fitted.values,
     main = "Valores reales transformados vs ajustados")
lines(c(2, 5), c(2, 5), col = "red", lwd = 2)

shapiro.test(modelo_pol2_trans$residuals)

hist(modelo_pol2_trans$residuals, main = "Histograma residuos modelo_pol2_trans")
plot(density(modelo_pol2_trans$residuals),
     main = "Densidad residuos modelo_pol2_trans")
```

### Transformación raíz cuadrada

```{r modelo-sqrt}
modelo_pol3_trans <- lm(sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)
summary(modelo_pol3_trans)

shapiro.test(modelo_pol3_trans$residuals)

plot(modelo_pol3_trans$residuals, modelo_pol3_trans$fitted.values,
     main = "Residuos vs ajustados (sqrt(mpg))")
plot(sqrt(millaje$mpg), modelo_pol3_trans$fitted.values,
     main = "sqrt(mpg) real vs ajustado")
lines(c(4, 8), c(4, 8), col = "red", lwd = 2)
```

### Transformación 1/sqrt(mpg)

```{r modelo-inv-sqrt}
modelo_pol4_trans <- lm(1/sqrt(mpg) ~ vol + hp + I(hp^2), data = millaje)
summary(modelo_pol4_trans)

plot(modelo_pol4_trans$residuals, modelo_pol4_trans$fitted.values,
     main = "Residuos vs ajustados (1/sqrt(mpg))")
plot(1/sqrt(millaje$mpg), modelo_pol4_trans$fitted.values,
     main = "1/sqrt(mpg) real vs ajustado")
shapiro.test(modelo_pol4_trans$residuals)
```

### Transformaciones más complejas

```{r modelos-log-hp}
modelo_pol2_tran_2 <- lm(log(1 + mpg) ~ vol + hp + log(1 + hp) + I(hp^2),
                         data = millaje)
summary(modelo_pol2_tran_2)

plot(log(1 + millaje$mpg), modelo_pol2_tran_2$fitted.values,
     main = "log(1+mpg) real vs ajustado (modelo_tran_2)")

shapiro.test(modelo_pol2_tran_2$residuals)
hist(modelo_pol2_tran_2$residuals, main = "Histograma residuos modelo_tran_2")
plot(density(modelo_pol2_tran_2$residuals),
     main = "Densidad residuos modelo_tran_2")

plot(modelo_pol2_tran_2)
```

Otro modelo más flexible:

```{r modelo-tran-3}
modelo_pol2_tran_3 <- lm(log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) +
                           log(1 + hp) + I(hp^2),
                         data = millaje)
summary(modelo_pol2_tran_3)

shapiro.test(modelo_pol2_tran_3$residuals)

plot(modelo_pol2_tran_3)
plot(log(1 + millaje$mpg), modelo_pol2_tran_3$fitted.values,
     main = "log(1+mpg) real vs ajustado (modelo_tran_3)")
lines(c(3, 4.5), c(3, 4.5), col = "red", lwd = 2)
```

### Modelos sin constante y selección

```{r modelos-sin-constante}
modelo_pol2_tran_4 <- lm(log(1 + mpg) ~ hp + I(1/hp) + I(1/(hp^2)) +
                           log(1 + hp) + I(hp^2) - 1,
                         data = millaje)
summary(modelo_pol2_tran_4)

plot(log(1 + millaje$mpg), modelo_pol2_tran_4$fitted.values,
     main = "Modelo_tran_4 (sin constante)")
lines(c(3, 4.5), c(3, 4.5), col = "red", lwd = 2)

modelo_pol2_tran_5 <- lm(log(1 + mpg) ~ hp + I(1/hp) + log(1 + hp) + I(hp^2) - 1,
                         data = millaje)
summary(modelo_pol2_tran_5)

shapiro.test(modelo_pol2_tran_5$residuals)

plot(log(1 + millaje$mpg), modelo_pol2_tran_5$fitted.values,
     main = "Modelo_tran_5 (sin constante)")
lines(c(3, 4.5), c(3, 4.5), col = "red", lwd = 2)

plot(modelo_pol2_tran_5)
```

### Un modelo candidato “bueno”

El script sugiere como uno de los mejores:

```{r modelo-tran-6-y-7}
modelo_pol2_tran_6 <- lm(log(1 + mpg) ~ log(1 + hp) - 1, data = millaje)
summary(modelo_pol2_tran_6)

shapiro.test(modelo_pol2_tran_6$residuals)

hist(modelo_pol2_tran_6$residuals,
     main = "Histograma residuos modelo_tran_6")
plot(density(modelo_pol2_tran_6$residuals),
     main = "Densidad residuos modelo_tran_6")

plot(modelo_pol2_tran_6)

modelo_pol2_tran_7 <- lm(log(1 + mpg) ~ vol + log(1 + hp) - 1, data = millaje)
summary(modelo_pol2_tran_7)
```

::: {.callout-note}
En la práctica, al elegir entre varios modelos transformados, debes considerar:

- Supuestos sobre los **residuos** (normalidad, homocedasticidad).  
- Interpretabilidad económica de los coeficientes.  
- Capacidad predictiva (idealmente evaluada fuera de muestra).  
- Parsimonia: preferir el modelo más simple que explique bien los datos.
:::

# Cierre del laboratorio

En este laboratorio trabajaste con:

- Regresión múltiple con **eliminación de variables irrelevantes**.  
- Inclusión de **interacciones** y términos **cuadráticos**.  
- Visualizaciones 3D de superficies de regresión.  
- Modelos polinomiales de distintos grados.  
- Comparación de modelos vía **ANOVA**.  
- Uso de **transformaciones** (log, raíz, recíprocos) para mejorar los supuestos.

Todo esto forma parte del “arsenal” que usarás en cursos posteriores de econometría y en aplicaciones reales para ajustar modelos más realistas y robustos